{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11065693-20a5-462a-8ea3-f5a8f23835fb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.9/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg;\n",
    "\n",
    "Pkg.add(\"Genie\")\n",
    "Pkg.add(\"Images\")\n",
    "Pkg.add(\"Flux\")\n",
    "Pkg.add(\"MLUtils\")\n",
    "Pkg.add(\"ArgParse\")\n",
    "Pkg.add(\"LoggingExtras\")\n",
    "Pkg.add(\"Dates\")\n",
    "Pkg.add(\"Printf\")\n",
    "Pkg.add(\"TensorBoardLogger\")\n",
    "Pkg.add(\"JLD2\");\n",
    "Pkg.add(\"BSON\");\n",
    "Pkg.add(\"Pickle\")\n",
    "Pkg.add(\"ProgressBars\")\n",
    "Pkg.add(\"Distributions\")\n",
    "Pkg.add(\"Revise\")\n",
    "Pkg.add(\"Zygote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b62ebc-2bee-4d04-8e93-e5f0fccc0579",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "using Pickle;\n",
    "using ArgParse;\n",
    "using Random;\n",
    "using Logging, LoggingExtras, TensorBoardLogger;\n",
    "using Dates;\n",
    "using Printf;\n",
    "using ProgressBars;\n",
    "using Flux;\n",
    "using MLUtils;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c67737-8630-4baf-a1d4-fa9f077c94ed",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f_dir = \"dataset/KG_data\";\n",
    "f_model = \"FB15k-betae\";\n",
    "f_train_queries = \"train-queries.pkl\";\n",
    "f_train_answers = \"train-answers.pkl\";\n",
    "f_valid_queries = \"valid-queries.pkl\";\n",
    "f_valid_hard_answers = \"valid-hard-answers.pkl\";\n",
    "f_valid_easy_answers = \"valid-easy-answers.pkl\";\n",
    "f_test_queries = \"test-queries.pkl\";\n",
    "f_test_hard_answers = \"test-hard-answers.pkl\";\n",
    "f_test_easy_answers = \"test-easy-answers.pkl\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a095ef3b-c89d-4edb-8fdc-0d236501dcda",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "query_name_dict = Dict{Tuple, String}((\"e\",(\"r\",))=> \"1p\",\n",
    "                                    (\"e\", (\"r\", \"r\"))=> \"2p\",\n",
    "                                    (\"e\", (\"r\", \"r\", \"r\"))=> \"3p\",\n",
    "                                    ((\"e\", (\"r\",)), (\"e\", (\"r\",)))=> \"2i\",\n",
    "                                    ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"e\", (\"r\",)))=> \"3i\",\n",
    "                                    (((\"e\", (\"r\",)), (\"e\", (\"r\",))), (\"r\",))=> \"ip\",\n",
    "                                    ((\"e\", (\"r\", \"r\")), (\"e\", (\"r\",)))=> \"pi\",\n",
    "                                    ((\"e\", (\"r\",)), (\"e\", (\"r\", \"n\")))=> \"2in\",\n",
    "                                    ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"e\", (\"r\", \"n\")))=> \"3in\",\n",
    "                                    (((\"e\", (\"r\",)), (\"e\", (\"r\", \"n\"))), (\"r\",))=> \"inp\",\n",
    "                                    ((\"e\", (\"r\", \"r\")), (\"e\", (\"r\", \"n\")))=> \"pin\",\n",
    "                                    ((\"e\", (\"r\", \"r\", \"n\")), (\"e\", (\"r\",)))=> \"pni\",\n",
    "                                    ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"u\",))=> \"2u-DNF\",\n",
    "                                    (((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"u\",)), (\"r\",))=> \"up-DNF\",\n",
    "                                    (((\"e\", (\"r\", \"n\")), (\"e\", (\"r\", \"n\"))), (\"n\",))=> \"2u-DM\",\n",
    "                                    (((\"e\", (\"r\", \"n\")), (\"e\", (\"r\", \"n\"))), (\"n\", \"r\"))=> \"up-DM\"\n",
    "                                );\n",
    "name_query_dict = Dict{String, Tuple}((y => x) for (x, y) in query_name_dict);\n",
    "all_tasks = collect(keys(name_query_dict));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a5c0bdb-543c-4665-a13d-e058db064ca3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set_logger"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function parse_cmdargs(args::Vector{String})\n",
    "    s = ArgParseSettings(\n",
    "        description = \"Training and Testing Knowledge Graph Embedding Models\",\n",
    "        usage = \"train.py [<args>] [-h | --help]\"\n",
    "    )\n",
    "\n",
    "    @add_arg_table s begin\n",
    "        \"--cuda\"\n",
    "            action= :store_true\n",
    "            help=\"use GPU\"\n",
    "        \"--train\"\n",
    "            action= :store_true\n",
    "            help=\"do train\"\n",
    "        \"--valid\"\n",
    "            action= :store_true\n",
    "            help=\"do valid\"\n",
    "        \"--test\"\n",
    "            action= :store_true\n",
    "            help=\"do test\"\n",
    "        \"--data_path\"\n",
    "            arg_type=String\n",
    "            default= nothing\n",
    "            help=\"KG data path\"\n",
    "        \"-n\", \"--negative_sample_size\"\n",
    "            default=128\n",
    "            arg_type=Int\n",
    "            help=\"negative entities sampled per query\"\n",
    "        \"-d\", \"--hidden_dim\"\n",
    "            default=500\n",
    "            arg_type=Int\n",
    "            help=\"embedding dimension\"\n",
    "        \"-g\", \"--gamma\"\n",
    "            default=12.0\n",
    "            arg_type=Float64\n",
    "            help=\"margin in the loss\"\n",
    "        \"-b\", \"--batch_size\"\n",
    "            default=1024\n",
    "            arg_type=Int\n",
    "            help=\"batch size of queries\"\n",
    "        \"--test_batch_size\"\n",
    "            default=1\n",
    "            arg_type=Int\n",
    "            help=\"valid/test batch size\"\n",
    "        \"--lr\"\n",
    "            default=0.0001\n",
    "            arg_type=Float64\n",
    "        \"--cpu\"\n",
    "            default=10\n",
    "            arg_type=Int\n",
    "            help=\"used to speed up torch.dataloader\"\n",
    "        \"--save_path\"\n",
    "            default=\".\"\n",
    "            arg_type=String\n",
    "            help=\"no need to set manually, will configure automatically\"\n",
    "        \"--max_steps\"\n",
    "            default=100000\n",
    "            arg_type=Int\n",
    "            help=\"maximum iterations to train\"\n",
    "        \"--warm_up_steps\"\n",
    "            default=nothing\n",
    "            arg_type=Int\n",
    "            help=\"no need to set manually, will configure automatically\"\n",
    "        \"--save_checkpoint_steps\"\n",
    "            default=50000\n",
    "            arg_type=Int\n",
    "            help=\"save checkpoints every xx steps\"\n",
    "        \"--valid_steps\"\n",
    "            default=10000\n",
    "            arg_type=Int\n",
    "            help=\"evaluate validation queries every xx steps\"\n",
    "        \"--log_steps\"\n",
    "            default=100\n",
    "            arg_type=Int\n",
    "            help=\"train log every xx steps\"\n",
    "        \"--test_log_steps\"\n",
    "            default=1000\n",
    "            arg_type=Int\n",
    "            help=\"valid/test log every xx steps\"\n",
    "        \"--nentity\"\n",
    "            arg_type=Int\n",
    "            default=0\n",
    "            help=\"DO NOT MANUALLY SET\"\n",
    "        \"--nrelation\"\n",
    "            arg_type=Int\n",
    "            default=0\n",
    "            help=\"DO NOT MANUALLY SET\"\n",
    "        \"--geo\"\n",
    "            default=\"vec\"\n",
    "            arg_type=String\n",
    "            help=\"the reasoning model, vec for GQE, box for Query2box, beta for BetaE\"\n",
    "        \"--print_on_screen\"\n",
    "            action= :store_false\n",
    "        \"--tasks\"\n",
    "            default=\"1p.2p.3p.2i.3i.ip.pi.2in.3in.inp.pin.pni.2u.up\"\n",
    "            arg_type=String\n",
    "            help=\"tasks connected by dot, refer to the BetaE paper for detailed meaning and structure of each task\"\n",
    "        \"--seed\"\n",
    "            default=0\n",
    "            arg_type=Int\n",
    "            help=\"random seed\"\n",
    "        \"--beta_mode\"\n",
    "            default=\"(1600,2)\"\n",
    "            arg_type=String\n",
    "            help=\"(hidden_dim,num_layer) for BetaE relational projection\"\n",
    "        \"--box_mode\"\n",
    "            default=\"(nothing,0.02)\"\n",
    "            arg_type=String\n",
    "            help=\"(offset activation,center_reg) for Query2box, center_reg balances the in_box dist and out_box dist\"\n",
    "        \"--prefix\"\n",
    "            default=nothing\n",
    "            arg_type=String\n",
    "            help=\"prefix of the log path\"\n",
    "        \"--checkpoint_path\"\n",
    "            default=nothing\n",
    "            arg_type=String\n",
    "            help=\"path for loading the checkpoints\"\n",
    "        \"--evaluate_union\"\n",
    "            default=\"DNF\"\n",
    "            arg_type=String\n",
    "            help=\"the way to evaluate union queries, transform it to disjunctive normal form (DNF) or use the De Morgan\\\"s laws (DM)\"\n",
    "    end\n",
    "\n",
    "    return parse_args(args, s)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Write logs to console and log file\n",
    "\"\"\"\n",
    "function set_logger(args)\n",
    "\n",
    "    if args[\"train\"] == true\n",
    "        log_file = joinpath(args[\"save_path\"], \"train.log\")\n",
    "    else\n",
    "        log_file = joinpath(args[\"save_path\"], \"test.log\")\n",
    "    end\n",
    "\n",
    "    log_io = open(log_file, \"w\");\n",
    "    datefmt=DateFormat(\"YY-mm-dd HH:MM:SS\");\n",
    "\n",
    "    timestamp_logger(logger) = TransformerLogger(logger) do log\n",
    "      merge(log, (; message = \"$(Dates.format(now(), datefmt)) $(log.message)\"))\n",
    "    end\n",
    "\n",
    "    file_logger = timestamp_logger(FileLogger(log_file));\n",
    "    global_logger(file_logger)\n",
    "\n",
    "    if args[\"print_on_screen\"]\n",
    "        time_loger = timestamp_logger(ConsoleLogger(stdout, Logging.Info));\n",
    "\n",
    "        tl = TeeLogger(file_logger, time_loger);\n",
    "        global_logger(tl)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b876a522-b879-45f3-8604-d5854a74afa3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_data (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_data(args, tasks, all_tasks, query_dict)\n",
    "    @info \"loading data....\"\n",
    "\n",
    "    data_path = args[\"data_path\"];\n",
    "    train_queries = Pickle.load(open(joinpath(data_path, f_train_queries)));\n",
    "    train_answers = Pickle.load(open(joinpath(data_path, f_train_answers)));\n",
    "    valid_queries = Pickle.load(open(joinpath(data_path, f_valid_queries)));\n",
    "    valid_hard_answers = Pickle.load(open(joinpath(data_path, f_valid_hard_answers)));\n",
    "    valid_easy_answers = Pickle.load(open(joinpath(data_path, f_valid_easy_answers)));\n",
    "    test_queries = Pickle.load(open(joinpath(data_path, f_test_queries)));\n",
    "    test_hard_answers = Pickle.load(open(joinpath(data_path, f_test_hard_answers)));\n",
    "    test_easy_answers = Pickle.load(open(joinpath(data_path, f_test_easy_answers)));\n",
    "\n",
    "    # remove tasks not in args.tasks\n",
    "    for name in all_tasks\n",
    "        if 'u' in name\n",
    "            name, evaluate_union = split(name, \"-\")\n",
    "        else\n",
    "            evaluate_union = args[\"evaluate_union\"]\n",
    "        end\n",
    "        if !(name in tasks) || evaluate_union != args[\"evaluate_union\"]\n",
    "            query_structure = query_dict[eval(if !('u' in name) name else join([name, evaluate_union], \"-\") end)]\n",
    "            #println(\"load_data: deleteing structure...:\\n $(query_structure)\")\n",
    "            if haskey(train_queries, query_structure)\n",
    "                delete!(train_queries, query_structure);\n",
    "            end\n",
    "            if haskey(valid_queries, query_structure)\n",
    "                delete!(valid_queries, query_structure);\n",
    "            end\n",
    "            if haskey(test_queries, query_structure)\n",
    "                delete!(test_queries, query_structure)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    @info \"load data....Done\"\n",
    "    return train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "678871bc-e742-48d5-9ad7-fc150f5235a0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Print the evaluation logs\n",
    "\"\"\"\n",
    "function log_metrics(mode, step, metrics)\n",
    "    for metric in metrics\n",
    "        @info \"$mode $metric at step $(step): $(metrics[metric.first])\"\n",
    "    end\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    Evaluate queries in dataloader\n",
    "\"\"\"\n",
    "function evaluate(model, tp_answers, fn_answers, args, dataloader, query_name_dict, mode, step, writer)\n",
    "\n",
    "    average_metrics = Dict{Float}()\n",
    "    all_metrics = Dict{Float}()\n",
    "\n",
    "    metrics = model.test_step(model, tp_answers, fn_answers, args, dataloader, query_name_dict)\n",
    "    num_query_structures = 0\n",
    "    num_queries = 0\n",
    "    for query_structure in metrics\n",
    "        log_metrics(mode * \" \" * query_name_dict[query_structure], step, metrics[query_structure])\n",
    "\n",
    "        for metric in metrics[query_structure]\n",
    "            writer.add_scalar(\"_\".join([mode, query_name_dict[query_structure], metric]), metrics[query_structure][metric], step)\n",
    "            all_metrics[\"_\".join([query_name_dict[query_structure], metric])] = metrics[query_structure][metric]\n",
    "            if metric != \"num_queries\"\n",
    "                average_metrics[metric] += metrics[query_structure][metric]\n",
    "            end\n",
    "        end\n",
    "        num_queries += metrics[query_structure][\"num_queries\"]\n",
    "        num_query_structures += 1\n",
    "    end\n",
    "\n",
    "    for metric in average_metrics\n",
    "        average_metrics[metric] /= num_query_structures\n",
    "        writer.add_scalar(\"_\".join([mode, \"average\", metric]), average_metrics[metric], step)\n",
    "        all_metrics[\"_\".join([\"average\", metric])] = average_metrics[metric]\n",
    "    end\n",
    "\n",
    "    log_metrics(\"$mode average\", step, average_metrics)\n",
    "    return all_metrics\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e852c1c-8fc9-4f9e-9677-8ab2fbf21a15",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flatten_query (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function format_time()\n",
    "    return Dates.format(Dates.now(), \"YY.mm.dd\")\n",
    "end\n",
    "\n",
    "#---Evaluate a tuple string into a tuple.\n",
    "function eval_tuple(arg_return)\n",
    "    if typeof(arg_return) <: Tuple\n",
    "        return arg_return\n",
    "    end\n",
    "\n",
    "    if !(arg_return[1] in (\"(\", \"[\"))\n",
    "        arg_return = eval(arg_return)\n",
    "    else\n",
    "        splitted = split(arg_return[2:length(arg_return)-1], \", \")\n",
    "        List = []\n",
    "        for item in splitted\n",
    "            try\n",
    "                item = eval(item)\n",
    "            catch err\n",
    "                pass\n",
    "            end\n",
    "            if item == \"\"\n",
    "                continue\n",
    "            end\n",
    "            append!(List, item)\n",
    "        end\n",
    "        arg_return = tuple(List)\n",
    "    return arg_return\n",
    "    end\n",
    "end\n",
    "\n",
    "function flatten_query(queries)\n",
    "    all_queries = []\n",
    "    for query_structure in keys(queries)\n",
    "        list_queries = collect(queries[query_structure])\n",
    "        ttt = [(query, query_structure) for query in list_queries]\n",
    "        #println(\"query_structure key: $(query_structure) queries length: $(length(list_queries)) tuple length: $(length(ttt))\");\n",
    "        append!(all_queries, [(query, query_structure) for query in list_queries])\n",
    "    end\n",
    "    return all_queries\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87586e14-fbf6-4bcd-9ceb-fd8c3ca2d8ad",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mloading data....\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mload data....Done\n"
     ]
    }
   ],
   "source": [
    "str_tasks = \"1p.2p.3p.2i.3i.ip.pi.2u.up\";\n",
    "tasks = split(str_tasks, \".\");\n",
    "args = Dict(\"data_path\"=> joinpath(f_dir ,f_model), \"evaluate_union\"=>\"DNF\");\n",
    "\n",
    "train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers = load_data(args, tasks, all_tasks, name_query_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe8f4885-5008-4dfa-a0f4-e0cc6540b449",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.KGDataset"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module KGDataset\n",
    "\n",
    "import MLUtils: DataLoader\n",
    "\n",
    "export numobs, getobs, TrainDataset, TestDataset, SingleDirectionalOneShotIterator\n",
    "\n",
    "abstract type Dataset end\n",
    "\n",
    "struct TrainDataset <: Dataset\n",
    "    queries::Vector{Any}\n",
    "    answer::Dict{Any, Any}\n",
    "    nentity::Int\n",
    "    nrelation::Int\n",
    "    negative_sample_size::Int\n",
    "end\n",
    "\n",
    "function numobs(data::TrainDataset)\n",
    "    return length(data.queries)\n",
    "end\n",
    "\n",
    "function getobs(data::TrainDataset, idx)\n",
    "    return data.queries[idx]\n",
    "end\n",
    "\n",
    "struct TestDataset <: Dataset\n",
    "    queries::Vector{Any}\n",
    "    nentity::Int\n",
    "    nrelation::Int\n",
    "end\n",
    "\n",
    "function numobs(data::TestDataset)\n",
    "    return length(data.queries)\n",
    "end\n",
    "\n",
    "function getobs(data::TestDataset, idx)\n",
    "    return data.queries[idx]\n",
    "end\n",
    "\n",
    "struct SingleDirectionalOneShotIterator\n",
    "    data_loader::DataLoader\n",
    "end\n",
    "\n",
    "function Base.iterate(iter::SingleDirectionalOneShotIterator, state = 1)\n",
    "    if length(iter.data_loader.data.queries) < state\n",
    "        return nothing\n",
    "    end\n",
    "    \n",
    "    return ( iter.data_loader.data.queries[state], state + 1 )\n",
    "end\n",
    "#=====\n",
    "function iterate(iter::SingleDirectionalOneShotIterator)\n",
    "    return ( iter.data_loader.data.queries[1], 1 )\n",
    "end\n",
    "\n",
    "function length(iter::SingleDirectionalOneShotIterator)\n",
    "    return length(iter.data_loader.data.queries);\n",
    "end\n",
    "\n",
    "function next(iter::SingleDirectionalOneShotIterator, state)\n",
    "    if length(iter.data_loader.data.queries) < state\n",
    "        return nothing\n",
    "    end\n",
    "    \n",
    "    return ( iter.data_loader.data.queries[state], state + 1)\n",
    "end\n",
    "\n",
    "function isdone(iter::SingleDirectionalOneShotIterator, state)\n",
    "    return length(iter.data_loader.data.queries) < state\n",
    "end\n",
    "========#\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ae66064-914a-4244-a018-fa77ddeeadfd",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_structure key: (\"e\", (\"r\", \"r\", \"r\")) queries length: 273710 tuple length: 273710\n",
      "query_structure key: ((\"e\", (\"r\",)), (\"e\", (\"r\",))) queries length: 273710 tuple length: 273710\n",
      "query_structure key: ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"e\", (\"r\",))) queries length: 273710 tuple length: 273710\n",
      "query_structure key: (\"e\", (\"r\", \"r\")) queries length: 273710 tuple length: 273710\n",
      "query_structure key: (\"e\", (\"r\",)) queries length: 273710 tuple length: 273710\n",
      "length of train_flatten_queries: 1368550\n",
      "length of train_answers: 2737100\n",
      "TrainDataset\n",
      "numobs, getobs.....\n",
      "((2674, (218, 383, 347)), (\"e\", (\"r\", \"r\", \"r\")))\n",
      "((253, (1219, 1074, 157)), (\"e\", (\"r\", \"r\", \"r\")))\n",
      "((7206, (65, 1509, 1650)), (\"e\", (\"r\", \"r\", \"r\")))\n",
      "((9713, (205, 613, 109)), (\"e\", (\"r\", \"r\", \"r\")))\n",
      "((3, (1310, 1195, 1315)), (\"e\", (\"r\", \"r\", \"r\")))\n",
      "((2535, (161, 336, 700)), (\"e\", (\"r\", \"r\", \"r\")))\n",
      "((2828, (1471, 1233, 385)), (\"e\", (\"r\", \"r\", \"r\")))\n",
      "((4542, (94, 1166, 330)), (\"e\", (\"r\", \"r\", \"r\")))\n",
      "((10531, (37, 460, 684)), (\"e\", (\"r\", \"r\", \"r\")))\n",
      "((12842, (356, 289, 697)), (\"e\", (\"r\", \"r\", \"r\")))\n",
      "((9077, (280, 313, 272)), (\"e\", (\"r\", \"r\", \"r\")))\n"
     ]
    }
   ],
   "source": [
    "using MLUtils;\n",
    "using .KGDataset\n",
    "\n",
    "train_flatten_queries = flatten_query(train_queries);\n",
    "println(\"length of train_flatten_queries: \" * \"$(length(train_flatten_queries))\")\n",
    "println(\"length of train_answers: \" * \"$(length(train_answers))\")\n",
    "negative_sample_size = 512\n",
    "batch_size = 128\n",
    "nentity=sum([length(q) for q in train_flatten_queries])\n",
    "nrelation=sum([length(q) for q in train_flatten_queries])\n",
    "data_set = KGDataset.TrainDataset(train_flatten_queries, train_answers, nentity, nrelation, negative_sample_size);\n",
    "#DataLoader(data; [batchsize, buffer, collate, parallel, partial, rng, shuffle])\n",
    "data_loader = MLUtils.DataLoader(data_set, batchsize = batch_size, collate = true, shuffle=false);\n",
    "println(typeof(data_loader.data))\n",
    "println(\"numobs, getobs.....\")\n",
    "train_path_iterator = SingleDirectionalOneShotIterator(data_loader);\n",
    "\n",
    "data_index = 1\n",
    "for item in train_path_iterator\n",
    "    println(item)\n",
    "    data_index += 1\n",
    "    if data_index >= 10\n",
    "        break\n",
    "    end\n",
    "end\n",
    "\n",
    "(item, next)  = iterate(train_path_iterator,data_index)\n",
    "println(item)\n",
    "\n",
    "(item, next)  = iterate(train_path_iterator, next)\n",
    "println(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34bd7e27-170a-4a7d-836e-18e03b0c89c5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module KGModule.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Main.KGModule"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module KGModule\n",
    "\n",
    "export Identity, normDims, BoxOffsetIntersection, CenterIntersection, BetaIntersection,\n",
    "        BetaProjection, Regularizer, KGReasoning\n",
    "\n",
    "using Flux;\n",
    "using Zygote;\n",
    "using Statistics;\n",
    "using Distributions;\n",
    "using MLUtils;\n",
    "\n",
    "function Identity(x)\n",
    "    return x;\n",
    "end\n",
    "\n",
    "function normDims(itr, p::Real=2; dim)\n",
    "    sum(itr .^ p; dims=dim).^(1 / p)\n",
    "end\n",
    "\n",
    "struct BoxOffsetIntersection\n",
    "    dim::Int\n",
    "    layer1::Flux.Dense\n",
    "    layer2::Flux.Dense\n",
    "end\n",
    "\n",
    "function BoxOffsetIntersection(dim::Int)\n",
    "    layer1 = Flux.Dense(dim => dim);\n",
    "    layer2 = Flux.Dense(dim => dim);\n",
    "    \n",
    "    return BoxOffsetIntersection(dim, layer1, layer2);\n",
    "end\n",
    "\n",
    "#Function-like Object\n",
    "function (m::BoxOffsetIntersection)(embeddings)\n",
    "    @show embeddings\n",
    "    layer1_act = Flux.relu(m.layer1(embeddings))\n",
    "    @show layer1_act\n",
    "    layer1_mean = mean(layer1_act, dims=length(size(layer1_act)))\n",
    "    @show layer1_mean\n",
    "    gate = Flux.sigmoid(m.layer2(layer1_mean))\n",
    "    @show gate\n",
    "    offset = minimum(embeddings, dims=length(size(layer1_act)))\n",
    "\n",
    "    return offset .* gate\n",
    "end\n",
    "\n",
    "Flux.@functor BoxOffsetIntersection\n",
    "\n",
    "struct CenterIntersection\n",
    "    dim::Int\n",
    "    layer1::Flux.Dense\n",
    "    layer2::Flux.Dense\n",
    "end\n",
    "\n",
    "function CenterIntersection(dim::Int)\n",
    "        layer1 = Flux.Dense(dim => dim)\n",
    "        layer2 = Flux.Dense(dim => dim)\n",
    "\n",
    "        #Flux.Dense is initialized by  xavier defaultly\n",
    "        return CenterIntersection(dim, layer1, layer2)\n",
    "end\n",
    "\n",
    "function (m::CenterIntersection)(embeddings)\n",
    "        layer1_act = Flux.relu(m.layer1(embeddings)) # ( dim, num_conj)\n",
    "        attention = Flux.softmax(m.layer2(layer1_act), dims=length(size(layer1_act))) # (dim, num_conj, )\n",
    "        embedding = sum(attention * embeddings, dims=length(size(layer1_act)))\n",
    "\n",
    "        return embedding\n",
    "end\n",
    "\n",
    "Flux.@functor CenterIntersection\n",
    "\n",
    "struct BetaIntersection\n",
    "    dim::Int\n",
    "    layer1::Flux.Dense\n",
    "    layer2::Flux.Dense\n",
    "end\n",
    "\n",
    "function BetaIntersection(dim::Int)\n",
    "    layer1 = Flux.Dense(2 * dim, 2 * dim)\n",
    "    layer2 = Flux.Dense(2 * dim, dim)\n",
    "\n",
    "    return BetaIntersection(dim, layer1, layer2)\n",
    "end\n",
    "\n",
    "Flux.@functor BetaIntersection\n",
    "\n",
    "function (m::BetaIntersection)(alpha_embeddings, beta_embeddings)\n",
    "    all_embeddings = cat(length(size(alpha_embeddings)), alpha_embeddings, beta_embeddings)\n",
    "    layer1_act = Flux.relu(layer1(all_embeddings)) # (num_conj, batch_size, 2 * dim)\n",
    "    attention = Flux.softmax(layer2(layer1_act), dims=length(size(alpha_embeddings))) # (num_conj, batch_size, dim)\n",
    "\n",
    "    alpha_embedding = sum(attention * alpha_embeddings, dims=length(size(alpha_embeddings)))\n",
    "    beta_embedding = sum(attention * beta_embeddings, dims=length(size(alpha_embeddings)))\n",
    "\n",
    "    return alpha_embedding, beta_embedding\n",
    "end\n",
    "\n",
    "Flux.@functor BetaIntersection\n",
    "\n",
    "struct BetaProjection\n",
    "    entity_dim::Int\n",
    "    relation_dim::Int\n",
    "    hidden_dim::Int\n",
    "    num_layers::Int\n",
    "    layer1::Flux.Dense\n",
    "    layer0::Flux.Dense\n",
    "    hidden_layers::Dict{String, Flux.Dense}\n",
    "    projection_regularizer\n",
    "end\n",
    "\n",
    "function BetaProjection(entity_dim, relation_dim, hidden_dim, projection_regularizer, num_layers)\n",
    "    layer1 = Flux.Dense(entity_dim + relation_dim, hidden_dim) # 1st layer\n",
    "    layer0 = Flux.Dense(hidden_dim, entity_dim) # final layer\n",
    "        \n",
    "    hidden_layers = Dict{String, Flux.Dense}()\n",
    "    for nl in range(2, num_layers + 1)\n",
    "        hidden_layers(\"layer$nl\".format(nl), Flux.Dense(hidden_dim, hidden_dim))\n",
    "    end\n",
    "    \n",
    "    return BetaProjection(entity_dim, relation_dim, hidden_dim, num_layers, \n",
    "                layer1, layer0, hidden_layers, projection_regularizer)\n",
    "\n",
    "end\n",
    "        \n",
    "function (m::BetaProjection)(e_embedding, r_embedding)\n",
    "    x = cat(1, e_embedding, r_embedding)\n",
    "    for nl in range(1, m.num_layers + 1)\n",
    "        x = Flux.relu(getattr(self, \"layer{}\".format(nl))(x))\n",
    "    end\n",
    "    x = m.layer0(x)\n",
    "    x = m.projection_regularizer(x)\n",
    "\n",
    "    return x\n",
    "end\n",
    "\n",
    "Flux.@functor BetaProjection\n",
    "\n",
    "struct Regularizer\n",
    "    base_add::Int\n",
    "    min_val::Int\n",
    "    max_val::Int\n",
    "end\n",
    "\n",
    "function (m::Regularizer)(entity_embedding)\n",
    "    return clamp(entity_embedding + self.base_add, self.min_val, self.max_val)\n",
    "end\n",
    "\n",
    "Flux.@functor Regularizer\n",
    "\n",
    "struct KGReasoning\n",
    "    nentity::Int\n",
    "    nrelation::Int\n",
    "    hidden_dim::Int\n",
    "    epsilon::Float16\n",
    "    geo::String\n",
    "    use_cuda::Bool\n",
    "    batch_entity_range #TODO type and initialize\n",
    "    query_name_dict::Dict{Tuple, String}\n",
    "    ############################################\n",
    "    gamma # nn.Parameter\n",
    "    embedding_range # nn.Parameter\n",
    "    \n",
    "    entity_dim::Int\n",
    "    relation_dim::Int\n",
    "    \n",
    "    entity_embedding # nn.Parameter\n",
    "    cen\n",
    "    func\n",
    "    entity_regularizer\n",
    "    projection_regularizer\n",
    "    \n",
    "    offset_embedding\n",
    "    center_net\n",
    "    offset_net\n",
    "    #hidden_dim\n",
    "    num_layers\n",
    "    #center_net\n",
    "    projection_net\n",
    "end\n",
    "\n",
    "function KGReasoning(nentity, \n",
    "                    nrelation, \n",
    "                    hidden_dim, \n",
    "                    gamma, \n",
    "                    geo, \n",
    "                    test_batch_size=1,\n",
    "                    box_mode=nothing, \n",
    "                    beta_mode=nothing,\n",
    "                    query_name_dict=nothing, \n",
    "                    use_cuda=False)\n",
    "    nentity = nentity\n",
    "    nrelation = nrelation\n",
    "    hidden_dim = hidden_dim\n",
    "    epsilon = 2.0\n",
    "    sgeo = geo\n",
    "    use_cuda = use_cuda\n",
    "    batch_entity_range = repeat(convert.(Float32, range(0, nentity - 1)), 1, test_batch_size)\n",
    "\n",
    "    gamma = Zygote.Params([gamma])\n",
    "    embedding_range = Zygote.Params([(gamma .+ epsilon) / hidden_dim]);\n",
    "\n",
    "    entity_dim = hidden_dim\n",
    "    relation_dim = hidden_dim\n",
    "\n",
    "    activation, cen, func = repeat([nothing], 3)\n",
    "    entity_embedding , entity_regularizer, projection_regularizer = repeat([nothing], 3)\n",
    "    if geo == \"box\"\n",
    "        entity_embedding = Zygote.Params(zeros(nentity, entity_dim)) # centor for entities\n",
    "        activation, cen = box_mode\n",
    "        cen = cen # hyperparameter that balances the in-box distance and the out-box distance\n",
    "        if activation == \"none\"\n",
    "            func = Identity;\n",
    "        elseif activation == \"relu\"\n",
    "            func = Flux.relu;\n",
    "        elseif activation == \"softplus\"\n",
    "            func = Flux.softplus;\n",
    "        end\n",
    "    elseif geo == \"vec\"\n",
    "        #entity_embedding = Flux.params(zeros(nentity, entity_dim)) # center for entities\n",
    "        entity_embedding = Zygote.Params(Flux.glorot_uniform(nentity, entity_dim))\n",
    "    elseif geo == \"beta\"\n",
    "        #entity_embedding = Flux.params(zeros(nentity, self.entity_dim * 2)) # alpha and beta\n",
    "        entity_embedding = Zygote.Params(Flux.glorot_uniform(nentity, entity_dim * 2))\n",
    "        entity_regularizer = Regularizer(1, 0.05, 1e9) # make sure the parameters of beta embeddings are positive\n",
    "        projection_regularizer = Regularizer(1, 0.05, 1e9) # make sure the parameters of beta embeddings after relation projection are positive\n",
    "    end\n",
    "    #nn.init.uniform_(\n",
    "    #    tensor=self.entity_embedding,\n",
    "    #    ###########################TODO##################################\n",
    "    #    a = -embedding_range, \n",
    "    #    b = embedding_range\n",
    "    #)\n",
    "    #relation_embedding = Flux.params(zeros(nrelation, relation_dim))\n",
    "    relation_embedding = Zygote.Params(Flux.glorot_uniform(nrelation, relation_dim))\n",
    "    #nn.init.uniform_(\n",
    "    #    tensor=relation_embedding, \n",
    "    #    a = -embedding_range, \n",
    "    #    b = embedding_range\n",
    "    #)\n",
    "\n",
    "    num_layers, offset_embedding, center_net, offset_net, projection_net = repeat([nothing], 6)\n",
    "    if geo == \"box\"\n",
    "        offset_embedding = Zygote.Params(Flux.glorot_uniform(nrelation, entity_dim))\n",
    "        #self.offset_embedding = nn.Parameter(torch.zeros(nrelation, self.entity_dim))\n",
    "        #nn.init.uniform_(\n",
    "        #    tensor=self.offset_embedding,\n",
    "        #    a=0.,\n",
    "        #    b=self.embedding_range.item()\n",
    "        #)\n",
    "        center_net = CenterIntersection(entity_dim)\n",
    "        offset_net = BoxOffsetIntersection(entity_dim)\n",
    "    elseif geo == \"vec\"\n",
    "        center_net = CenterIntersection(entity_dim)\n",
    "    elseif geo == \"beta\"\n",
    "        hidden_dim, num_layers = beta_mode\n",
    "        center_net = BetaIntersection(entity_dim)\n",
    "        projection_net = BetaProjection(entity_dim * 2, \n",
    "                                        relation_dim,\n",
    "                                        hidden_dim, \n",
    "                                        projection_regularizer, \n",
    "                                        num_layers)\n",
    "    end\n",
    "\n",
    "    return KGReasoning(nentity, nrelation, hidden_dim, epsilon, geo, use_cuda, batch_entity_range,\n",
    "                       query_name_dict, gamma, embedding_range, entity_dim, relation_dim, entity_embedding,\n",
    "                       cen, func, entity_regularizer, projection_regularizer, offset_embedding,\n",
    "                       center_net, offset_net, num_layers, projection_net);\n",
    "end\n",
    "\n",
    "function forward(m::KGReasoning, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    if m.geo == \"box\"\n",
    "        return forward_box(m, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    elseif m.geo == \"vec\"\n",
    "        return forward_vec(m, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    elseif m.geo == \"beta\"\n",
    "        return forward_beta(m, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    end\n",
    "end\n",
    "\n",
    "####\n",
    "# embed a batch of queries with same structure using Query2box\n",
    "# queries: a flattened batch of queries\n",
    "####\n",
    "function embed_query_box(m::KGReasoning, queries, query_structure, idx)\n",
    "    #@printf (queries)\n",
    "    #@printf (query_structure)\n",
    "    all_relation_flag = true\n",
    "     # whether the current query tree has mfferged to one branch and only need to do relation traversal,\n",
    "     # e.g., path queries or conjunctive queries after the intersection\n",
    "    for ele in last(query_structure)\n",
    "        if ele not in [\"r\", \"n\"]\n",
    "            all_relation_flag = false\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    if all_relation_flag\n",
    "        if query_structure[0] == \"e\"\n",
    "            embedding = m.entity_embedding[:, queries[:, idx]]\n",
    "            #embedding = torch.index_select(m.entity_embedding, dim=0, index=queries[:, idx])\n",
    "            offset_embedding = zeros(size(embedding))\n",
    "            if m.use_cuda\n",
    "                offset_embedding = zeros(size(embedding)) .|> gpu\n",
    "            end\n",
    "            idx += 1\n",
    "        else\n",
    "            embedding, offset_embedding, idx = embed_query_box(m, queries, query_structure[0], idx)\n",
    "        end\n",
    "\n",
    "        for i in range(1, length(last(query_structure)))\n",
    "            if last(query_structure)[i] == \"n\"\n",
    "                @assert false \"box cannot handle queries with negation\"\n",
    "            else\n",
    "                r_embedding = m.ralation_embedding[:, queries[:, idx]]\n",
    "                #r_embedding = torch.index_select(self.relation_embedding, dim=0, index=queries[:, idx])\n",
    "                r_offset_embedding = offset_bedding[:, queries[:, idx]]\n",
    "                #r_offset_embedding = torch.index_select(self.offset_embedding, dim=0, index=queries[:, idx])\n",
    "                embedding += r_embedding\n",
    "                offset_embedding += m.func(r_offset_embedding)\n",
    "            end\n",
    "            idx += 1\n",
    "        end\n",
    "    else\n",
    "        embedding_list = []\n",
    "        offset_embedding_list = []\n",
    "        for i in range(1, length(query_structure))\n",
    "            embedding, offset_embedding, idx = embed_query_box(m, queries, query_structure[i], idx)\n",
    "            push!(embedding_list, embedding)\n",
    "            push!(offset_embedding_list, offset_embedding)\n",
    "        end\n",
    "        embedding = m.center_net(vcat(embedding_list))\n",
    "        offset_embedding = m.offset_net(vcat(offset_embedding_list))\n",
    "    end\n",
    "    return embedding, offset_embedding, idx\n",
    "end\n",
    "\n",
    "#=\n",
    "Iterative embed a batch of queries with same structure using GQE\n",
    "queries: a flattened batch of queries\n",
    "=#\n",
    "function embed_query_vec(m::KGReasoning, queries, query_structure, idx)\n",
    "        \n",
    "    all_relation_flag = true\n",
    "    for ele in last(query_structure) # whether the current query tree has merged to one branch and only need to do relation traversal, e.g., path queries or conjunctive queries after the intersection\n",
    "        if !(ele in [\"r\", \"n\"])\n",
    "            all_relation_flag = false\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    if all_relation_flag\n",
    "        if query_structure[1] == \"e\"\n",
    "            embedding = m.entity_embedding[:,queries[:, idx]]\n",
    "            #embedding = torch.index_select(self.entity_embedding, dim=0, index=queries[:, idx])\n",
    "            idx += 1\n",
    "        else\n",
    "            embedding, idx = embed_query_vec(m, queries, query_structure[0], idx)\n",
    "        end\n",
    "                \n",
    "        for i in range(length(last(query_structure)))\n",
    "            if last(query_structure)[i] == \"n\"\n",
    "                @assert false  \"vec cannot handle queries with negation\"\n",
    "            else\n",
    "                r_embedding = m.relation_embedding[:, queries[:, idx]]\n",
    "                #r_embedding = torch.index_select(self.relation_embedding, dim=0, index=queries[:, idx])\n",
    "                embedding += r_embedding\n",
    "            end\n",
    "            idx += 1\n",
    "        end\n",
    "    else\n",
    "        embedding_list = []\n",
    "        for i in range(1, length(query_structure))\n",
    "            embedding, idx = embed_query_vec(m, queries, query_structure[i], idx)\n",
    "            push!(dembedding_list, embedding)\n",
    "        end\n",
    "        embedding = m.center_net(vcat(embedding_list))\n",
    "    end\n",
    "    return embedding, idx\n",
    "end\n",
    "\n",
    "#=\n",
    "Iterative embed a batch of queries with same structure using BetaE\n",
    "queries: a flattened batch of queries\n",
    "=#\n",
    "function embed_query_beta(m::KGReasoning, queries, query_structure, idx)\n",
    "\n",
    "    all_relation_flag = True\n",
    "    for ele in last(query_structure) # whether the current query tree has merged to one branch and only need to do relation traversal, e.g., path queries or conjunctive queries after the intersection\n",
    "        if !(ele in [\"r\", \"n\"])\n",
    "            all_relation_flag = false\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    if all_relation_flag\n",
    "        if query_structure[1] == \"e\"\n",
    "            embedding = m.entity_regularizer(selectdim(m.entity_embedding, dims=ndims(m.entity_embedding), queries[:, idx]))\n",
    "            #embedding = m.entity_regularizer(torch.index_select(self.entity_embedding, dim=0, index=queries[:, idx]))\n",
    "            idx += 1\n",
    "        else\n",
    "            alpha_embedding, beta_embedding, idx = m.embed_query_beta(m, queries, query_structure[1], idx)\n",
    "            embedding = cat(alpha_embedding, beta_embedding, dim=0)\n",
    "        end\n",
    "        for i in range(1, length(last(query_structure)))\n",
    "            if last(query_structure)[i] == \"n\"\n",
    "                @assert (queries[:, idx] == -2).all()\n",
    "                embedding = 1 ./ embedding\n",
    "            else\n",
    "                r_embedding = m.relation_embedding(queries[:, idx], :)\n",
    "                #r_embedding = torch.index_select(self.relation_embedding, dim=0, index=queries[:, idx])\n",
    "                embedding = m.projection_net(embedding, r_embedding)\n",
    "            end\n",
    "            idx += 1\n",
    "        end\n",
    "        ###############################TODO####################################\n",
    "        alpha_embedding, beta_embedding = chunk(embedding, 2, dim=ndims(embedding))\n",
    "    else\n",
    "        alpha_embedding_list = []\n",
    "        beta_embedding_list = []\n",
    "        for i in range(1, length(query_structure))\n",
    "            alpha_embedding, beta_embedding, idx = embed_query_beta(m, queries, query_structure[i], idx)\n",
    "            push!(alpha_embedding_list, alpha_embedding)\n",
    "            push!(beta_embedding_list, beta_embedding)\n",
    "        end\n",
    "        alpha_embedding, beta_embedding = m.center_net(cat(alpha_embedding_list), cat(beta_embedding_list))\n",
    "    end\n",
    "    return alpha_embedding, beta_embedding, idx\n",
    "end\n",
    "\n",
    "#============================================\n",
    "    transform 2u queries to two 1p queries\n",
    "    transform up queries to two 2p queries\n",
    "============================================#\n",
    "function transform_union_query(m::KGReasoning, queries, query_structure)\n",
    "\n",
    "    if m.query_name_dict[query_structure] == \"2u-DNF\"\n",
    "        queries = queries[:, 1:(size(queries, 2) - 1)] # remove union -1\n",
    "    elseif m.query_name_dict[query_structure] == \"up-DNF\"\n",
    "        queries = cat(cat(queries[:, 1:2], queries[:, 5:6], dims=1), cat(queries[:, 2:4], queries[:, 5:6], dims=1), dims=1)\n",
    "    end\n",
    "    queries = reshape(queries, :, size(queries)[1]*2)\n",
    "    return queries\n",
    "end\n",
    "\n",
    "function transform_union_structure(m::KGReasoning, query_structure)\n",
    "    if m.query_name_dict[query_structure] == \"2u-DNF\"\n",
    "        return (\"e\", (\"r\",))\n",
    "    elseif m.query_name_dict[query_structure] == \"up-DNF\"\n",
    "        return (\"e\", (\"r\", \"r\"))\n",
    "    end\n",
    "end\n",
    "\n",
    "function cal_logit_beta(m::KGReasoning, entity_embedding, query_dist)\n",
    "    ##########################TODO#######################################\n",
    "    alpha_embedding, beta_embedding = chunk(entity_embedding, 2)\n",
    "    entity_dist = Distributions.Beta(alpha_embedding, beta_embedding)\n",
    "    logit = m.gamma - normDims(Distributions.KLDivergence(entity_dist, query_dist), 1)\n",
    "    return logit\n",
    "end\n",
    "\n",
    "function forward_beta(m::KGReasoning, positive_sample, negative_sample, subsampling_weight,\n",
    "                      batch_queries_dict, batch_idxs_dict)\n",
    "    all_idxs, all_alpha_embeddings, all_beta_embeddings = [], [], []\n",
    "    all_union_idxs, all_union_alpha_embeddings, all_union_beta_embeddings = [], [], []\n",
    "    for query_structure in batch_queries_dict\n",
    "        if \"u\" in m.query_name_dict[query_structure] && \"DNF\" in m.query_name_dict[query_structure]\n",
    "            alpha_embedding, beta_embedding, _ = \\\n",
    "                embed_query_beta(m, transform_union_query(m, batch_queries_dict[query_structure], \n",
    "                                                            query_structure), \n",
    "                                 transform_union_structure(m, query_structure), \n",
    "                                 0)\n",
    "            push!(all_union_idxs, batch_idxs_dict[query_structure])\n",
    "            #all_union_idxs.extend(batch_idxs_dict[query_structure])\n",
    "            push!(all_union_alpha_embeddings, alpha_embedding)\n",
    "            push!(all_union_beta_embeddings, beta_embedding)\n",
    "        else\n",
    "            alpha_embedding, beta_embedding, _ = embed_query_beta(m, batch_queries_dict[query_structure], \n",
    "                                                                  query_structure, \n",
    "                                                                  0)\n",
    "            push!(all_idxs, batch_idxs_dict[query_structure])\n",
    "            #all_idxs.extend(batch_idxs_dict[query_structure])\n",
    "            push!(all_alpha_embeddings, alpha_embedding)\n",
    "            push!(all_beta_embeddings, beta_embedding)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if length(all_alpha_embeddings) > 0\n",
    "        #all_alpha_embeddings = torch.cat(all_alpha_embeddings, dim=0).unsqueeze(1)\n",
    "        all_alpha_embeddfings = reduce((x, y) -> cat(x, y, dims=ndims(x)), all_alpha_embeddings)\n",
    "        all_beta_embeddings = reduce(all_beta_embeddings) do x, y\n",
    "                                         cat(x, y, dims=ndims(x))\n",
    "                                     end\n",
    "        all_beta_embeddings= unsqueeze(all_beta_embeddings, dims = ndims(all_beta_embeddings))\n",
    "        all_dists = Distributions.Beta(all_alpha_embeddings, all_beta_embeddings)\n",
    "    end\n",
    "\n",
    "    if len(all_union_alpha_embeddings) > 0\n",
    "        #all_union_alpha_embeddings = torch.cat(all_union_alpha_embeddings, dim=0).unsqueeze(1)\n",
    "        #all_union_beta_embeddings = torch.cat(all_union_beta_embeddings, dim=0).unsqueeze(1)\n",
    "        #all_union_alpha_embeddings = all_union_alpha_embeddings.view(all_union_alpha_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        #all_union_beta_embeddings = all_union_beta_embeddings.view(all_union_beta_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        #all_union_dists = torch.distributions.beta.Beta(all_union_alpha_embeddings, all_union_beta_embeddings)\n",
    "        all_union_alpha_embeddings = reduce(all_union_alpha_embeddings) do x, y\n",
    "                                             cat(x, y, dim=ndims(x))\n",
    "                                         end\n",
    "        #all_union_alpha_embeddings = cat(all_union_alpha_embeddings, dims = ndims(all_union_alpha_embeddings) + 1)\n",
    "        all_union_alpha_embeddings = unsqueeze(all_union_alpha_embeddings, dims = ndims(all_union_alpha_embeddings))\n",
    "        all_union_beta_embeddings = reduce(all_union_beta_embeddings) do x, y\n",
    "                                             cat(x, y, dim=ndims(x))\n",
    "                                         end\n",
    "        all_union_beta_embeddings = unsqueeze(all_union_beta_embeddings, dims = ndims(all_union_beta_embeddings))\n",
    "        #################################################################################################\n",
    "        #all_union_alpha_embeddings = all_union_alpha_embeddings.view(all_union_alpha_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        #all_union_beta_embeddings = all_union_beta_embeddings.view(all_union_beta_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        all_union_alpha_embeddings = reshape(all_union_alpha_embeddings, :, 1, 2,\n",
    "                                             div(size(all_union_alpha_embeddings, ndims(all_union_alpha_embedding)), 2))\n",
    "        all_union_beta_embeddings = reshape(all_union_beta_embeddings, :, 1, 2,\n",
    "                                             div(size(all_union_beta_embeddings, ndims(all_union_beta_embedding)), 2))\n",
    "\n",
    "        all_union_dists = Distributions.Beta(all_union_alpha_embeddings, all_union_beta_embeddings)\n",
    "    end\n",
    "                                                                                    \n",
    "    if typeof(subsampling_weight) != typeof(nothing)\n",
    "        subsampling_weight = subsampling_weight[all_idxs+all_union_idxs]\n",
    "    end\n",
    "\n",
    "    if typeof(positive_sample) != type(None)\n",
    "        if length(all_alpha_embeddings) > 0\n",
    "            positive_sample_regular = positive_sample[all_idxs] # positive samples for non-union queries in this batch\n",
    "            entity_embedding_select = selectdim(m.entity_embedding,\n",
    "                                                ndims(m.entity_embedding),\n",
    "                                                positive_sample_regular);\n",
    "            positive_embedding = m.entity_regularizer(unsqueeze(entity_embedding_select,\n",
    "                                                                ndims(entity_embedding_select)))\n",
    "            positive_logit = cal_logit_beta(m, positive_embedding, all_dists)\n",
    "        else\n",
    "            positive_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_alpha_embeddings) > 0\n",
    "            positive_sample_union = positive_sample[all_union_idxs] # positive samples for union queries in this batch\n",
    "            \n",
    "            entity_embedding_select = selectdim(m.entity_embedding, \n",
    "                                                ndims(m.entity_embedding), \n",
    "                                                positive_sample_union);\n",
    "            entity_embedding_select_unsqueeze = unsqueeze(entity_embedding_select, \n",
    "                                                        dims=ndims(entity_embedding_select) - 1);\n",
    "            positive_embedding = m.entity_regularizer(entity_embedding_select_unsqueeze)\n",
    "            positive_union_logit = cal_logit_beta(m, positive_embedding, all_union_dists)\n",
    "            positive_union_logit = max(positive_union_logit, dim=1)[0]\n",
    "        else\n",
    "            positive_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "        positive_logit = cat(positive_logit, positive_union_logit, dims=ndims(positive_logit))\n",
    "    else\n",
    "        positive_logit = nothing\n",
    "    end\n",
    "\n",
    "    if typeof(negative_sample) != typeof(nothing)\n",
    "        if length(all_alpha_embeddings) > 0\n",
    "            negative_sample_regular = negative_sample[all_idxs]\n",
    "            batch_size, negative_size = negative_sample_regular.shape\n",
    "            #negative_embedding = self.entity_regularizer(torch.index_select(self.entity_embedding, dim=0, index=negative_sample_regular.view(-1)).view(batch_size, negative_size, -1))\n",
    "            negative_embedding = m.entity_regularizer(reshape(reshape(selectdim(m.entity_embedding, ndims(m.entity_embedding), negative_sample_regular), :), :, negative_size, batch_size))\n",
    "            negative_logit = cal_logit_beta(m, negative_embedding, all_dists)\n",
    "        else\n",
    "            ########################## TODO ##################################\n",
    "            #negative_logit = torch.Tensor([]).to(self.entity_embedding.device)\n",
    "            negative_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_alpha_embeddings) > 0\n",
    "            negative_sample_union = negative_sample[all_union_idxs]\n",
    "            batch_size, negative_size = size(negative_sample_union)\n",
    "            negative_embedding = m.entity_regularizer(reshape(reshape(selectdim(m.entity_embedding, 0, negative_sample_union), :), (:, negative_size, 1, batch_size)))\n",
    "            negative_union_logit = cal_logit_beta(m, negative_embedding, all_union_dists)\n",
    "            negative_union_logit = max(negative_union_logit, dim=2)[0]\n",
    "        else\n",
    "            ######################### TODO  ###################################\n",
    "            negative_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        negative_logit = cat(negative_logit, negative_union_logit, dim=ndims(negative_logit))\n",
    "    else\n",
    "        negative_logit = nothing\n",
    "    end\n",
    "\n",
    "    return positive_logit, negative_logit, subsampling_weight, all_idxs+all_union_idxs\n",
    "end\n",
    "\n",
    "function cal_logit_box(m::KGReasoning, entity_embedding, query_center_embedding, query_offset_embedding)\n",
    "    delta = abs(entity_embedding - query_center_embedding)\n",
    "    distance_out = Flux.relu(delta - query_offset_embedding)\n",
    "    distance_in = min(delta, query_offset_embedding)\n",
    "    logit = m.gamma - normDims(distance_out, 1; dims=0) - m.cen * normDims(distance_in, 1, dims=0)\n",
    "    return logit\n",
    "end\n",
    "\n",
    "function forward_box(m::KGReasoning, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    all_center_embeddings, all_offset_embeddings, all_idxs = [], [], []\n",
    "    all_union_center_embeddings, all_union_offset_embeddings, all_union_idxs = [], [], []\n",
    "    for query_structure in batch_queries_dict\n",
    "        if \"u\" in self.query_name_dict[query_structure]\n",
    "            center_embedding, offset_embedding, _ = \\\n",
    "                embed_query_box(m, m.transform_union_query(batch_queries_dict[query_structure], \n",
    "                                                                query_structure), \n",
    "                                transform_union_structure(m, query_structure), \n",
    "                                0)\n",
    "            push!(all_union_center_embeddings, center_embedding)\n",
    "            push!(all_union_offset_embeddings, offset_embedding)\n",
    "            push!(all_union_idxs, batch_idxs_dict[query_structure])\n",
    "        else\n",
    "            center_embedding, offset_embedding, _ = embed_query_box(m, batch_queries_dict[query_structure], \n",
    "                                                                    query_structure, \n",
    "                                                                    0)\n",
    "            push!(all_center_embeddings, center_embedding)\n",
    "            push!(all_offset_embeddings, offset_embedding)\n",
    "            push!(all_idxs, batch_idxs_dict[query_structure])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if length(all_center_embeddings) > 0 && length(all_offset_embeddings) > 0\n",
    "        all_center_embeddings_cat = reduce(all_center_embeddings) do x, y\n",
    "                                          cat(x, y, dims=ndims(x))\n",
    "                                    end\n",
    "        all_center_embeddings_cat_unsqueeze = unsqueeze(all_center_embeddings_cat,\n",
    "                                          dims = ndims(all_center_embeddings_cat) - 1)\n",
    "\n",
    "        all_offset_embeddings_cat = reduce(all_offset_embeddings) do x, y\n",
    "                                          cat(x, y, dims=ndims(x))\n",
    "                                    end\n",
    "        all_offset_embeddings_cat_unsqueeze = unsqueeze(all_offset_embeddings_cat,\n",
    "                                                        dims = ndims(all_offset_embeddings_cat) - 1)\n",
    "        #all_offset_embeddings = torch.cat(all_offset_embeddings, dim=0).unsqueeze(1)\n",
    "    end\n",
    "\n",
    "    if length(all_union_center_embeddings) > 0 && length(all_union_offset_embeddings) > 0\n",
    "        #all_union_center_embeddings = torch.cat(all_union_center_embeddings, dim=0).unsqueeze(1)\n",
    "        #all_union_offset_embeddings = torch.cat(all_union_offset_embeddings, dim=0).unsqueeze(1)\n",
    "        all_union_center_embeddings_cat = reduce(all_union_center_embeddings) do x, y\n",
    "                                              cat(x, y, dims=ndims(x))\n",
    "                                          end\n",
    "        all_union_center_embeddings_cat_unsqueeze = unsqueeze(all_union_center_embeddings_cat,\n",
    "                                                              dims = ndims(all_union_center_embeddings_cat) - 1)\n",
    "        all_union_offset_embeddings_cat = reduce(all_union_offset_embeddings) do x, y\n",
    "                                              cat(x, y, dims=ndims(x))\n",
    "                                          end\n",
    "        all_union_offset_embeddings_cat_unsqueeze = unsqueeze(all_union_offset_embeddings_cat,\n",
    "                                                              dims = ndims(all_offset_embeddings_cat) - 1)\n",
    "        #all_union_center_embeddings = all_union_center_embeddings.view(all_union_center_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        #all_union_offset_embeddings = all_union_offset_embeddings.view(all_union_offset_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        all_union_center_embeddings = reshape(all_union_center_embeddings_cat_unsqueeze,\n",
    "                                              :, 1, 2, div(ndims(all_union_center_embeddings_cat_unsqueeze), 2))\n",
    "        all_union_offset_embeddings = reshape(all_union_offset_embeddings_cat_unsqueeze,\n",
    "                                              :, 1, 2, div(ndims(all_union_offset_embeddings_cat_unsqueeze), 2))\n",
    "    end\n",
    "\n",
    "    if typeof(subsampling_weight) != typeof(nothing)\n",
    "        subsampling_weight = subsampling_weight[all_idxs+all_union_idxs]\n",
    "    end\n",
    "\n",
    "    if typeof(positive_sample) != typeof(nothing)\n",
    "        if length(all_center_embeddings) > 0\n",
    "            positive_sample_regular = positive_sample[all_idxs]\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), positive_sample_regular)\n",
    "            positive_embedding = unsqueeze(entity_embedding_select, ndims(entity_embedding_select) - 1)\n",
    "            positive_logit = cal_logit_box(m, positive_embedding, all_center_embeddings, all_offset_embeddings)\n",
    "        else\n",
    "            #positive_logit = torch.Tensor([]).to(self.entity_embedding.device)\n",
    "            positive_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_center_embeddings) > 0\n",
    "            positive_sample_union = positive_sample[all_union_idxs]\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), positive_sample_union)\n",
    "            entity_embedding_select_unquezze = unsqueeze(entity_embedding_select, ndims(entity_embedding_select) - 1)\n",
    "            positive_embedding = unsqueeze(entity_embedding_select_unquezze, ndims(entity_embedding_select_unquezze) - 1)\n",
    "            positive_union_logit = cal_logit_box(m, positive_embedding, all_union_center_embeddings, all_union_offset_embeddings)\n",
    "            positive_union_logit = max(positive_union_logit, dims=ndims(positive_union_logit) - 1)[1]\n",
    "        else\n",
    "            #positive_union_logit = torch.Tensor([]).to(self.entity_embedding.device)\n",
    "            positive_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "        positive_logit = reduce([positive_logit, positive_union_logit]) do x, y\n",
    "                              cat(x, y, dim=ndims(x))\n",
    "                         end\n",
    "    else\n",
    "        positive_logit = nothing\n",
    "    end\n",
    "\n",
    "    if typeof(negative_sample) != typeof(nothing)\n",
    "        if len(all_center_embeddings) > 0\n",
    "            negative_sample_regular = negative_sample[all_idxs]\n",
    "            batch_size, negative_size = size(negative_sample_regular)\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), reshape(negative_sample_regular, :))\n",
    "            negative_embedding = reshape(entity_embedding_select, :, negative_size, batch_size)\n",
    "            negative_logit = cal_logit_box(m, negative_embedding, all_center_embeddings, all_offset_embeddings)\n",
    "        else\n",
    "            #negative_logit = torch.Tensor([]).to(self.entity_embedding.device)\n",
    "            negative_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_center_embeddings) > 0\n",
    "            negative_sample_union = negative_sample[all_union_idxs]\n",
    "            batch_size, negative_size = size(negative_sample_union)\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), reshape(negative_sample_union, :))\n",
    "            negative_embedding = reshape(entity_embedding_select, :, negative_size, 1, batch_size)\n",
    "            negative_union_logit = cal_logit_box(m, negative_embedding, all_union_center_embeddings, all_union_offset_embeddings)\n",
    "            negative_union_logit = max(negative_union_logit, dims=ndims(negative_union_logit) - 1)[1]\n",
    "        else\n",
    "            #negative_union_logit = torch.Tensor([]).to(self.entity_embedding.device)\n",
    "            negative_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "        negative_logit = reduce([negative_logit, negative_union_logit]) do x, y\n",
    "                              cat(x, y, dim=ndims(x))\n",
    "                         end\n",
    "    else\n",
    "        negative_logit = nothing\n",
    "    end\n",
    "\n",
    "    return positive_logit, negative_logit, subsampling_weight, all_idxs+all_union_idxs\n",
    "end\n",
    "\n",
    "function cal_logit_vec(m::KGReasoning, entity_embedding, query_embedding)\n",
    "    distance = entity_embedding - query_embedding\n",
    "    logit = m.gamma - normDims(distance, 1, dim=2)\n",
    "    return logit\n",
    "end\n",
    "\n",
    "function forward_vec(m::KGReasoning, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    all_center_embeddings, all_idxs = [], []\n",
    "    all_union_center_embeddings, all_union_idxs = [], []\n",
    "    for query_structure in batch_queries_dict\n",
    "        if \"u\" in self.query_name_dict[query_structure]\n",
    "            center_embedding, _ = embed_query_vec(m, transform_union_query(m, batch_queries_dict[query_structure], \n",
    "                                                                           query_structure), \n",
    "                                                  transform_union_structure(query_structure), 0)\n",
    "            push!(all_union_center_embeddings, center_embedding)\n",
    "            append!(all_union_idxs, batch_idxs_dict[query_structure])\n",
    "        else\n",
    "            center_embedding, _ = embed_query_vec(m, batch_queries_dict[query_structure], query_structure, 0)\n",
    "            push!(all_center_embeddings, center_embedding)\n",
    "            append!(all_idxs, batch_idxs_dict[query_structure])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if length(all_center_embeddings) > 0\n",
    "        all_center_embeddings_cat = reduce(all_center_embeddings) do x, y\n",
    "                                        cat(x, y, dims = ndims(x))\n",
    "                                    end\n",
    "        all_center_embeddings = unsqueeze(all_center_embeddings_cat, ndims(all_center_embeddings_cat) - 1)\n",
    "    end\n",
    "\n",
    "    if length(all_union_center_embeddings) > 0\n",
    "        all_union_center_embeddings_cat = reduce(all_union_center_embeddings) do x, y\n",
    "                                              cat(x, y, dims = ndims(x))\n",
    "                                          end\n",
    "        all_union_center_embeddings_unsqueeze = unsqueeze(all_union_center_embeddings_cat, ndims(all_union_center_embeddings_cat) - 1)\n",
    "        #all_union_center_embeddings = torch.cat(all_union_center_embeddings, dim=0).unsqueeze(1)\n",
    "        all_union_center_embeddings = reshape(all_union_center_embeddings_unsqueeze,\n",
    "                                              :, 1, 2, div(size(all_union_center_embeddings,\n",
    "                                                                ndims(all_union_center_embeddings)),\n",
    "                                                           2))\n",
    "    end\n",
    "\n",
    "    if typeof(subsampling_weight) != typeof(nothing)\n",
    "        subsampling_weight = subsampling_weight[all_idxs+all_union_idxs]\n",
    "    end\n",
    "\n",
    "    if typeof(positive_sample) != typeof(nothing)\n",
    "        if length(all_center_embeddings) > 0\n",
    "            positive_sample_regular = positive_sample[all_idxs]\n",
    "            positive_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), positive_sample_regular)\n",
    "            positive_embedding = unsqueeze(positive_embedding_select, ndims(positive_embedding_select) - 1)\n",
    "            positive_logit = cal_logit_vec(m, positive_embedding, all_center_embeddings)\n",
    "        else\n",
    "            positive_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_center_embeddings) > 0\n",
    "            positive_sample_union = positive_sample[all_union_idxs]\n",
    "            positive_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), positive_sample_regular)\n",
    "            positive_embedding_unsqueeze = unsqueeze(positive_embedding_select, ndims(positive_embedding_select) - 1)\n",
    "            positive_embedding = unsqueeze(positive_embedding_unsqueeze, ndims(positive_embedding_unsqueeze) - 1)\n",
    "            positive_union_logit = cal_logit_vec(m, positive_embedding, all_union_center_embeddings)\n",
    "            positive_union_logit = max(positive_union_logit, dims=ndims(positive_union_logit) - 1)[1]\n",
    "        else\n",
    "            positive_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "        positive_logit = reduce([positive_logit, positive_union_logit]) do x, y\n",
    "                             cat(x, y, dims=ndims(x))\n",
    "                         end\n",
    "    else\n",
    "        positive_logit = nothing\n",
    "    end\n",
    "\n",
    "    if typeof(negative_sample) != typeof(nothing)\n",
    "        if length(all_center_embeddings) > 0\n",
    "            negative_sample_regular = negative_sample[all_idxs]\n",
    "            batch_size, negative_size = size(negative_sample_regular)\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, 0, reshape(negative_sample_regular, :))\n",
    "            negative_embedding = reshape(entity_embedding_select, :, negative_size, batch_size)\n",
    "            negative_logit = cal_logit_vec(m, negative_embedding, all_center_embeddings)\n",
    "        else\n",
    "            negative_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_center_embeddings) > 0\n",
    "            negative_sample_union = negative_sample[all_union_idxs]\n",
    "            batch_size, negative_size = size(negative_sample_union)\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding, reshape(negative_sample_union, :)))\n",
    "            negative_embedding = reshape(entity_embedding_select, :, negtive_size, 1, batch_size)\n",
    "            negative_union_logit = cal_logit_vec(m, negative_embedding, all_union_center_embeddings)\n",
    "            negative_union_logit = max(negative_union_logit, dim=ndims(negative_union_logit) -1)[0]\n",
    "        else\n",
    "            negative_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        negative_logit = reduce([negative_logit, negative_union_logit]) do x, y\n",
    "                             cat(x, y, dim=ndims(x))\n",
    "                         end\n",
    "    else\n",
    "        negative_logit = nothing\n",
    "    end\n",
    "\n",
    "    return positive_logit, negative_logit, subsampling_weight, all_idxs+all_union_idxs\n",
    "end\n",
    "#=================================================================================\n",
    "function mean_loss(y_bar)\n",
    "    negative_logsigmoid = Flux.logsigmoid(-y_bar[:negative_logit])\n",
    "    negative_score = mean.(negative_logsigmoid, dims=ndims(negative_logsigmoid))\n",
    "    positive_logsigmoid =Flux.logsigmoid(-y_bar[:positive_logit]) \n",
    "    positive_score = squeeze(positive_logsigmoid, dim=ndims(positive_logsigmoid))\n",
    "    positive_sample_loss = - sum(y_bar[:subsampling_weight] * positive_score)\n",
    "    negative_sample_loss = - sum(y_bar[:subsampling_weight] * negative_score)\n",
    "    positive_sample_loss /= sum(y_bar[:subsampling_weight])\n",
    "    negative_sample_loss /= sum(y_bar[:subsampling_weight])\n",
    "\n",
    "    loss = (positive_sample_loss + negative_sample_loss)/2\n",
    "end\n",
    "===============================================================================#\n",
    "# @staticmethod\n",
    "function train_step(model, optimizer, train_iterator, args, step)\n",
    "    opti_stat = Flux.setup(model, optimizer)\n",
    "\n",
    "    opti_stat = Flux.train!(model, )\n",
    "\n",
    "    ########################################################################################################\n",
    "    #model.train() # set model as train mode\n",
    "    #optimizer.zero_grad() # clear grad, set to zero\n",
    "\n",
    "    positive_sample, negative_sample, subsampling_weight, batch_queries, query_structures = next(train_iterator)\n",
    "    #batch_queries_dict = collections.defaultdict(list)\n",
    "    #batch_idxs_dict = collections.defaultdict(list)\n",
    "    batch_queries_dict = Dict{Any, Any}()\n",
    "    batch_idxs_dict = Dict{Any, Any}()\n",
    "    for (i, query) in enumerate(batch_queries) # group queries with same structure\n",
    "        push!(get!(batch_queries_dict, query_structures[i], []), query)\n",
    "        push!(get!(batch_idxs_dict, query_structures[i], []), i)\n",
    "    end\n",
    "    for query_structure in batch_queries_dict\n",
    "        if args[\"cuda\"]\n",
    "            batch_queries_dict[query_structure] = Int64.(batch_queries_dict[query_structure]) .|> gpu\n",
    "        else\n",
    "            batch_queries_dict[query_structure] = Int64.(batch_queries_dict[query_structure])\n",
    "        end\n",
    "    end\n",
    "    if args[\"cuda\"]\n",
    "        positive_sample = positive_sample |> gpu\n",
    "        negative_sample = negative_sample |> gpu\n",
    "        subsampling_weight = subsampling_weight |> gpu\n",
    "    end\n",
    "\n",
    "    opt_grads = Flux.gradient(model) do m\n",
    "                       positive_logit, negative_logit, subsampling_weight, _ = model(positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "                       negative_logsigmoid = Flux.logsigmoid(negative_logit)\n",
    "                       negative_score = mean.(negative_logsigmoid, dims=ndims(negative_logsigmoid))\n",
    "                       positive_logsigmoid =Flux.logsigmoid(positive_logit) \n",
    "                       positive_score = squeeze(positive_logsigmoid, dim=ndims(positive_logsigmoid))\n",
    "                       positive_sample_loss = - sum(subsampling_weight * positive_score)\n",
    "                       negative_sample_loss = - sum(subsampling_weight * negative_score)\n",
    "                       positive_sample_loss /= sum(subsampling_weight)\n",
    "                       negative_sample_loss /= sum(subsampling_weight)\n",
    "\n",
    "                       loss = (positive_sample_loss + negative_sample_loss)/2\n",
    "                end\n",
    "#=========================================================================\n",
    "    negative_score = F.logsigmoid(-negative_logit).mean(dim=1)\n",
    "    positive_score = F.logsigmoid(positive_logit).squeeze(dim=1)\n",
    "    positive_sample_loss = - (subsampling_weight * positive_score).sum()\n",
    "    negative_sample_loss = - (subsampling_weight * negative_score).sum()\n",
    "    positive_sample_loss /= subsampling_weight.sum()\n",
    "    negative_sample_loss /= subsampling_weight.sum()\n",
    "\n",
    "    loss = (positive_sample_loss + negative_sample_loss)/2\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "==========================================================================#\n",
    "    log = Dict{\n",
    "        \"positive_sample_loss\": positive_sample_loss.item(),\n",
    "        \"negative_sample_loss\": negative_sample_loss.item(),\n",
    "        \"loss\": loss.item(),\n",
    "    }\n",
    "    return log\n",
    "end\n",
    "\n",
    "#@staticmethod\n",
    "function test_step(model, easy_answers, hard_answers, args, test_dataloader, query_name_dict, save_result=False, save_str=\"\", save_empty=False)\n",
    "#    model.eval()\n",
    "\n",
    "    step = 0\n",
    "    total_steps = length(test_dataloader)\n",
    "    #logs = collections.defaultdict(list)\n",
    "    logs = Dict()\n",
    "\n",
    "    #with torch.no_grad():\n",
    "    for (negative_sample, queries, queries_unflatten, query_structures) in tqdm(test_dataloader)\n",
    "        batch_queries_dict = Dict() #collections.defaultdict(list)\n",
    "        batch_idxs_dict = Dict() #collections.defaultdict(list)\n",
    "        for (i, query) in enumerate(queries)\n",
    "            push!(batch_queries_dict[query_structures[i]], query)\n",
    "            push!(batch_idxs_dict[query_structures[i]], i)\n",
    "        end\n",
    "\n",
    "        for query_structure in batch_queries_dict\n",
    "            if args[\"cuda\"]\n",
    "                batch_queries_dict[query_structure] = Int64.(batch_queries_dict[query_structure]) .|> gpu\n",
    "            else\n",
    "                batch_queries_dict[query_structure] = Int64.(batch_queries_dict[query_structure])\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if args[\"cuda\"]\n",
    "            negative_sample = negative_sample .|> gpu\n",
    "        end\n",
    "\n",
    "        _, negative_logit, _, idxs = model(None, negative_sample, None, batch_queries_dict, batch_idxs_dict)\n",
    "        queries_unflatten = [queries_unflatten[i] for i in idxs]\n",
    "        query_structures = [query_structures[i] for i in idxs]\n",
    "        argsort = sortperm(negative_logit, dim=ndims(negative_logit)-1, rev=true)\n",
    "        ranking = Float32.(copy(argsort))\n",
    "        if length(argsort) == args[\"test_batch_size\"] # if it is the same shape with test_batch_size, we can reuse batch_entity_range without creating a new one\n",
    "            #ranking = ranking.scatter_(1, argsort, model.batch_entity_range) # achieve the ranking of all entities\n",
    "            ranking = getindex(model.batch_entity_range, argsort)\n",
    "        else # otherwise, create a new torch Tensor for batch_entity_range\n",
    "            if args[\"cuda\"]\n",
    "                #ranking = ranking.scatter_(1, \n",
    "                #                           argsort, \n",
    "                #                           torch.arange(model.nentity).to(torch.float).repeat(argsort.shape[0], \n",
    "                #                                                                              1).cuda()\n",
    "                #                           ) # achieve the ranking of all entities\n",
    "                target = repeat(Float32.(collect(1:model.nentity)), 1, size(argsort, ndims(argsort)))\n",
    "                ranking = getindex(argsort, target) |> gpu\n",
    "            else\n",
    "                #ranking = ranking.scatter_(1, \n",
    "                #                           argsort, \n",
    "                #                           torch.arange(model.nentity).to(torch.float).repeat(argsort.shape[0], \n",
    "                #                                                                              1)\n",
    "                #                           ) # achieve the ranking of all entities\n",
    "                target = repeat(Float32.(collect(1:model.nentity)), 1, size(argsort, ndims(argsort)))\n",
    "                ranking = getindex(argsort, target)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        for (idx, (i, query, query_structure)) in enumerate(zip(argsort[:, ndims(argsort)], queries_unflatten, query_structures))\n",
    "            hard_answer = hard_answers[query]\n",
    "            easy_answer = easy_answers[query]\n",
    "            num_hard = length(hard_answer)\n",
    "            num_easy = length(easy_answer)\n",
    "            @assert length(hard_answer.intersection(easy_answer)) == 0\n",
    "            cur_ranking = ranking[idx, list(easy_answer) + list(hard_answer)]\n",
    "            cur_ranking, indices = sortperm(cur_ranking)\n",
    "            masks = indices >= num_easy\n",
    "            if args[\"cuda\"]\n",
    "                answer_list = Float32.(collect(1:(num_hard + num_easy))) .|> gpu\n",
    "            else\n",
    "                answer_list = Float32.(collect(1:(num_hard + num_easy)))\n",
    "            end\n",
    "            cur_ranking = cur_ranking .- answer_list + 1 # filtered setting\n",
    "            cur_ranking = cur_ranking[masks] # only take indices that belong to the hard answers\n",
    "\n",
    "            mrr = collect(mean(1 ./ cur_ranking))\n",
    "            h1 = collect(Float32.(mean((cur_ranking <= 1))))\n",
    "            h3 = collect(Float32.(mean((cur_ranking <= 3))))\n",
    "            h10 = collect(Float32.(mean((cur_ranking <= 10))))\n",
    "\n",
    "            push!(get!(logs, query_structure, Dict()), Dict(\n",
    "                \"MRR\"=> mrr,\n",
    "                \"HITS1\"=> h1,\n",
    "                \"HITS3\"=> h3,\n",
    "                \"HITS10\"=> h10,\n",
    "                \"num_hard_answer\"=> num_hard\n",
    "            ))\n",
    "        end\n",
    "\n",
    "        if step % args.test_log_steps == 0\n",
    "            @info(\"Evaluating the model... ($step/$total_steps)\")\n",
    "        end\n",
    "        step += 1\n",
    "    end\n",
    "\n",
    "    #metrics = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "    metrics = Dict()\n",
    "    for query_structure in logs\n",
    "        for metric in keys(logs[query_structure][0])\n",
    "            if metric in [\"num_hard_answer\"]\n",
    "                continue\n",
    "            end\n",
    "            metrics[:query_structure][:metric] = sum([log[metric] for log in logs[query_structure]])/length(logs[query_structure])\n",
    "        end\n",
    "        metrics[:query_structure][\"num_queries\"] = length(logs[query_structure])\n",
    "    end\n",
    "\n",
    "    return metrics\n",
    "end\n",
    "\n",
    "end #end module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d72ac1d9-3402-4f31-9c64-373b7fca53e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main (generic function with 1 method)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Revise\n",
    "\n",
    "import .KGDataset\n",
    "import .KGModule\n",
    "\n",
    "function main(args)\n",
    "    global train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers\n",
    "    \n",
    "    Random.seed!(args[\"seed\"])\n",
    "    tasks = split(args[\"tasks\"], \".\")\n",
    "    for task in tasks\n",
    "        if 'n' in task && args[\"geo\"] in [\"box\", \"vec\"]\n",
    "            @assert false \"Q2B and GQE cannot handle queries with negation\"\n",
    "        end\n",
    "    end\n",
    "    if args[\"evaluate_union\"] == \"DM\"\n",
    "        @assert args[\"geo\"] == \"beta\" \"only BetaE supports modeling union using De Morgan's Laws\"\n",
    "    end\n",
    "\n",
    "    cur_time = format_time()\n",
    "    if args[\"prefix\"] == nothing\n",
    "        prefix = \"logs\"\n",
    "    else\n",
    "        prefix = args[\"prefix\"]\n",
    "    end\n",
    "\n",
    "    @info (\"overwritting saving path: $(args[\"save_path\"])\")\n",
    "    args[\"save_path\"] = joinpath(prefix, last(split(args[\"data_path\"], \"/\")), args[\"tasks\"], args[\"geo\"])\n",
    "    geo = args[\"geo\"]\n",
    "    if geo in [\"box\"]\n",
    "        save_str = \"g-$(args[\"gamma\"])-mode-$(args[\"box_mode\"])\"\n",
    "    elseif geo in [\"vec\"]\n",
    "        save_str = \"g-$(args[\"gamma\"])\"\n",
    "    elseif geo == \"beta\"\n",
    "        save_str = \"g-$(args[\"gamma\"])-mode-$(args[\"beta_mode\"])\"\n",
    "    end\n",
    "\n",
    "    if args[\"checkpoint_path\"] != nothing\n",
    "            args[\"save_path\"] = args[\"checkpoint_path\"]\n",
    "    else\n",
    "        args[\"save_path\"] = joinpath(args[\"save_path\"], save_str, cur_time)\n",
    "    end\n",
    "\n",
    "    if ! ispath(args[\"save_path\"])\n",
    "        mkpath(args[\"save_path\"])\n",
    "    end\n",
    "\n",
    "    @info (\"logging to $(args[\"save_path\"])\")\n",
    "    if ! args[\"train\"] # if not training, then create tensorboard files in some tmp location\n",
    "        writer = TBLogger(\"./logs-debug/unused-tb\")\n",
    "    else\n",
    "        writer = TBLogger(args[\"save_path\"])\n",
    "    end\n",
    "    set_logger(args)\n",
    "\n",
    "    nentity, nrelation = open(joinpath(args[\"data_path\"], \"stats.txt\")) do f\n",
    "        entrel = readlines(f)\n",
    "        nentity = parse(Int, last(split(entrel[1], \" \")))\n",
    "        nrelation = parse(Int, last(split(entrel[2], \" \")))\n",
    "\n",
    "        (nentity, nrelation)\n",
    "    end\n",
    "\n",
    "    args[\"nentity\"] = nentity\n",
    "    args[\"nrelation\"] = nrelation\n",
    "\n",
    "    @info(repeat(\"-------------------------------\", 3))\n",
    "    @info(\"Geo: $(args[\"geo\"])\")\n",
    "    @info(\"Data Path: $(args[\"data_path\"])\")\n",
    "    @info(\"#entity: $(nentity)\")\n",
    "    @info(\"#relation: $(nrelation)\")\n",
    "    @info(\"#max steps: $(args[\"max_steps\"])\")\n",
    "    @info(\"Evaluate unoins using: $(args[\"evaluate_union\"])\")\n",
    "\n",
    "    #train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers = load_data(args, tasks, all_tasks, name_query_dict)\n",
    "\n",
    "    if args[\"train\"]\n",
    "        @info(\"Training ...\")\n",
    "#=         \n",
    "        for query_structure in keys(train_queries)\n",
    "            @info (query_name_dict[query_structure] * \": \" * \"$(length(train_queries[query_structure]))\")\n",
    "        end\n",
    "=#\n",
    "        train_path_queries = Dict{Any, Set}()\n",
    "        train_other_queries = Dict{Any, Set}()\n",
    "        query_path_list = [\"1p\", \"2p\", \"3p\"]\n",
    "        for query_structure in keys(train_queries)\n",
    "            if query_name_dict[query_structure] in query_path_list\n",
    "                train_path_queries[query_structure] = train_queries[query_structure]\n",
    "            else\n",
    "                train_other_queries[query_structure] = train_queries[query_structure]\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        train_path_queries = flatten_query(train_path_queries)\n",
    "        @info \"Flatten query length: $(length(train_path_queries)) typeof(query) $(typeof(train_path_queries))\"\n",
    "        \n",
    "        train_dataset = KGDataset.TrainDataset(train_path_queries, train_answers, nentity, nrelation, args[\"negative_sample_size\"])\n",
    "        data_loader = MLUtils.DataLoader(train_dataset, batchsize = args[\"batch_size\"], collate = true, shuffle = false);\n",
    "        #for x in data_loader\n",
    "        #    @info \"data_loader loop....\" * \"$(size(x))\"\n",
    "        #end\n",
    "        train_qpath_iterator = KGDataset.SingleDirectionalOneShotIterator(data_loader);\n",
    "#            num_workers=args.cpu_num,\n",
    "#            collate_fn=TrainDataset.collate_fn));\n",
    "\n",
    "        if length(train_other_queries) > 0\n",
    "           train_other_queries = flatten_query(train_other_queries)\n",
    "           train_other_iterator = KGDataset.SingleDirectionalOneShotIterator(MLUtils.DataLoader(KGDataset.TrainDataset(train_other_queries, \n",
    "                                                                                                                        train_answers, \n",
    "                                                                                                                        nentity, \n",
    "                                                                                                                        nrelation, \n",
    "                                                                                                                        args[\"negative_sample_size\"]),\n",
    "                                                                                                batchsize=args[\"batch_size\"],\n",
    "                                                                                                shuffle=true));\n",
    "#                                       num_workers=args.cpu_num,\n",
    "#                                       collate_fn=TrainDataset.collate_fn))\n",
    "        else\n",
    "           train_other_iterator = None\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if args[\"valid\"]\n",
    "        @info(\"Validation ...\")\n",
    "        \n",
    "        #for query_structure in keys(valid_queries)\n",
    "        #    @info query_name_dict[query_structure] * \": \" * \"$(length(valid_queries[query_structure]))\"\n",
    "        # end\n",
    "        valid_queries2 = flatten_query(valid_queries)\n",
    "        valid_dataloader = KGDataset.DataLoader(KGDataset.TestDataset(valid_queries2, nentity, nrelation), \n",
    "                                                batchsize=args[\"test_batch_size\"]);\n",
    "#            num_workers=args.cpu_num, \n",
    "#            collate_fn=TestDataset.collate_fn)\n",
    "    end\n",
    "\n",
    "    if args[\"test\"]\n",
    "        @info(\"Test ...\")\n",
    "        \n",
    "        # for query_structure in keys(test_queries)\n",
    "        #    @info query_name_dict[query_structure] * \": \" * \"$(length(test_queries[query_structure]))\"\n",
    "        # end\n",
    "        test_queries = flatten_query(test_queries)\n",
    "        test_dataloader = KGDataset.DataLoader(\n",
    "            KGDataset.TestDataset(test_queries, nentity, nrelation), \n",
    "            batchsize=args[\"test_batch_size\"]);\n",
    "   #         num_workers=args.cpu_num, \n",
    "   #         collate_fn=TestDataset.collate_fn)\n",
    "    end\n",
    "\n",
    "    model = KGModule.KGReasoning(nentity,\n",
    "                                nrelation,\n",
    "                                args[\"hidden_dim\"],\n",
    "                                args[\"gamma\"],\n",
    "                                args[\"geo\"],\n",
    "                                args[\"test_batch_size\"],\n",
    "                                eval_tuple(args[\"box_mode\"]),\n",
    "                                eval_tuple(args[\"beta_mode\"]),\n",
    "                                query_name_dict,\n",
    "                                args[\"cuda\"] == \"Yes\")\n",
    "\n",
    "    @info(\"Model Parameter Configuration:\")\n",
    "    num_params = 0\n",
    "    for (lindex,layer) in enumerate(Flux.params(model)) #.named_parameters()\n",
    "        #@info(\"Parameter %s: %s, require_grad = %s\" % (name, str(param.size()), str(param.requires_grad)))\n",
    "        #if param.requires_grad\n",
    "        #    num_params += np.prod(param.size())\n",
    "        #end\n",
    "        for (pindex, pa) in enumerate(Flux.params(layer))\n",
    "            @info(\"Parameter layer$lindex-$pindex: $(size(pa))\")\n",
    "            num_params += sum(length, Flux.params(layer))\n",
    "        end\n",
    "    end\n",
    "    @info(\"Parameter Number: $num_params\")\n",
    "#\n",
    "#    if args[\"cuda\"]\n",
    "#        model = model.cuda()\n",
    "#    end\n",
    "#\n",
    "#    if args[\"train\"]\n",
    "#        current_learning_rate = args[\"learning_rate\"]\n",
    "#        optimizer = torch.optim.Adam(\n",
    "#            filter(lambda p: p.requires_grad, model.parameters()), \n",
    "#            lr=current_learning_rate\n",
    "#        )\n",
    "#        warm_up_steps = args[\"max_steps\"] // 2\n",
    "#    end\n",
    "#\n",
    "#    if args[\"checkpoint_path\"] is not Nothing\n",
    "#        @info(\"Loading checkpoint $(args[\"checkpoint_path\"]...\")\n",
    "#        checkpoint = torch.load(joinPath(args[\"checkpoint_path\"], \"checkpoint\"))\n",
    "#        init_step = checkpoint[\"step\"]\n",
    "#        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "#\n",
    "#        if args[\"train\"]\n",
    "#            current_learning_rate = checkpoint[\"current_learning_rate\"]\n",
    "#            warm_up_steps = checkpoint[\"warm_up_steps\"]\n",
    "#            optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "#        end\n",
    "#    else\n",
    "#        @info(\"Ramdomly Initializing $(args[\"geo\"]) Model...\")\n",
    "#        init_step = 0\n",
    "#    end\n",
    "#\n",
    "#    step = init_step \n",
    "#    if args[\"geo\"] == \"box\"\n",
    "#        @info(\"box mode = $args[\"box_mode\"]\")\n",
    "#    elif args[\"geo\"] == \"beta\"\n",
    "#        @info(\"beta mode = $($args[\"beta_mode\"])\")\n",
    "#    end\n",
    "#    @info(\"tasks = $(args[\"tasks\"])\")\n",
    "#    @info(\"init_step = $init_step\")\n",
    "#    if args[\"train\"]\n",
    "#        @info(\"learning_rate = $current_learning_rate\")\n",
    "#    end\n",
    "#    @info(\"batch_size = $(args[\"batch_size\"])\")\n",
    "#    @info(\"hidden_dim = $(args[\"hidden_dim\"])\")\n",
    "#    @info(\"gamma = $(args[\"gamma\"])\")\n",
    "#\n",
    "#    if args[\"train\"]\n",
    "#        @info(\"Start Training...\")\n",
    "#        training_logs = []\n",
    "#        # #Training Loop\n",
    "#        for step in range(init_step, args.max_steps):\n",
    "#            if step == 2*args.max_steps//3\n",
    "#                args.valid_steps *= 4\n",
    "#            end\n",
    "#\n",
    "#            log = model.train_step(model, optimizer, train_path_iterator, args, step)\n",
    "#            for metric in log\n",
    "#                writer.add_scalar(\"path_\"+metric, log[metric], step)\n",
    "#            end\n",
    "#            if train_other_iterator is not Nothing\n",
    "#                log = model.train_step(model, optimizer, train_other_iterator, args, step)\n",
    "#                for metric in log\n",
    "#                    writer.add_scalar(\"other_\"+metric, log[metric], step)\n",
    "#                end\n",
    "#                log = model.train_step(model, optimizer, train_path_iterator, args, step)\n",
    "#            end\n",
    "#\n",
    "#            training_logs.append(log)\n",
    "#\n",
    "#            if step >= warm_up_steps\n",
    "#                current_learning_rate = current_learning_rate / 5\n",
    "#                @info(\"Change learning_rate to %f at step %d\" % (current_learning_rate, step))\n",
    "#                optimizer = torch.optim.Adam(\n",
    "#                    filter(lambda p: p.requires_grad, model.parameters()), \n",
    "#                    lr=current_learning_rate\n",
    "#                )\n",
    "#                warm_up_steps = warm_up_steps * 1.5\n",
    "#            end\n",
    "#\n",
    "#            if step % args.save_checkpoint_steps == 0\n",
    "#                save_variable_list = {\n",
    "#                    \"step\": step,\n",
    "#                    \"current_learning_rate\": current_learning_rate,\n",
    "#                    \"warm_up_steps\": warm_up_steps\n",
    "#                }\n",
    "#                save_model(model, optimizer, save_variable_list, args)\n",
    "#            end\n",
    "#\n",
    "#            if step % args.valid_steps == 0 and step > 0\n",
    "#                if args.do_valid\n",
    "#                    @info(\"Evaluating on Valid Dataset...\")\n",
    "#                    valid_all_metrics = evaluate(model, valid_easy_answers, valid_hard_answers, args, valid_dataloader, query_name_dict, \"Valid\", step, writer)\n",
    "#                end\n",
    "#\n",
    "#                if args.do_test\n",
    "#                    @info(\"Evaluating on Test Dataset...\")\n",
    "#                    test_all_metrics = evaluate(model, test_easy_answers, test_hard_answers, args, test_dataloader, query_name_dict, \"Test\", step, writer)\n",
    "#                end\n",
    "#            end\n",
    "#\n",
    "#            if step % args.log_steps == 0\n",
    "#                metrics = {}\n",
    "#                for metric in training_logs[0].keys():\n",
    "#                    metrics[metric] = sum([log[metric] for log in training_logs])/len(training_logs)\n",
    "#                end\n",
    "#\n",
    "#                log_metrics(\"Training average\", step, metrics)\n",
    "#                training_logs = []\n",
    "#            end\n",
    "#\n",
    "#        save_variable_list = {\n",
    "#            \"step\": step, \n",
    "#            \"current_learning_rate\": current_learning_rate,\n",
    "#            \"warm_up_steps\": warm_up_steps\n",
    "#        }\n",
    "#        save_model(model, optimizer, save_variable_list, args)\n",
    "#\n",
    "#    try\n",
    "#        print (step)\n",
    "#    catch\n",
    "#        step = 0\n",
    "#    end\n",
    "#\n",
    "#    if args[\"test\"]\n",
    "#        @info(\"Evaluating on Test Dataset...\")\n",
    "#        test_all_metrics = evaluate(model, test_easy_answers, test_hard_answers, args, test_dataloader, query_name_dict, \"Test\", step, writer)\n",
    "#    end\n",
    "#\n",
    "    @info(\"Training finished!!\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8798cda4-05f3-43a1-94bf-756f5e12bdf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:39:23 /home/users/hjk/.julia/packages/IJulia/Vo51o/src/kernel.jl x In[52]\n",
      "Dict{String, Any}(\"geo\" => \"vec\", \"test_log_steps\" => 1000, \"lr\" => 0.0001, \"tasks\" => \"1p.2p.3p.2i.3i.ip.pi.2u.up\", \"batch_size\" => 512, \"evaluate_union\" => \"DNF\", \"nentity\" => 0, \"nrelation\" => 0, \"print_on_screen\" => true, \"cpu\" => 1, \"valid\" => true, \"valid_steps\" => 15000, \"train\" => true, \"negative_sample_size\" => 128, \"checkpoint_path\" => nothing, \"prefix\" => nothing, \"cuda\" => true, \"warm_up_steps\" => nothing, \"hidden_dim\" => 800, \"beta_mode\" => \"(1600,2)\", \"box_mode\" => \"(nothing,0.02)\", \"data_path\" => \"/home/users/hjk/dataset/KG_data/FB15k-betae\", \"max_steps\" => 450001, \"save_checkpoint_steps\" => 50000, \"save_path\" => \".\", \"test\" => true, \"gamma\" => 24.0, \"log_steps\" => 100, \"seed\" => 0, \"test_batch_size\" => 1)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:39:24 overwritting saving path: .\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:39:24 logging to logs/FB15k-betae/1p.2p.3p.2i.3i.ip.pi.2u.up/vec/g-24.0/2023.11.20\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:39:24 ---------------------------------------------------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:39:24 Geo: vec\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:39:24 Data Path: /home/users/hjk/dataset/KG_data/FB15k-betae\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:39:24 #entity: 14951\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:39:24 #relation: 2690\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:39:24 #max steps: 450001\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:39:24 Evaluate unoins using: DNF\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:39:24 Training ...\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:39:24 Flatten query length: 821130 typeof(query) Vector{Any}\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:39:26 Validation ...\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:39:26 Test ...\n",
      "query_name_dict type :Dict{Tuple, String}\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:44:20 Model Parameter Configuration:\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:44:20 Parameter Number: 0\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2023-11-20 14:44:20 Training finished!!\n"
     ]
    }
   ],
   "source": [
    "@info \"$(abspath(PROGRAM_FILE)) x $(@__FILE__)\"\n",
    "#if abspath(PROGRAM_FILE) == @__FILE__\n",
    "#end\n",
    "\n",
    "args = Vector{String}([\"--cuda\", \"--train\", \"--valid\", \"--test\", \"--data_path\", \"/home/users/hjk/dataset/KG_data/FB15k-betae\",\n",
    "                        \"-n\", \"128\", \"-b\", \"512\", \"-d\", \"800\", \"-g\", \"24\",\"--lr\", \"0.0001\", \"--max_steps\", \"450001\", \"--cpu\", \"1\", \n",
    "                       \"--geo\", \"vec\", \"--valid_steps\", \"15000\", \"--tasks\", \"1p.2p.3p.2i.3i.ip.pi.2u.up\"])\n",
    "structed_args = parse_cmdargs(args);\n",
    "println(structed_args)\n",
    "\n",
    "set_logger(structed_args);\n",
    "\n",
    "main(structed_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fae9d4e0-94a3-4b76-a392-659c9c6ac87d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geovecString\n",
      "test_log_steps1000Int64\n",
      "lr0.0001Float64\n",
      "tasks1p.2p.3p.2i.3i.ip.pi.2u.upString\n",
      "batch_size512Int64\n",
      "evaluate_unionDNFString\n",
      "nentity0Int64\n",
      "nrelation0Int64\n",
      "print_on_screentrueBool\n",
      "cpu1Int64\n",
      "validtrueBool\n",
      "valid_steps15000Int64\n",
      "traintrueBool\n",
      "negative_sample_size128Int64\n",
      "checkpoint_pathnothingNothing\n",
      "prefixnothingNothing\n",
      "cudatrueBool\n",
      "warm_up_stepsnothingNothing\n",
      "hidden_dim800Int64\n",
      "beta_mode(1600,2)String\n",
      "box_mode(nothing,0.02)String\n",
      "data_path/home/users/hjk/dataset/KG_data/FB15k-betaeString\n",
      "max_steps450001Int64\n",
      "save_checkpoint_steps50000Int64\n",
      "save_path.String\n",
      "testtrueBool\n",
      "gamma24.0Float64\n",
      "log_steps100Int64\n",
      "seed0Int64\n",
      "test_batch_size1Int64\n"
     ]
    }
   ],
   "source": [
    "using Dates;\n",
    "\n",
    "Dates.format(Dates.now(), \"YY-mm-dd HH-MM-SS\")\n",
    "\n",
    "args = Vector{String}([\"--cuda\", \"--train\", \"--valid\", \"--test\", \"--data_path\", \"/home/users/hjk/dataset/KG_data/FB15k-betae\",\n",
    "                        \"-n\", \"128\", \"-b\", \"512\", \"-d\", \"800\", \"-g\", \"24\",\"--lr\", \"0.0001\", \"--max_steps\", \"450001\", \"--cpu\", \"1\", \n",
    "                       \"--geo\", \"vec\", \"--valid_steps\", \"15000\", \"--tasks\", \"1p.2p.3p.2i.3i.ip.pi.2u.up\"])\n",
    "structed_args = parse_cmdargs(args);\n",
    "\n",
    "for q in keys(structed_args)\n",
    "    println(q, structed_args[q], typeof(structed_args[q]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1319ac7f-7b4e-4225-a383-b61883827348",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c5a157-b35a-4c26-9e7c-736d396d6575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  },
  "name": "KGReasoning.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
