{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11065693-20a5-462a-8ea3-f5a8f23835fb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "using Pkg;\n",
    "#=\n",
    "Pkg.add(\"Genie\")\n",
    "Pkg.add(\"Images\")\n",
    "Pkg.add(\"Flux\")\n",
    "Pkg.add(\"MLUtils\")\n",
    "Pkg.add(\"ArgParse\")\n",
    "Pkg.add(\"LoggingExtras\")\n",
    "Pkg.add(\"Dates\")\n",
    "Pkg.add(\"Printf\")\n",
    "Pkg.add(\"TensorBoardLogger\")\n",
    "Pkg.add(\"JLD2\");\n",
    "Pkg.add(\"BSON\");\n",
    "Pkg.add(\"Pickle\")\n",
    "Pkg.add(\"ProgressBars\")\n",
    "Pkg.add(\"Distributions\")\n",
    "Pkg.add(\"Revise\")\n",
    "Pkg.add(\"Zygote\")\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b62ebc-2bee-4d04-8e93-e5f0fccc0579",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "using Pickle;\n",
    "using ArgParse;\n",
    "using Random;\n",
    "using Logging, LoggingExtras, TensorBoardLogger;\n",
    "using Dates;\n",
    "using Printf;\n",
    "using ProgressBars;\n",
    "using Flux;\n",
    "using MLUtils;\n",
    "using Revise;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c67737-8630-4baf-a1d4-fa9f077c94ed",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cd(\"/sata/sdb5/julia/pro_kgreasoning\")\n",
    "\n",
    "f_dir = \"dataset\";\n",
    "f_model = \"FB15k-betae\";\n",
    "f_train_queries = \"train-queries.pkl\";\n",
    "f_train_answers = \"train-answers.pkl\";\n",
    "f_valid_queries = \"valid-queries.pkl\";\n",
    "f_valid_hard_answers = \"valid-hard-answers.pkl\";\n",
    "f_valid_easy_answers = \"valid-easy-answers.pkl\";\n",
    "f_test_queries = \"test-queries.pkl\";\n",
    "f_test_hard_answers = \"test-hard-answers.pkl\";\n",
    "f_test_easy_answers = \"test-easy-answers.pkl\";\n",
    "\n",
    "query_name_dict = Dict{Tuple, String}((\"e\",(\"r\",))=> \"1p\",\n",
    "                                    (\"e\", (\"r\", \"r\"))=> \"2p\",\n",
    "                                    (\"e\", (\"r\", \"r\", \"r\"))=> \"3p\",\n",
    "                                    ((\"e\", (\"r\",)), (\"e\", (\"r\",)))=> \"2i\",\n",
    "                                    ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"e\", (\"r\",)))=> \"3i\",\n",
    "                                    (((\"e\", (\"r\",)), (\"e\", (\"r\",))), (\"r\",))=> \"ip\",\n",
    "                                    ((\"e\", (\"r\", \"r\")), (\"e\", (\"r\",)))=> \"pi\",\n",
    "                                    ((\"e\", (\"r\",)), (\"e\", (\"r\", \"n\")))=> \"2in\",\n",
    "                                    ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"e\", (\"r\", \"n\")))=> \"3in\",\n",
    "                                    (((\"e\", (\"r\",)), (\"e\", (\"r\", \"n\"))), (\"r\",))=> \"inp\",\n",
    "                                    ((\"e\", (\"r\", \"r\")), (\"e\", (\"r\", \"n\")))=> \"pin\",\n",
    "                                    ((\"e\", (\"r\", \"r\", \"n\")), (\"e\", (\"r\",)))=> \"pni\",\n",
    "                                    ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"u\",))=> \"2u-DNF\",\n",
    "                                    (((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"u\",)), (\"r\",))=> \"up-DNF\",\n",
    "                                    (((\"e\", (\"r\", \"n\")), (\"e\", (\"r\", \"n\"))), (\"n\",))=> \"2u-DM\",\n",
    "                                    (((\"e\", (\"r\", \"n\")), (\"e\", (\"r\", \"n\"))), (\"n\", \"r\"))=> \"up-DM\"\n",
    "                                );\n",
    "name_query_dict = Dict{String, Tuple}((y => x) for (x, y) in query_name_dict);\n",
    "all_tasks = collect(keys(name_query_dict));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b876a522-b879-45f3-8604-d5854a74afa3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_data (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_data(args, tasks, all_tasks, query_dict)\n",
    "    @info \"loading data....\"\n",
    "\n",
    "    data_path = args[\"data_path\"];\n",
    "    train_queries = Pickle.load(open(joinpath(data_path, f_train_queries)));\n",
    "    train_answers = Pickle.load(open(joinpath(data_path, f_train_answers)));\n",
    "    valid_queries = Pickle.load(open(joinpath(data_path, f_valid_queries)));\n",
    "    valid_hard_answers = Pickle.load(open(joinpath(data_path, f_valid_hard_answers)));\n",
    "    valid_easy_answers = Pickle.load(open(joinpath(data_path, f_valid_easy_answers)));\n",
    "    test_queries = Pickle.load(open(joinpath(data_path, f_test_queries)));\n",
    "    test_hard_answers = Pickle.load(open(joinpath(data_path, f_test_hard_answers)));\n",
    "    test_easy_answers = Pickle.load(open(joinpath(data_path, f_test_easy_answers)));\n",
    "\n",
    "    # remove tasks not in args.tasks\n",
    "    for name in all_tasks\n",
    "        if 'u' in name\n",
    "            name, evaluate_union = split(name, \"-\")\n",
    "        else\n",
    "            evaluate_union = args[\"evaluate_union\"]\n",
    "        end\n",
    "        if !(name in tasks) || evaluate_union != args[\"evaluate_union\"]\n",
    "            query_structure = query_dict[eval(if !('u' in name) name else join([name, evaluate_union], \"-\") end)]\n",
    "            #println(\"load_data: deleteing structure...:\\n $(query_structure)\")\n",
    "            if haskey(train_queries, query_structure)\n",
    "                delete!(train_queries, query_structure);\n",
    "            end\n",
    "            if haskey(valid_queries, query_structure)\n",
    "                delete!(valid_queries, query_structure);\n",
    "            end\n",
    "            if haskey(test_queries, query_structure)\n",
    "                delete!(test_queries, query_structure)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    @info \"load data....Done\"\n",
    "    return train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87586e14-fbf6-4bcd-9ceb-fd8c3ca2d8ad",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sata/sdb5/julia/pro_kgreasoning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mloading data....\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mload data....Done\n"
     ]
    }
   ],
   "source": [
    "str_tasks = \"1p.2p.3p.2i.3i.ip.pi.2u.up\";\n",
    "tasks = split(str_tasks, \".\");\n",
    "args = Dict(\"data_path\"=> joinpath(f_dir ,f_model), \"evaluate_union\"=>\"DNF\");\n",
    "\n",
    "train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers = load_data(args, tasks, all_tasks, name_query_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "678871bc-e742-48d5-9ad7-fc150f5235a0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Print the evaluation logs\n",
    "\"\"\"\n",
    "function log_metrics(mode, step, metrics)\n",
    "    for metric in metrics\n",
    "        @info \"$mode $metric at step $(step): $(metrics[metric.first])\"\n",
    "    end\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    Evaluate queries in dataloader\n",
    "\"\"\"\n",
    "function evaluate(model, tp_answers, fn_answers, args, dataloader, query_name_dict, mode, step, writer)\n",
    "\n",
    "    average_metrics = Dict{Float}()\n",
    "    all_metrics = Dict{Float}()\n",
    "\n",
    "    metrics = model.test_step(model, tp_answers, fn_answers, args, dataloader, query_name_dict)\n",
    "    num_query_structures = 0\n",
    "    num_queries = 0\n",
    "    for query_structure in metrics\n",
    "        log_metrics(mode * \" \" * query_name_dict[query_structure], step, metrics[query_structure])\n",
    "\n",
    "        for metric in metrics[query_structure]\n",
    "            writer.add_scalar(\"_\".join([mode, query_name_dict[query_structure], metric]), metrics[query_structure][metric], step)\n",
    "            all_metrics[\"_\".join([query_name_dict[query_structure], metric])] = metrics[query_structure][metric]\n",
    "            if metric != \"num_queries\"\n",
    "                average_metrics[metric] += metrics[query_structure][metric]\n",
    "            end\n",
    "        end\n",
    "        num_queries += metrics[query_structure][\"num_queries\"]\n",
    "        num_query_structures += 1\n",
    "    end\n",
    "\n",
    "    for metric in average_metrics\n",
    "        average_metrics[metric] /= num_query_structures\n",
    "        writer.add_scalar(\"_\".join([mode, \"average\", metric]), average_metrics[metric], step)\n",
    "        all_metrics[\"_\".join([\"average\", metric])] = average_metrics[metric]\n",
    "    end\n",
    "\n",
    "    log_metrics(\"$mode average\", step, average_metrics)\n",
    "    return all_metrics\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e852c1c-8fc9-4f9e-9677-8ab2fbf21a15",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flatten (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function format_time()\n",
    "    return Dates.format(Dates.now(), \"YY.mm.dd\")\n",
    "end\n",
    "\n",
    "#---Evaluate a tuple string into a tuple.\n",
    "function eval_tuple(arg_return)\n",
    "    if typeof(arg_return) <: Tuple\n",
    "        return arg_return\n",
    "    end\n",
    "\n",
    "    if !(arg_return[1] in (\"(\", \"[\"))\n",
    "        arg_return = eval(arg_return)\n",
    "    else\n",
    "        splitted = split(arg_return[2:length(arg_return)-1], \", \")\n",
    "        List = []\n",
    "        for item in splitted\n",
    "            try\n",
    "                item = eval(item)\n",
    "            catch err\n",
    "                pass\n",
    "            end\n",
    "            if item == \"\"\n",
    "                continue\n",
    "            end\n",
    "            append!(List, item)\n",
    "        end\n",
    "        arg_return = tuple(List)\n",
    "    return arg_return\n",
    "    end\n",
    "end\n",
    "\n",
    "function flatten_query(queries)\n",
    "    all_queries = []\n",
    "    for query_structure in keys(queries)\n",
    "        list_queries = collect(queries[query_structure])\n",
    "        #ttt = [(query, query_structure) for query in list_queries]\n",
    "        #println(\"query_structure key: $(query_structure) queries length: $(length(list_queries)) tuple length: $(length(ttt))\");\n",
    "        append!(all_queries, [(query, query_structure) for query in list_queries])\n",
    "    end\n",
    "    return all_queries\n",
    "end\n",
    "\n",
    "function flatten(l)\n",
    "    collect(Iterators.flatten(l))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe8f4885-5008-4dfa-a0f4-e0cc6540b449",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.KGDataset13"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module KGDataset\n",
    "\n",
    "using Main\n",
    "import MLUtils: DataLoader\n",
    "\n",
    "export numobs, getobs, TrainDataset, TestDataset, SingleDirectionalOneShotIterator\n",
    "\n",
    "abstract type Dataset end\n",
    "struct TrainDataset <: Dataset\n",
    "    queries::Vector{Any}\n",
    "    answer::Dict{Any, Any}\n",
    "    nentity::Int\n",
    "    nrelation::Int\n",
    "    negative_sample_size::Int\n",
    "    count::Dict{Tuple, Int}\n",
    "end\n",
    "#=\n",
    "function collate_fn(data::TrainDataset)\n",
    "    positive_sample = cat([_[0] for _ in data], dim=0)\n",
    "    negative_sample = stack([_[1] for _ in data], dim=0)\n",
    "    subsample_weight = cat([_[2] for _ in data], dim=0)\n",
    "    query = [_[3] for _ in data]\n",
    "    query_structure = [_[4] for _ in data]\n",
    "    return positive_sample, negative_sample, subsample_weight, query, query_structure\n",
    "end\n",
    "=#\n",
    "function count_frequency(queries, answer, start=4)\n",
    "    count = Dict{Tuple, Int}()\n",
    "    for (query, _) in queries\n",
    "        #println(\"$(query) -- $(length(answer[query]))\")\n",
    "        count[query] = start + length(answer[query])\n",
    "    end\n",
    "    return count\n",
    "end\n",
    "\n",
    "function TrainDataset(queries, answers, nentity, nrelation, negtaive_sample_size)\n",
    "    count = count_frequency(queries, answers);\n",
    "    return TrainDataset(queries, answers, nentity, nrelation, negtaive_sample_size, count)\n",
    "end\n",
    "\n",
    "function numobs(data::TrainDataset)\n",
    "    return length(data.queries)\n",
    "end\n",
    "\n",
    "function getobs(data::TrainDataset, idx::Int)\n",
    "\n",
    "    query = data.queries[idx][1]\n",
    "    query_structure = data.queries[idx][2]\n",
    "    @info \"TrainDataset [$(idx)] -> $(data.queries[idx]) answer: $(data.answer[query])\"\n",
    "    tail = rand(collect(data.answer[query]))\n",
    "    subsampling_weight = data.count[query]\n",
    "    @info \"TrainDataset tail $(tail) subsampling_weight: $(subsampling_weight)\"\n",
    "    subsampling_weight = sqrt.(1 ./ [subsampling_weight])\n",
    "    negative_sample_list = []\n",
    "    negative_sample_size = 0\n",
    "    while negative_sample_size < data.negative_sample_size\n",
    "        negative_sample = rand(1:data.nentity, data.negative_sample_size*2)\n",
    "        # check whether the items in ar1 belong to ar2, return a vector\n",
    "        # has the same length with ar1, filled with true or false\n",
    "        #mask = np.in1d(negative_sample, data.answer[query],\n",
    "        #               assume_unique=true, invert=true)\n",
    " \n",
    "        avail_index = indexin(negative_sample, collect(data.answer[query]))\n",
    "        #println(\"avail_index: $(avail_index)\")\n",
    "        mask = falses(data.negative_sample_size * 2)\n",
    "        #println(\"mask: $(mask)\")\n",
    "        map(avail_index) do x\n",
    "            if x != nothing\n",
    "                println(\"getobs: set mask at $x\")\n",
    "                mask[Int(x)] = true\n",
    "            end \n",
    "        end\n",
    "        reverse!(mask)\n",
    "        negative_sample = negative_sample[mask]\n",
    "        append!(negative_sample_list, negative_sample)\n",
    "        negative_sample_size += length(negative_sample)\n",
    "    end\n",
    "    negative_sample = stack(negative_sample_list)[1:data.negative_sample_size]\n",
    "    negative_sample = negative_sample # original: torch.from_numpy\n",
    "    positive_sample = convert.(Float64, [tail])\n",
    "\n",
    "    return positive_sample, negative_sample, subsampling_weight, Main.flatten(query), query_structure\n",
    "end\n",
    "\n",
    "struct SingleDirectionalOneShotIterator\n",
    "    data_loader::DataLoader\n",
    "end\n",
    "\n",
    "function Base.iterate(iter::SingleDirectionalOneShotIterator)\n",
    "    state = 1\n",
    "    if length(iter.data_loader.data.queries) <= 0\n",
    "        return nothing\n",
    "    end\n",
    "\n",
    "    return ( getobs(iter.data_loader.data, state), state + 1 )\n",
    "end\n",
    "\n",
    "function Base.iterate(iter::SingleDirectionalOneShotIterator, state = 1)\n",
    "    if length(iter.data_loader.data.queries) < state\n",
    "        return nothing\n",
    "    end\n",
    "\n",
    "    return ( getobs(iter.data_loader.data, state), state + 1 )\n",
    "end\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae66064-914a-4244-a018-fa77ddeeadfd",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "using Revise\n",
    "using MLUtils;\n",
    "\n",
    "using .KGDataset13\n",
    "\n",
    "train_flatten_queries = flatten_query(train_queries);\n",
    "println(\"length of train_flatten_queries: $(length(train_flatten_queries))\")\n",
    "println(\"length of train_answers: $(length(train_answers))\")\n",
    "negative_sample_size = 32\n",
    "batch_size = 1\n",
    "nentity=sum([length(q) for q in train_flatten_queries])\n",
    "nrelation=sum([length(q) for q in train_flatten_queries])\n",
    "data_set = KGDataset13.TrainDataset(train_flatten_queries, train_answers, nentity, nrelation, negative_sample_size);\n",
    "#DataLoader(data; [batchsize, buffer, collate, parallel, partial, rng, shuffle])\n",
    "data_loader = MLUtils.DataLoader(data_set, batchsize = batch_size, collate = true, shuffle=false);\n",
    "#println(typeof(data_loader.data))\n",
    "#println(\"numobs, getobs.....\")\n",
    "train_path_iterator = KGDataset13.SingleDirectionalOneShotIterator(data_loader);\n",
    "\n",
    "data_index = 1\n",
    "for item in train_path_iterator\n",
    "    println(\"for loop: --$(item)\")\n",
    "    data_index += 1\n",
    "    if data_index >= 2\n",
    "        break\n",
    "    end\n",
    "end\n",
    "\n",
    "(item, next)  = iterate(train_path_iterator,data_index)\n",
    "println(item)\n",
    "\n",
    "(item, next)  = iterate(train_path_iterator, next)\n",
    "println(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd7e27-170a-4a7d-836e-18e03b0c89c5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "module KGModule\n",
    "\n",
    "using Zygote: AbstractFFTs\n",
    "export Identity, normDims, BoxOffsetIntersection, CenterIntersection, BetaIntersection,\n",
    "    BetaProjection, Regularizer, KGReasoning, train_step\n",
    "\n",
    "using Flux;\n",
    "using Zygote;\n",
    "using Statistics;\n",
    "using Distributions;\n",
    "using MLUtils;\n",
    "\n",
    "include(\"src/utils.jl\")\n",
    "\n",
    "function Identity(x)\n",
    "    return x;\n",
    "end\n",
    "\n",
    "function normDims(itr, p::Real=2; dim)\n",
    "    sum(itr .^ p; dims=dim).^(1 / p)\n",
    "end\n",
    "\n",
    "struct BoxOffsetIntersection\n",
    "    dim::Int\n",
    "    layer1::Flux.Dense\n",
    "    layer2::Flux.Dense\n",
    "end\n",
    "\n",
    "function BoxOffsetIntersection(dim::Int)\n",
    "    layer1 = Flux.Dense(dim => dim);\n",
    "    layer2 = Flux.Dense(dim => dim);\n",
    "\n",
    "    return BoxOffsetIntersection(dim, layer1, layer2);\n",
    "end\n",
    "\n",
    "#Function-like Object\n",
    "function (m::BoxOffsetIntersection)(embeddings)\n",
    "    @show embeddings\n",
    "    layer1_act = Flux.relu(m.layer1(embeddings))\n",
    "    @show layer1_act\n",
    "    layer1_mean = mean(layer1_act, dims=length(size(layer1_act)))\n",
    "    @show layer1_mean\n",
    "    gate = Flux.sigmoid(m.layer2(layer1_mean))\n",
    "    @show gate\n",
    "    offset = minimum(embeddings, dims=length(size(layer1_act)))\n",
    "\n",
    "    return offset .* gate\n",
    "end\n",
    "\n",
    "Flux.@functor BoxOffsetIntersection\n",
    "\n",
    "struct CenterIntersection\n",
    "    dim::Int\n",
    "    layer1::Flux.Dense\n",
    "    layer2::Flux.Dense\n",
    "end\n",
    "\n",
    "function CenterIntersection(dim::Int)\n",
    "    layer1 = Flux.Dense(dim => dim)\n",
    "    layer2 = Flux.Dense(dim => dim)\n",
    "\n",
    "    #Flux.Dense is initialized by  xavier defaultly\n",
    "    return CenterIntersection(dim, layer1, layer2)\n",
    "end\n",
    "\n",
    "function (m::CenterIntersection)(embeddings)\n",
    "    layer1_act = Flux.relu(m.layer1(embeddings)) # ( dim, num_conj)\n",
    "    attention = Flux.softmax(m.layer2(layer1_act), dims=length(size(layer1_act))) # (dim, num_conj, )\n",
    "    embedding = sum(attention * embeddings, dims=length(size(layer1_act)))\n",
    "\n",
    "    return embedding\n",
    "end\n",
    "\n",
    "Flux.@functor CenterIntersection\n",
    "\n",
    "struct BetaIntersection\n",
    "    dim::Int\n",
    "    layer1::Flux.Dense\n",
    "    layer2::Flux.Dense\n",
    "end\n",
    "\n",
    "function BetaIntersection(dim::Int)\n",
    "    layer1 = Flux.Dense(2 * dim, 2 * dim)\n",
    "    layer2 = Flux.Dense(2 * dim, dim)\n",
    "\n",
    "    return BetaIntersection(dim, layer1, layer2)\n",
    "end\n",
    "\n",
    "function (m::BetaIntersection)(alpha_embeddings, beta_embeddings)\n",
    "    all_embeddings = cat(length(size(alpha_embeddings)), alpha_embeddings, beta_embeddings)\n",
    "    layer1_act = Flux.relu(m.layer1(all_embeddings)) # (num_conj, batch_size, 2 * dim)\n",
    "    attention = Flux.softmax(m.layer2(layer1_act), dims=length(size(alpha_embeddings))) # (num_conj, batch_size, dim)\n",
    "\n",
    "    alpha_embedding = sum(attention * alpha_embeddings, dims=length(size(alpha_embeddings)))\n",
    "    beta_embedding = sum(attention * beta_embeddings, dims=length(size(alpha_embeddings)))\n",
    "\n",
    "    return alpha_embedding, beta_embedding\n",
    "end\n",
    "\n",
    "Flux.@functor BetaIntersection\n",
    "\n",
    "struct Regularizer\n",
    "    base_add::AbstractFloat\n",
    "    min_val::AbstractFloat\n",
    "    max_val::AbstractFloat\n",
    "end\n",
    "\n",
    "function (m::Regularizer)(entity_embedding)\n",
    "    return clamp(entity_embedding + m.base_add, m.min_val, m.max_val)\n",
    "end\n",
    "\n",
    "Flux.@functor Regularizer\n",
    "\n",
    "struct BetaProjection\n",
    "    entity_dim::Int\n",
    "    relation_dim::Int\n",
    "    hidden_dim::Int\n",
    "    num_layers::Int\n",
    "\n",
    "    layers::Dict{Symbol, Flux.Dense}\n",
    "    projection_regularizer\n",
    "end\n",
    "\n",
    "function Base.setproperty!(m::BetaProjection, property::Symbol, value)\n",
    "    getfield(m, :layers)[property] = value\n",
    "end\n",
    "\n",
    "function Base.getproperty(m::BetaProjection, property::Symbol, value)\n",
    "    return getfield(m, :layers)[property]\n",
    "end\n",
    "\n",
    "function Base.propertynames(m::BetaProjection, private = false)\n",
    "    return keys(getproperty(m, :layers))\n",
    "end\n",
    "\n",
    "function BetaProjection(entity_dim, relation_dim, hidden_dim, projection_regularizer, num_layers)\n",
    "    layer1 = Flux.Dense((entity_dim + relation_dim) => hidden_dim) # 1st layer\n",
    "    layer0 = Flux.Dense(hidden_dim => entity_dim) # final layer\n",
    "\n",
    "    layers = Dict{Symbol, Flux.Dense}()\n",
    "    layers[:layer1] = Flux.Dense((entity_dim + relation_dim) => hidden_dim) # 1st layer\n",
    "    layers[:layer0]  = Flux.Dense(hidden_dim => entity_dim) # final layer\n",
    "    for nl in range(2, num_layers)\n",
    "        layers[Symbol(\"layer$(nl)\")] = Flux.Dense(hidden_dim, hidden_dim)\n",
    "    end\n",
    "\n",
    "    return BetaProjection(entity_dim, relation_dim, hidden_dim, num_layers,\n",
    "                          layers, projection_regularizer)\n",
    "\n",
    "end\n",
    "\n",
    "function (m::BetaProjection)(e_embedding, r_embedding)\n",
    "    x = cat(1, e_embedding, r_embedding)\n",
    "    for nl in range(1, m.num_layers)\n",
    "        x = Flux.relu(getproperty(m, Symbol(\"layer$(nl)\")(x)))\n",
    "    end\n",
    "    x = getproperty(m, :layer0)(x)\n",
    "    x = m.projection_regularizer(x)\n",
    "\n",
    "    return x\n",
    "end\n",
    "\n",
    "Flux.@functor BetaProjection\n",
    "\n",
    "struct KGReasoning\n",
    "    nentity::Int\n",
    "    nrelation::Int\n",
    "    hidden_dim::Int\n",
    "    epsilon::AbstractFloat\n",
    "    geo::String\n",
    "    use_cuda::Bool\n",
    "    batch_entity_range #TODO type and initialize\n",
    "    query_name_dict::Dict{Tuple, String}\n",
    "    ############################################\n",
    "    gamma # nn.Parameter\n",
    "    embedding_range # nn.Parameter\n",
    "\n",
    "    entity_dim::Int\n",
    "    relation_dim::Int\n",
    "\n",
    "    entity_embedding # nn.Parameter\n",
    "    cen\n",
    "    func\n",
    "    entity_regularizer\n",
    "    projection_regularizer\n",
    "\n",
    "    offset_embedding\n",
    "    center_net\n",
    "    offset_net\n",
    "    #hidden_dim\n",
    "    num_layers\n",
    "    #center_net\n",
    "    projection_net\n",
    "end\n",
    "\n",
    "Flux.@functor KGReasoning\n",
    "\n",
    "function KGReasoning(nentity, nrelation, hidden_dim, gamma, geo, test_batch_size=1,\n",
    "                     box_mode=nothing, beta_mode=nothing, query_name_dict=nothing, use_cuda=false)\n",
    "    epsilon = 2.0\n",
    "\n",
    "    batch_entity_range = repeat(convert.(Float32, range(0, nentity - 1)), 1, test_batch_size)\n",
    "\n",
    "    gamma = Zygote.Params([gamma])\n",
    "    embedding_range = Zygote.Params([(gamma .+ epsilon) / hidden_dim]);\n",
    "\n",
    "    entity_dim = hidden_dim\n",
    "    relation_dim = hidden_dim\n",
    "\n",
    "    activation, cen, func = repeat([nothing], 3)\n",
    "    entity_embedding , entity_regularizer, projection_regularizer = repeat([nothing], 3)\n",
    "    if geo == \"box\"\n",
    "        entity_embedding = Zygote.Params(zeros(nentity, entity_dim)) # centor for entities\n",
    "        activation, cen = box_mode\n",
    "        cen = cen # hyperparameter that balances the in-box distance and the out-box distance\n",
    "        if activation == \"none\"\n",
    "            func = Identity;\n",
    "        elseif activation == \"relu\"\n",
    "            func = Flux.relu;\n",
    "        elseif activation == \"softplus\"\n",
    "            func = Flux.softplus;\n",
    "        end\n",
    "    elseif geo == \"vec\"\n",
    "        #entity_embedding = Flux.params(zeros(nentity, entity_dim)) # center for entities\n",
    "        entity_embedding = Zygote.Params(Flux.glorot_uniform(nentity, entity_dim))\n",
    "    elseif geo == \"beta\"\n",
    "        #entity_embedding = Flux.params(zeros(nentity, self.entity_dim * 2)) # alpha and beta\n",
    "        entity_embedding = Zygote.Params(Flux.glorot_uniform(nentity, entity_dim * 2))\n",
    "        entity_regularizer = Regularizer(1, 0.05, 1e9) # make sure the parameters of beta embeddings are positive\n",
    "        projection_regularizer = Regularizer(1, 0.05, 1e9) # make sure the parameters of beta embeddings after relation projection are positive\n",
    "    end\n",
    "    #nn.init.uniform_(\n",
    "    #    tensor=self.entity_embedding,\n",
    "    #    ###########################TODO##################################\n",
    "    #    a = -embedding_range,\n",
    "    #    b = embedding_range\n",
    "    #)\n",
    "    #relation_embedding = Flux.params(zeros(nrelation, relation_dim))\n",
    "    relation_embedding = Zygote.Params(Flux.glorot_uniform(nrelation, relation_dim))\n",
    "    #nn.init.uniform_(\n",
    "    #    tensor=relation_embedding,\n",
    "    #    a = -embedding_range,\n",
    "    #    b = embedding_range\n",
    "    #)\n",
    "\n",
    "    num_layers, offset_embedding, center_net, offset_net, projection_net = repeat([nothing], 6)\n",
    "    if geo == \"box\"\n",
    "        offset_embedding = Zygote.Params(Flux.glorot_uniform(nrelation, entity_dim))\n",
    "        #self.offset_embedding = nn.Parameter(torch.zeros(nrelation, self.entity_dim))\n",
    "        #nn.init.uniform_(\n",
    "        #    tensor=self.offset_embedding,\n",
    "        #    a=0.,\n",
    "        #    b=self.embedding_range.item()\n",
    "        #)\n",
    "        center_net = CenterIntersection(entity_dim)\n",
    "        offset_net = BoxOffsetIntersection(entity_dim)\n",
    "    elseif geo == \"vec\"\n",
    "        center_net = CenterIntersection(entity_dim)\n",
    "    elseif geo == \"beta\"\n",
    "        hidden_dim, num_layers = eval_tuple(beta_mode)\n",
    "\n",
    "        center_net = BetaIntersection(entity_dim)\n",
    "        projection_net = BetaProjection(entity_dim * 2,\n",
    "                                        relation_dim,\n",
    "                                        hidden_dim,\n",
    "                                        projection_regularizer,\n",
    "                                        num_layers)\n",
    "    end\n",
    "\n",
    "    return KGReasoning(nentity, nrelation, hidden_dim, epsilon, geo, use_cuda, batch_entity_range,\n",
    "                       query_name_dict, gamma, embedding_range, entity_dim, relation_dim, entity_embedding,\n",
    "                       cen, func, entity_regularizer, projection_regularizer, offset_embedding,\n",
    "                       center_net, offset_net, num_layers, projection_net);\n",
    "end\n",
    "\n",
    "function forward(m::KGReasoning, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    if m.geo == \"box\"\n",
    "        return forward_box(m, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    elseif m.geo == \"vec\"\n",
    "        return forward_vec(m, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    elseif m.geo == \"beta\"\n",
    "        return forward_beta(m, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    end\n",
    "end\n",
    "\n",
    "####\n",
    "# embed a batch of queries with same structure using Query2box\n",
    "# queries: a flattened batch of queries\n",
    "####\n",
    "function embed_query_box(m::KGReasoning, queries, query_structure, idx)\n",
    "    #@printf (queries)\n",
    "    #@printf (query_structure)\n",
    "    all_relation_flag = true\n",
    "     # whether the current query tree has mfferged to one branch and only need to do relation traversal,\n",
    "     # e.g., path queries or conjunctive queries after the intersection\n",
    "    for r in last(query_structure)\n",
    "        if !(r in [\"r\", \"n\"])\n",
    "            all_relation_flag = false\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if all_relation_flag\n",
    "        if query_structure[0] == \"e\"\n",
    "            embedding = m.entity_embedding[:, queries[:, idx]]\n",
    "            #embedding = torch.index_select(m.entity_embedding, dim=0, index=queries[:, idx])\n",
    "            offset_embedding = zeros(size(embedding))\n",
    "            if m.use_cuda\n",
    "                offset_embedding = zeros(size(embedding)) .|> gpu\n",
    "            end\n",
    "            idx += 1\n",
    "        else\n",
    "            embedding, offset_embedding, idx = embed_query_box(m, queries, query_structure[0], idx)\n",
    "        end\n",
    "\n",
    "        for i in range(1, length(last(query_structure)))\n",
    "            if last(query_structure)[i] == \"n\"\n",
    "                @assert false \"box cannot handle queries with negation\"\n",
    "            else\n",
    "                r_embedding = m.ralation_embedding[:, queries[:, idx]]\n",
    "                #r_embedding = torch.index_select(self.relation_embedding, dim=0, index=queries[:, idx])\n",
    "                r_offset_embedding = offset_bedding[:, queries[:, idx]]\n",
    "                #r_offset_embedding = torch.index_select(self.offset_embedding, dim=0, index=queries[:, idx])\n",
    "                embedding += r_embedding\n",
    "                offset_embedding += m.func(r_offset_embedding)\n",
    "            end\n",
    "            idx += 1\n",
    "        end\n",
    "    else\n",
    "        embedding_list = []\n",
    "        offset_embedding_list = []\n",
    "        for i in range(1, length(query_structure))\n",
    "            embedding, offset_embedding, idx = embed_query_box(m, queries, query_structure[i], idx)\n",
    "            push!(embedding_list, embedding)\n",
    "            push!(offset_embedding_list, offset_embedding)\n",
    "        end\n",
    "        embedding = m.center_net(vcat(embedding_list))\n",
    "        offset_embedding = m.offset_net(vcat(offset_embedding_list))\n",
    "    end\n",
    "    return embedding, offset_embedding, idx\n",
    "end\n",
    "\n",
    "#=\n",
    "Iterative embed a batch of queries with same structure using GQE\n",
    "queries: a flattened batch of queries\n",
    "=#\n",
    "function embed_query_vec(m::KGReasoning, queries, query_structure, idx)\n",
    "\n",
    "    all_relation_flag = true\n",
    "    # whether the current query tree has merged to one branch and only need to do relation traversal,\n",
    "    # e.g., path queries or conjunctive queries after the intersection\n",
    "    for ele in last(query_structure)\n",
    "        if !(ele in [\"r\", \"n\"])\n",
    "            all_relation_flag = false\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    if all_relation_flag\n",
    "        if query_structure[1] == \"e\"\n",
    "            embedding = m.entity_embedding[:,queries[:, idx]]\n",
    "            #embedding = torch.index_select(self.entity_embedding, dim=0, index=queries[:, idx])\n",
    "            idx += 1\n",
    "        else\n",
    "            embedding, idx = embed_query_vec(m, queries, query_structure[0], idx)\n",
    "        end\n",
    "\n",
    "        for i in range(length(last(query_structure)))\n",
    "            if last(query_structure)[i] == \"n\"\n",
    "                @assert false  \"vec cannot handle queries with negation\"\n",
    "            else\n",
    "                r_embedding = m.relation_embedding[:, queries[:, idx]]\n",
    "                #r_embedding = torch.index_select(self.relation_embedding, dim=0, index=queries[:, idx])\n",
    "                embedding += r_embedding\n",
    "            end\n",
    "            idx += 1\n",
    "        end\n",
    "    else\n",
    "        embedding_list = []\n",
    "        for i in range(1, length(query_structure))\n",
    "            embedding, idx = embed_query_vec(m, queries, query_structure[i], idx)\n",
    "            push!(dembedding_list, embedding)\n",
    "        end\n",
    "        embedding = m.center_net(vcat(embedding_list))\n",
    "    end\n",
    "    return embedding, idx\n",
    "end\n",
    "\n",
    "#=\n",
    "Iterative embed a batch of queries with same structure using BetaE\n",
    "queries: a flattened batch of queries\n",
    "=#\n",
    "function embed_query_beta(m::KGReasoning, queries, query_structure, idx)\n",
    "\n",
    "    all_relation_flag = true\n",
    "    # whether the current query tree has merged to one branch and only need to do relation traversal,\n",
    "    # e.g., path queries or conjunctive queries after the intersection\n",
    "    for ele in last(query_structure)\n",
    "        if !(ele in [\"r\", \"n\"])\n",
    "            all_relation_flag = false\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    if all_relation_flag\n",
    "        if query_structure[1] == \"e\"\n",
    "            embedding = m.entity_regularizer(selectdim(m.entity_embedding, dims=ndims(m.entity_embedding), queries[:, idx]))\n",
    "            #embedding = m.entity_regularizer(torch.index_select(self.entity_embedding, dim=0, index=queries[:, idx]))\n",
    "            idx += 1\n",
    "        else\n",
    "            alpha_embedding, beta_embedding, idx = m.embed_query_beta(m, queries, query_structure[1], idx)\n",
    "            embedding = cat(alpha_embedding, beta_embedding, dim=0)\n",
    "        end\n",
    "        for i in range(1, length(last(query_structure)))\n",
    "            if last(query_structure)[i] == \"n\"\n",
    "                @assert (queries[:, idx] == -2).all()\n",
    "                embedding = 1 ./ embedding\n",
    "            else\n",
    "                r_embedding = m.relation_embedding(queries[:, idx], :)\n",
    "                #r_embedding = torch.index_select(self.relation_embedding, dim=0, index=queries[:, idx])\n",
    "                embedding = m.projection_net(embedding, r_embedding)\n",
    "            end\n",
    "            idx += 1\n",
    "        end\n",
    "        ###############################TODO####################################\n",
    "        alpha_embedding, beta_embedding = chunk(embedding, 2, dim=ndims(embedding))\n",
    "    else\n",
    "        alpha_embedding_list = []\n",
    "        beta_embedding_list = []\n",
    "        for i in range(1, length(query_structure))\n",
    "            alpha_embedding, beta_embedding, idx = embed_query_beta(m, queries, query_structure[i], idx)\n",
    "            push!(alpha_embedding_list, alpha_embedding)\n",
    "            push!(beta_embedding_list, beta_embedding)\n",
    "        end\n",
    "        alpha_embedding, beta_embedding = m.center_net(cat(alpha_embedding_list), cat(beta_embedding_list))\n",
    "    end\n",
    "    return alpha_embedding, beta_embedding, idx\n",
    "end\n",
    "\n",
    "#============================================\n",
    "    transform 2u queries to two 1p queries\n",
    "    transform up queries to two 2p queries\n",
    "============================================#\n",
    "function transform_union_query(m::KGReasoning, queries, query_structure)\n",
    "\n",
    "    if m.query_name_dict[query_structure] == \"2u-DNF\"\n",
    "        queries = queries[:, 1:(size(queries, 2) - 1)] # remove union -1\n",
    "    elseif m.query_name_dict[query_structure] == \"up-DNF\"\n",
    "        queries = cat(cat(queries[:, 1:2], queries[:, 5:6], dims=1), cat(queries[:, 2:4], queries[:, 5:6], dims=1), dims=1)\n",
    "    end\n",
    "    queries = reshape(queries, :, size(queries)[1]*2)\n",
    "    return queries\n",
    "end\n",
    "\n",
    "function transform_union_structure(m::KGReasoning, query_structure)\n",
    "    if m.query_name_dict[query_structure] == \"2u-DNF\"\n",
    "        return (\"e\", (\"r\",))\n",
    "    elseif m.query_name_dict[query_structure] == \"up-DNF\"\n",
    "        return (\"e\", (\"r\", \"r\"))\n",
    "    end\n",
    "end\n",
    "\n",
    "function cal_logit_beta(m::KGReasoning, entity_embedding, query_dist)\n",
    "    ##########################TODO#######################################\n",
    "    alpha_embedding, beta_embedding = chunk(entity_embedding, 2)\n",
    "    entity_dist = Distributions.Beta(alpha_embedding, beta_embedding)\n",
    "    logit = m.gamma - normDims(Distributions.KLDivergence(entity_dist, query_dist), 1)\n",
    "    return logit\n",
    "end\n",
    "\n",
    "function forward_beta(m::KGReasoning, positive_sample, negative_sample, subsampling_weight,\n",
    "                      batch_queries_dict, batch_idxs_dict)\n",
    "    all_idxs, all_alpha_embeddings, all_beta_embeddings = [], [], []\n",
    "    all_union_idxs, all_union_alpha_embeddings, all_union_beta_embeddings = [], [], []\n",
    "    for query_structure in batch_queries_dict\n",
    "        if \"u\" in m.query_name_dict[query_structure] && \"DNF\" in m.query_name_dict[query_structure]\n",
    "            alpha_embedding, beta_embedding, _ = \\\n",
    "                embed_query_beta(m, transform_union_query(m, batch_queries_dict[query_structure],\n",
    "                                                            query_structure),\n",
    "                                 transform_union_structure(m, query_structure),\n",
    "                                 0)\n",
    "            push!(all_union_idxs, batch_idxs_dict[query_structure])\n",
    "            #all_union_idxs.extend(batch_idxs_dict[query_structure])\n",
    "            push!(all_union_alpha_embeddings, alpha_embedding)\n",
    "            push!(all_union_beta_embeddings, beta_embedding)\n",
    "        else\n",
    "            alpha_embedding, beta_embedding, _ = embed_query_beta(m, batch_queries_dict[query_structure],\n",
    "                                                                  query_structure,\n",
    "                                                                  0)\n",
    "            push!(all_idxs, batch_idxs_dict[query_structure])\n",
    "            #all_idxs.extend(batch_idxs_dict[query_structure])\n",
    "            push!(all_alpha_embeddings, alpha_embedding)\n",
    "            push!(all_beta_embeddings, beta_embedding)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if length(all_alpha_embeddings) > 0\n",
    "        #all_alpha_embeddings = torch.cat(all_alpha_embeddings, dim=0).unsqueeze(1)\n",
    "        all_alpha_embeddfings = reduce((x, y) -> cat(x, y, dims=ndims(x)), all_alpha_embeddings)\n",
    "        all_beta_embeddings = reduce(all_beta_embeddings) do x, y\n",
    "                                         cat(x, y, dims=ndims(x))\n",
    "                                     end\n",
    "        all_beta_embeddings= unsqueeze(all_beta_embeddings, dims = ndims(all_beta_embeddings))\n",
    "        all_dists = Distributions.Beta(all_alpha_embeddings, all_beta_embeddings)\n",
    "    end\n",
    "\n",
    "    if len(all_union_alpha_embeddings) > 0\n",
    "        #all_union_alpha_embeddings = torch.cat(all_union_alpha_embeddings, dim=0).unsqueeze(1)\n",
    "        #all_union_beta_embeddings = torch.cat(all_union_beta_embeddings, dim=0).unsqueeze(1)\n",
    "        #all_union_alpha_embeddings = all_union_alpha_embeddings.view(all_union_alpha_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        #all_union_beta_embeddings = all_union_beta_embeddings.view(all_union_beta_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        #all_union_dists = torch.distributions.beta.Beta(all_union_alpha_embeddings, all_union_beta_embeddings)\n",
    "        all_union_alpha_embeddings = reduce(all_union_alpha_embeddings) do x, y\n",
    "                                             cat(x, y, dim=ndims(x))\n",
    "                                         end\n",
    "        #all_union_alpha_embeddings = cat(all_union_alpha_embeddings, dims = ndims(all_union_alpha_embeddings) + 1)\n",
    "        all_union_alpha_embeddings = unsqueeze(all_union_alpha_embeddings, dims = ndims(all_union_alpha_embeddings))\n",
    "        all_union_beta_embeddings = reduce(all_union_beta_embeddings) do x, y\n",
    "                                             cat(x, y, dim=ndims(x))\n",
    "                                         end\n",
    "        all_union_beta_embeddings = unsqueeze(all_union_beta_embeddings, dims = ndims(all_union_beta_embeddings))\n",
    "        #################################################################################################\n",
    "        #all_union_alpha_embeddings = all_union_alpha_embeddings.view(all_union_alpha_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        #all_union_beta_embeddings = all_union_beta_embeddings.view(all_union_beta_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        all_union_alpha_embeddings = reshape(all_union_alpha_embeddings, :, 1, 2,\n",
    "                                             div(size(all_union_alpha_embeddings, ndims(all_union_alpha_embedding)), 2))\n",
    "        all_union_beta_embeddings = reshape(all_union_beta_embeddings, :, 1, 2,\n",
    "                                             div(size(all_union_beta_embeddings, ndims(all_union_beta_embedding)), 2))\n",
    "\n",
    "        all_union_dists = Distributions.Beta(all_union_alpha_embeddings, all_union_beta_embeddings)\n",
    "    end\n",
    "\n",
    "    if typeof(subsampling_weight) != typeof(nothing)\n",
    "        subsampling_weight = subsampling_weight[all_idxs+all_union_idxs]\n",
    "    end\n",
    "\n",
    "    if typeof(positive_sample) != type(None)\n",
    "        if length(all_alpha_embeddings) > 0\n",
    "            positive_sample_regular = positive_sample[all_idxs] # positive samples for non-union queries in this batch\n",
    "            entity_embedding_select = selectdim(m.entity_embedding,\n",
    "                                                ndims(m.entity_embedding),\n",
    "                                                positive_sample_regular);\n",
    "            positive_embedding = m.entity_regularizer(unsqueeze(entity_embedding_select,\n",
    "                                                                ndims(entity_embedding_select)))\n",
    "            positive_logit = cal_logit_beta(m, positive_embedding, all_dists)\n",
    "        else\n",
    "            positive_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_alpha_embeddings) > 0\n",
    "            positive_sample_union = positive_sample[all_union_idxs] # positive samples for union queries in this batch\n",
    "\n",
    "            entity_embedding_select = selectdim(m.entity_embedding,\n",
    "                                                ndims(m.entity_embedding),\n",
    "                                                positive_sample_union);\n",
    "            entity_embedding_select_unsqueeze = unsqueeze(entity_embedding_select,\n",
    "                                                        dims=ndims(entity_embedding_select) - 1);\n",
    "            positive_embedding = m.entity_regularizer(entity_embedding_select_unsqueeze)\n",
    "            positive_union_logit = cal_logit_beta(m, positive_embedding, all_union_dists)\n",
    "            positive_union_logit = max(positive_union_logit, dim=1)[0]\n",
    "        else\n",
    "            positive_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "        positive_logit = cat(positive_logit, positive_union_logit, dims=ndims(positive_logit))\n",
    "    else\n",
    "        positive_logit = nothing\n",
    "    end\n",
    "\n",
    "    if typeof(negative_sample) != typeof(nothing)\n",
    "        if length(all_alpha_embeddings) > 0\n",
    "            negative_sample_regular = negative_sample[all_idxs]\n",
    "            batch_size, negative_size = negative_sample_regular.shape\n",
    "            #negative_embedding = self.entity_regularizer(torch.index_select(self.entity_embedding, dim=0, index=negative_sample_regular.view(-1)).view(batch_size, negative_size, -1))\n",
    "            negative_embedding = m.entity_regularizer(reshape(reshape(selectdim(m.entity_embedding, ndims(m.entity_embedding), negative_sample_regular), :), :, negative_size, batch_size))\n",
    "            negative_logit = cal_logit_beta(m, negative_embedding, all_dists)\n",
    "        else\n",
    "            ########################## TODO ##################################\n",
    "            #negative_logit = torch.Tensor([]).to(self.entity_embedding.device)\n",
    "            negative_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_alpha_embeddings) > 0\n",
    "            negative_sample_union = negative_sample[all_union_idxs]\n",
    "            batch_size, negative_size = size(negative_sample_union)\n",
    "            negative_embedding = m.entity_regularizer(reshape(reshape(selectdim(m.entity_embedding, 0, negative_sample_union), :), (:, negative_size, 1, batch_size)))\n",
    "            negative_union_logit = cal_logit_beta(m, negative_embedding, all_union_dists)\n",
    "            negative_union_logit = max(negative_union_logit, dim=2)[0]\n",
    "        else\n",
    "            ######################### TODO  ###################################\n",
    "            negative_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        negative_logit = cat(negative_logit, negative_union_logit, dim=ndims(negative_logit))\n",
    "    else\n",
    "        negative_logit = nothing\n",
    "    end\n",
    "\n",
    "    return positive_logit, negative_logit, subsampling_weight, all_idxs+all_union_idxs\n",
    "end\n",
    "\n",
    "function cal_logit_box(m::KGReasoning, entity_embedding, query_center_embedding, query_offset_embedding)\n",
    "    delta = abs(entity_embedding - query_center_embedding)\n",
    "    distance_out = Flux.relu(delta - query_offset_embedding)\n",
    "    distance_in = min(delta, query_offset_embedding)\n",
    "    logit = m.gamma - normDims(distance_out, 1; dims=0) - m.cen * normDims(distance_in, 1, dims=0)\n",
    "    return logit\n",
    "end\n",
    "\n",
    "function forward_box(m::KGReasoning, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    all_center_embeddings, all_offset_embeddings, all_idxs = [], [], []\n",
    "    all_union_center_embeddings, all_union_offset_embeddings, all_union_idxs = [], [], []\n",
    "    for query_structure in batch_queries_dict\n",
    "        if \"u\" in m.query_name_dict[query_structure]\n",
    "            center_embedding, offset_embedding, _ = \\\n",
    "                embed_query_box(m, m.transform_union_query(batch_queries_dict[query_structure],\n",
    "                                                                query_structure),\n",
    "                                transform_union_structure(m, query_structure),\n",
    "                                0)\n",
    "            push!(all_union_center_embeddings, center_embedding)\n",
    "            push!(all_union_offset_embeddings, offset_embedding)\n",
    "            push!(all_union_idxs, batch_idxs_dict[query_structure])\n",
    "        else\n",
    "            center_embedding, offset_embedding, _ = embed_query_box(m, batch_queries_dict[query_structure],\n",
    "                                                                    query_structure,\n",
    "                                                                    0)\n",
    "            push!(all_center_embeddings, center_embedding)\n",
    "            push!(all_offset_embeddings, offset_embedding)\n",
    "            push!(all_idxs, batch_idxs_dict[query_structure])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if length(all_center_embeddings) > 0 && length(all_offset_embeddings) > 0\n",
    "        all_center_embeddings_cat = reduce(all_center_embeddings) do x, y\n",
    "                                          cat(x, y, dims=ndims(x))\n",
    "                                    end\n",
    "        all_center_embeddings_cat_unsqueeze = unsqueeze(all_center_embeddings_cat,\n",
    "                                          dims = ndims(all_center_embeddings_cat) - 1)\n",
    "\n",
    "        all_offset_embeddings_cat = reduce(all_offset_embeddings) do x, y\n",
    "                                          cat(x, y, dims=ndims(x))\n",
    "                                    end\n",
    "        all_offset_embeddings_cat_unsqueeze = unsqueeze(all_offset_embeddings_cat,\n",
    "                                                        dims = ndims(all_offset_embeddings_cat) - 1)\n",
    "        #all_offset_embeddings = torch.cat(all_offset_embeddings, dim=0).unsqueeze(1)\n",
    "    end\n",
    "\n",
    "    if length(all_union_center_embeddings) > 0 && length(all_union_offset_embeddings) > 0\n",
    "        #all_union_center_embeddings = torch.cat(all_union_center_embeddings, dim=0).unsqueeze(1)\n",
    "        #all_union_offset_embeddings = torch.cat(all_union_offset_embeddings, dim=0).unsqueeze(1)\n",
    "        all_union_center_embeddings_cat = reduce(all_union_center_embeddings) do x, y\n",
    "                                              cat(x, y, dims=ndims(x))\n",
    "                                          end\n",
    "        all_union_center_embeddings_cat_unsqueeze = unsqueeze(all_union_center_embeddings_cat,\n",
    "                                                              dims = ndims(all_union_center_embeddings_cat) - 1)\n",
    "        all_union_offset_embeddings_cat = reduce(all_union_offset_embeddings) do x, y\n",
    "                                              cat(x, y, dims=ndims(x))\n",
    "                                          end\n",
    "        all_union_offset_embeddings_cat_unsqueeze = unsqueeze(all_union_offset_embeddings_cat,\n",
    "                                                              dims = ndims(all_offset_embeddings_cat) - 1)\n",
    "        #all_union_center_embeddings = all_union_center_embeddings.view(all_union_center_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        #all_union_offset_embeddings = all_union_offset_embeddings.view(all_union_offset_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        all_union_center_embeddings = reshape(all_union_center_embeddings_cat_unsqueeze,\n",
    "                                              :, 1, 2, div(ndims(all_union_center_embeddings_cat_unsqueeze), 2))\n",
    "        all_union_offset_embeddings = reshape(all_union_offset_embeddings_cat_unsqueeze,\n",
    "                                              :, 1, 2, div(ndims(all_union_offset_embeddings_cat_unsqueeze), 2))\n",
    "    end\n",
    "\n",
    "    if typeof(subsampling_weight) != typeof(nothing)\n",
    "        subsampling_weight = subsampling_weight[all_idxs+all_union_idxs]\n",
    "    end\n",
    "\n",
    "    if typeof(positive_sample) != typeof(nothing)\n",
    "        if length(all_center_embeddings) > 0\n",
    "            positive_sample_regular = positive_sample[all_idxs]\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), positive_sample_regular)\n",
    "            positive_embedding = unsqueeze(entity_embedding_select, ndims(entity_embedding_select) - 1)\n",
    "            positive_logit = cal_logit_box(m, positive_embedding, all_center_embeddings, all_offset_embeddings)\n",
    "        else\n",
    "            #positive_logit = torch.Tensor([]).to(self.entity_embedding.device)\n",
    "            positive_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_center_embeddings) > 0\n",
    "            positive_sample_union = positive_sample[all_union_idxs]\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), positive_sample_union)\n",
    "            entity_embedding_select_unquezze = unsqueeze(entity_embedding_select, ndims(entity_embedding_select) - 1)\n",
    "            positive_embedding = unsqueeze(entity_embedding_select_unquezze, ndims(entity_embedding_select_unquezze) - 1)\n",
    "            positive_union_logit = cal_logit_box(m, positive_embedding, all_union_center_embeddings, all_union_offset_embeddings)\n",
    "            positive_union_logit = max(positive_union_logit, dims=ndims(positive_union_logit) - 1)[1]\n",
    "        else\n",
    "            #positive_union_logit = torch.Tensor([]).to(self.entity_embedding.device)\n",
    "            positive_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "        positive_logit = reduce([positive_logit, positive_union_logit]) do x, y\n",
    "                              cat(x, y, dim=ndims(x))\n",
    "                         end\n",
    "    else\n",
    "        positive_logit = nothing\n",
    "    end\n",
    "\n",
    "    if typeof(negative_sample) != typeof(nothing)\n",
    "        if len(all_center_embeddings) > 0\n",
    "            negative_sample_regular = negative_sample[all_idxs]\n",
    "            batch_size, negative_size = size(negative_sample_regular)\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), reshape(negative_sample_regular, :))\n",
    "            negative_embedding = reshape(entity_embedding_select, :, negative_size, batch_size)\n",
    "            negative_logit = cal_logit_box(m, negative_embedding, all_center_embeddings, all_offset_embeddings)\n",
    "        else\n",
    "            #negative_logit = torch.Tensor([]).to(self.entity_embedding.device)\n",
    "            negative_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_center_embeddings) > 0\n",
    "            negative_sample_union = negative_sample[all_union_idxs]\n",
    "            batch_size, negative_size = size(negative_sample_union)\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), reshape(negative_sample_union, :))\n",
    "            negative_embedding = reshape(entity_embedding_select, :, negative_size, 1, batch_size)\n",
    "            negative_union_logit = cal_logit_box(m, negative_embedding, all_union_center_embeddings, all_union_offset_embeddings)\n",
    "            negative_union_logit = max(negative_union_logit, dims=ndims(negative_union_logit) - 1)[1]\n",
    "        else\n",
    "            #negative_union_logit = torch.Tensor([]).to(self.entity_embedding.device)\n",
    "            negative_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "        negative_logit = reduce([negative_logit, negative_union_logit]) do x, y\n",
    "                              cat(x, y, dim=ndims(x))\n",
    "                         end\n",
    "    else\n",
    "        negative_logit = nothing\n",
    "    end\n",
    "\n",
    "    return positive_logit, negative_logit, subsampling_weight, all_idxs+all_union_idxs\n",
    "end\n",
    "\n",
    "function cal_logit_vec(m::KGReasoning, entity_embedding, query_embedding)\n",
    "    distance = entity_embedding - query_embedding\n",
    "    logit = m.gamma - normDims(distance, 1, dim=2)\n",
    "    return logit\n",
    "end\n",
    "\n",
    "function forward_vec(m::KGReasoning, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    all_center_embeddings, all_idxs = [], []\n",
    "    all_union_center_embeddings, all_union_idxs = [], []\n",
    "    for query_structure in batch_queries_dict\n",
    "        if \"u\" in m.query_name_dict[query_structure]\n",
    "            center_embedding, _ = embed_query_vec(m, transform_union_query(m, batch_queries_dict[query_structure],\n",
    "                                                                           query_structure),\n",
    "                                                  transform_union_structure(query_structure), 0)\n",
    "            push!(all_union_center_embeddings, center_embedding)\n",
    "            append!(all_union_idxs, batch_idxs_dict[query_structure])\n",
    "        else\n",
    "            center_embedding, _ = embed_query_vec(m, batch_queries_dict[query_structure], query_structure, 0)\n",
    "            push!(all_center_embeddings, center_embedding)\n",
    "            append!(all_idxs, batch_idxs_dict[query_structure])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if length(all_center_embeddings) > 0\n",
    "        all_center_embeddings_cat = reduce(all_center_embeddings) do x, y\n",
    "                                        cat(x, y, dims = ndims(x))\n",
    "                                    end\n",
    "        all_center_embeddings = unsqueeze(all_center_embeddings_cat, ndims(all_center_embeddings_cat) - 1)\n",
    "    end\n",
    "\n",
    "    if length(all_union_center_embeddings) > 0\n",
    "        all_union_center_embeddings_cat = reduce(all_union_center_embeddings) do x, y\n",
    "                                              cat(x, y, dims = ndims(x))\n",
    "                                          end\n",
    "        all_union_center_embeddings_unsqueeze = unsqueeze(all_union_center_embeddings_cat, ndims(all_union_center_embeddings_cat) - 1)\n",
    "        #all_union_center_embeddings = torch.cat(all_union_center_embeddings, dim=0).unsqueeze(1)\n",
    "        all_union_center_embeddings = reshape(all_union_center_embeddings_unsqueeze,\n",
    "                                              :, 1, 2, div(size(all_union_center_embeddings,\n",
    "                                                                ndims(all_union_center_embeddings)),\n",
    "                                                           2))\n",
    "    end\n",
    "\n",
    "    if typeof(subsampling_weight) != typeof(nothing)\n",
    "        subsampling_weight = subsampling_weight[all_idxs+all_union_idxs]\n",
    "    end\n",
    "\n",
    "    if typeof(positive_sample) != typeof(nothing)\n",
    "        if length(all_center_embeddings) > 0\n",
    "            positive_sample_regular = positive_sample[all_idxs]\n",
    "            positive_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), positive_sample_regular)\n",
    "            positive_embedding = unsqueeze(positive_embedding_select, ndims(positive_embedding_select) - 1)\n",
    "            positive_logit = cal_logit_vec(m, positive_embedding, all_center_embeddings)\n",
    "        else\n",
    "            positive_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_center_embeddings) > 0\n",
    "            positive_sample_union = positive_sample[all_union_idxs]\n",
    "            positive_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), positive_sample_regular)\n",
    "            positive_embedding_unsqueeze = unsqueeze(positive_embedding_select, ndims(positive_embedding_select) - 1)\n",
    "            positive_embedding = unsqueeze(positive_embedding_unsqueeze, ndims(positive_embedding_unsqueeze) - 1)\n",
    "            positive_union_logit = cal_logit_vec(m, positive_embedding, all_union_center_embeddings)\n",
    "            positive_union_logit = max(positive_union_logit, dims=ndims(positive_union_logit) - 1)[1]\n",
    "        else\n",
    "            positive_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "        positive_logit = reduce([positive_logit, positive_union_logit]) do x, y\n",
    "                             cat(x, y, dims=ndims(x))\n",
    "                         end\n",
    "    else\n",
    "        positive_logit = nothing\n",
    "    end\n",
    "\n",
    "    if typeof(negative_sample) != typeof(nothing)\n",
    "        if length(all_center_embeddings) > 0\n",
    "            negative_sample_regular = negative_sample[all_idxs]\n",
    "            batch_size, negative_size = size(negative_sample_regular)\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, 0, reshape(negative_sample_regular, :))\n",
    "            negative_embedding = reshape(entity_embedding_select, :, negative_size, batch_size)\n",
    "            negative_logit = cal_logit_vec(m, negative_embedding, all_center_embeddings)\n",
    "        else\n",
    "            negative_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_center_embeddings) > 0\n",
    "            negative_sample_union = negative_sample[all_union_idxs]\n",
    "            batch_size, negative_size = size(negative_sample_union)\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding, reshape(negative_sample_union, :)))\n",
    "            negative_embedding = reshape(entity_embedding_select, :, negtive_size, 1, batch_size)\n",
    "            negative_union_logit = cal_logit_vec(m, negative_embedding, all_union_center_embeddings)\n",
    "            negative_union_logit = max(negative_union_logit, dim=ndims(negative_union_logit) -1)[0]\n",
    "        else\n",
    "            negative_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        negative_logit = reduce([negative_logit, negative_union_logit]) do x, y\n",
    "                             cat(x, y, dim=ndims(x))\n",
    "                         end\n",
    "    else\n",
    "        negative_logit = nothing\n",
    "    end\n",
    "\n",
    "    return positive_logit, negative_logit, subsampling_weight, all_idxs+all_union_idxs\n",
    "end\n",
    "#=================================================================================\n",
    "function mean_loss(y_bar)\n",
    "    negative_logsigmoid = Flux.logsigmoid(-y_bar[:negative_logit])\n",
    "    negative_score = mean.(negative_logsigmoid, dims=ndims(negative_logsigmoid))\n",
    "    positive_logsigmoid =Flux.logsigmoid(-y_bar[:positive_logit])\n",
    "    positive_score = squeeze(positive_logsigmoid, dim=ndims(positive_logsigmoid))\n",
    "    positive_sample_loss = - sum(y_bar[:subsampling_weight] * positive_score)\n",
    "    negative_sample_loss = - sum(y_bar[:subsampling_weight] * negative_score)\n",
    "    positive_sample_loss /= sum(y_bar[:subsampling_weight])\n",
    "    negative_sample_loss /= sum(y_bar[:subsampling_weight])\n",
    "\n",
    "    loss = (positive_sample_loss + negative_sample_loss)/2\n",
    "end\n",
    "===============================================================================#\n",
    "\n",
    "function loss()\n",
    "    return 0\n",
    "end\n",
    "\n",
    "# @staticmethod\n",
    "function train_step(model::KGReasoning, opt_state, data, args, step)\n",
    "    #opti_stat = Flux.setup(model, optimizer)\n",
    "\n",
    "    opti_stat = Flux.train!(model, data, opt_state) do\n",
    "\n",
    "        ########################################################################################################\n",
    "        #model.train() # set model as train mode\n",
    "        #optimizer.zero_grad() # clear grad, set to zero\n",
    "\n",
    "        positive_sample, negative_sample, subsampling_weight, batch_queries, query_structures = next(train_iterator)\n",
    "        print(\"train_step chunk :$(batch_queries)\\n state: $(query_structures)\")\n",
    "        #batch_queries_dict = collections.defaultdict(list)\n",
    "        #batch_idxs_dict = collections.defaultdict(list)\n",
    "        batch_queries_dict = Dict{Any, Any}()\n",
    "        batch_idxs_dict = Dict{Any, Any}()\n",
    "        for (i, query) in enumerate(batch_queries) # group queries with same structure\n",
    "            push!(get!(batch_queries_dict, query_structures[i], []), query)\n",
    "            push!(get!(batch_idxs_dict, query_structures[i], []), i)\n",
    "        end\n",
    "\n",
    "        for query_structure in batch_queries_dict\n",
    "            if args[\"cuda\"]\n",
    "                batch_queries_dict[query_structure] = Int64.(batch_queries_dict[query_structure]) .|> gpu\n",
    "            else\n",
    "                batch_queries_dict[query_structure] = Int64.(batch_queries_dict[query_structure])\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if args[\"cuda\"]\n",
    "            positive_sample = positive_sample |> gpu\n",
    "            negative_sample = negative_sample |> gpu\n",
    "            subsampling_weight = subsampling_weight |> gpu\n",
    "        end\n",
    "\n",
    "        opt_grads = Flux.gradient(model) do m\n",
    "            positive_logit, negative_logit,\n",
    "            subsampling_weight, _ = model(positive_sample, negative_sample,\n",
    "                                          subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "            negative_logsigmoid = Flux.logsigmoid(negative_logit)\n",
    "            negative_score = mean.(negative_logsigmoid, dims=ndims(negative_logsigmoid))\n",
    "            positive_logsigmoid =Flux.logsigmoid(positive_logit)\n",
    "            positive_score = squeeze(positive_logsigmoid, dim=ndims(positive_logsigmoid))\n",
    "            positive_sample_loss = - sum(subsampling_weight * positive_score)\n",
    "            negative_sample_loss = - sum(subsampling_weight * negative_score)\n",
    "            positive_sample_loss /= sum(subsampling_weight)\n",
    "            negative_sample_loss /= sum(subsampling_weight)\n",
    "\n",
    "            loss = (positive_sample_loss + negative_sample_loss)/2\n",
    "        end\n",
    "    end\n",
    "    #=========================================================================\n",
    "    negative_score = F.logsigmoid(-negative_logit).mean(dim=1)\n",
    "    positive_score = F.logsigmoid(positive_logit).squeeze(dim=1)\n",
    "    positive_sample_loss = - (subsampling_weight * positive_score).sum()\n",
    "    negative_sample_loss = - (subsampling_weight * negative_score).sum()\n",
    "    positive_sample_loss /= subsampling_weight.sum()\n",
    "    negative_sample_loss /= subsampling_weight.sum()\n",
    "\n",
    "    loss = (positive_sample_loss + negative_sample_loss)/2\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    ==========================================================================#\n",
    "    log = Dict{\n",
    "        \"positive_sample_loss\": positive_sample_loss.item(),\n",
    "        \"negative_sample_loss\": negative_sample_loss.item(),\n",
    "        \"loss\": loss.item(),\n",
    "    }\n",
    "    return log\n",
    "end\n",
    "\n",
    "#@staticmethod\n",
    "function test_step(model, easy_answers, hard_answers, args, test_dataloader, query_name_dict, save_result=False, save_str=\"\", save_empty=False)\n",
    "#    model.eval()\n",
    "\n",
    "    step = 0\n",
    "    total_steps = length(test_dataloader)\n",
    "    #logs = collections.defaultdict(list)\n",
    "    logs = Dict()\n",
    "\n",
    "    #with torch.no_grad():\n",
    "    for (negative_sample, queries, queries_unflatten, query_structures) in tqdm(test_dataloader)\n",
    "        batch_queries_dict = Dict() #collections.defaultdict(list)\n",
    "        batch_idxs_dict = Dict() #collections.defaultdict(list)\n",
    "        for (i, query) in enumerate(queries)\n",
    "            push!(batch_queries_dict[query_structures[i]], query)\n",
    "            push!(batch_idxs_dict[query_structures[i]], i)\n",
    "        end\n",
    "\n",
    "        for query_structure in batch_queries_dict\n",
    "            if args[\"cuda\"]\n",
    "                batch_queries_dict[query_structure] = Int64.(batch_queries_dict[query_structure]) .|> gpu\n",
    "            else\n",
    "                batch_queries_dict[query_structure] = Int64.(batch_queries_dict[query_structure])\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if args[\"cuda\"]\n",
    "            negative_sample = negative_sample .|> gpu\n",
    "        end\n",
    "\n",
    "        _, negative_logit, _, idxs = model(None, negative_sample, None, batch_queries_dict, batch_idxs_dict)\n",
    "        queries_unflatten = [queries_unflatten[i] for i in idxs]\n",
    "        query_structures = [query_structures[i] for i in idxs]\n",
    "        argsort = sortperm(negative_logit, dim=ndims(negative_logit)-1, rev=true)\n",
    "        ranking = Float32.(copy(argsort))\n",
    "        if length(argsort) == args[\"test_batch_size\"] # if it is the same shape with test_batch_size, we can reuse batch_entity_range without creating a new one\n",
    "            #ranking = ranking.scatter_(1, argsort, model.batch_entity_range) # achieve the ranking of all entities\n",
    "            ranking = getindex(model.batch_entity_range, argsort)\n",
    "        else # otherwise, create a new torch Tensor for batch_entity_range\n",
    "            if args[\"cuda\"]\n",
    "                #ranking = ranking.scatter_(1,\n",
    "                #                           argsort,\n",
    "                #                           torch.arange(model.nentity).to(torch.float).repeat(argsort.shape[0],\n",
    "                #                                                                              1).cuda()\n",
    "                #                           ) # achieve the ranking of all entities\n",
    "                target = repeat(Float32.(collect(1:model.nentity)), 1, size(argsort, ndims(argsort)))\n",
    "                ranking = getindex(argsort, target) |> gpu\n",
    "            else\n",
    "                #ranking = ranking.scatter_(1,\n",
    "                #                           argsort,\n",
    "                #                           torch.arange(model.nentity).to(torch.float).repeat(argsort.shape[0],\n",
    "                #                                                                              1)\n",
    "                #                           ) # achieve the ranking of all entities\n",
    "                target = repeat(Float32.(collect(1:model.nentity)), 1, size(argsort, ndims(argsort)))\n",
    "                ranking = getindex(argsort, target)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        for (idx, (i, query, query_structure)) in enumerate(zip(argsort[:, ndims(argsort)], queries_unflatten, query_structures))\n",
    "            hard_answer = hard_answers[query]\n",
    "            easy_answer = easy_answers[query]\n",
    "            num_hard = length(hard_answer)\n",
    "            num_easy = length(easy_answer)\n",
    "            @assert length(hard_answer.intersection(easy_answer)) == 0\n",
    "            cur_ranking = ranking[idx, list(easy_answer) + list(hard_answer)]\n",
    "            cur_ranking, indices = sortperm(cur_ranking)\n",
    "            masks = indices >= num_easy\n",
    "            if args[\"cuda\"]\n",
    "                answer_list = Float32.(collect(1:(num_hard + num_easy))) .|> gpu\n",
    "            else\n",
    "                answer_list = Float32.(collect(1:(num_hard + num_easy)))\n",
    "            end\n",
    "            cur_ranking = cur_ranking .- answer_list + 1 # filtered setting\n",
    "            cur_ranking = cur_ranking[masks] # only take indices that belong to the hard answers\n",
    "\n",
    "            mrr = collect(mean(1 ./ cur_ranking))\n",
    "            h1 = collect(Float32.(mean((cur_ranking <= 1))))\n",
    "            h3 = collect(Float32.(mean((cur_ranking <= 3))))\n",
    "            h10 = collect(Float32.(mean((cur_ranking <= 10))))\n",
    "\n",
    "            push!(get!(logs, query_structure, Dict()), Dict(\n",
    "                \"MRR\"=> mrr,\n",
    "                \"HITS1\"=> h1,\n",
    "                \"HITS3\"=> h3,\n",
    "                \"HITS10\"=> h10,\n",
    "                \"num_hard_answer\"=> num_hard\n",
    "            ))\n",
    "        end\n",
    "\n",
    "        if step % args.test_log_steps == 0\n",
    "            @info(\"Evaluating the model... ($step/$total_steps)\")\n",
    "        end\n",
    "        step += 1\n",
    "    end\n",
    "\n",
    "    #metrics = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "    metrics = Dict()\n",
    "    for query_structure in logs\n",
    "        for metric in keys(logs[query_structure][0])\n",
    "            if metric in [\"num_hard_answer\"]\n",
    "                continue\n",
    "            end\n",
    "            metrics[:query_structure][:metric] = sum([log[metric] for log in logs[query_structure]])/length(logs[query_structure])\n",
    "        end\n",
    "        metrics[:query_structure][\"num_queries\"] = length(logs[query_structure])\n",
    "    end\n",
    "\n",
    "    return metrics\n",
    "end\n",
    "\n",
    "end #end module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d72ac1d9-3402-4f31-9c64-373b7fca53e7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module KGDataset.\n",
      "WARNING: using KGDataset.load_data in module Main conflicts with an existing identifier.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "main (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Revise\n",
    "\n",
    "using MLUtils\n",
    "using Random\n",
    "using ArgParse\n",
    "using LoggingExtras, TensorBoardLogger\n",
    "using Dates\n",
    "using Flux, JLD2\n",
    "\n",
    "#println(\"working directory: {$(pwd())}\")\n",
    "\n",
    "include(\"src/dataloader.jl\")\n",
    "include(\"src/model.jl\")\n",
    "include(\"src/utils.jl\")\n",
    "\n",
    "using .KGDataset\n",
    "using .KGModel\n",
    "\n",
    "f_dir = \"dataset\";\n",
    "f_model = \"FB15k-betae\";\n",
    "\n",
    "query_name_dict = Dict{Tuple, String}((\"e\",(\"r\",))=> \"1p\",\n",
    "                                      (\"e\", (\"r\", \"r\"))=> \"2p\",\n",
    "                                      (\"e\", (\"r\", \"r\", \"r\"))=> \"3p\",\n",
    "                                      ((\"e\", (\"r\",)), (\"e\", (\"r\",)))=> \"2i\",\n",
    "                                      ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"e\", (\"r\",)))=> \"3i\",\n",
    "                                      (((\"e\", (\"r\",)), (\"e\", (\"r\",))), (\"r\",))=> \"ip\",\n",
    "                                      ((\"e\", (\"r\", \"r\")), (\"e\", (\"r\",)))=> \"pi\",\n",
    "                                      ((\"e\", (\"r\",)), (\"e\", (\"r\", \"n\")))=> \"2in\",\n",
    "                                      ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"e\", (\"r\", \"n\")))=> \"3in\",\n",
    "                                      (((\"e\", (\"r\",)), (\"e\", (\"r\", \"n\"))), (\"r\",))=> \"inp\",\n",
    "                                      ((\"e\", (\"r\", \"r\")), (\"e\", (\"r\", \"n\")))=> \"pin\",\n",
    "                                      ((\"e\", (\"r\", \"r\", \"n\")), (\"e\", (\"r\",)))=> \"pni\",\n",
    "                                      ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"u\",))=> \"2u-DNF\",\n",
    "                                      (((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"u\",)), (\"r\",))=> \"up-DNF\",\n",
    "                                      (((\"e\", (\"r\", \"n\")), (\"e\", (\"r\", \"n\"))), (\"n\",))=> \"2u-DM\",\n",
    "                                      (((\"e\", (\"r\", \"n\")), (\"e\", (\"r\", \"n\"))), (\"n\", \"r\"))=> \"up-DM\"\n",
    "                                      );\n",
    "name_query_dict = Dict{String, Tuple}((y => x) for (x, y) in query_name_dict);\n",
    "all_tasks = collect(keys(name_query_dict));\n",
    "\n",
    "function parse_cmdargs(args::Vector{String})\n",
    "    s = ArgParseSettings(\n",
    "        description = \"Training and Testing Knowledge Graph Embedding Models\",\n",
    "        usage = \"julia --project=[/path/to/project] src/$(@__FILE__) [<args>] [-h | --help]\"\n",
    "    )\n",
    "\n",
    "    @add_arg_table s begin\n",
    "        \"--cuda\"\n",
    "        action= :store_true\n",
    "        help=\"use GPU\"\n",
    "        \"--train\"\n",
    "        action= :store_true\n",
    "        help=\"do train\"\n",
    "        \"--valid\"\n",
    "        action= :store_true\n",
    "        help=\"do valid\"\n",
    "        \"--test\"\n",
    "        action= :store_true\n",
    "        help=\"do test\"\n",
    "        \"--data_path\"\n",
    "        arg_type=String\n",
    "        default= nothing\n",
    "        help=\"KG data path\"\n",
    "        \"-n\", \"--negative_sample_size\"\n",
    "        default=128\n",
    "        arg_type=Int\n",
    "        help=\"negative entities sampled per query\"\n",
    "        \"-d\", \"--hidden_dim\"\n",
    "        default=500\n",
    "        arg_type=Int\n",
    "        help=\"embedding dimension\"\n",
    "        \"-g\", \"--gamma\"\n",
    "        default=12.0\n",
    "        arg_type=Float64\n",
    "        help=\"margin in the loss\"\n",
    "        \"-b\", \"--batch_size\"\n",
    "        default=1024\n",
    "        arg_type=Int\n",
    "        help=\"batch size of queries\"\n",
    "        \"--test_batch_size\"\n",
    "        default=1\n",
    "        arg_type=Int\n",
    "        help=\"valid/test batch size\"\n",
    "        \"--learning_rate\"\n",
    "        default=0.0001\n",
    "        arg_type=Float64\n",
    "        \"--cpu\"\n",
    "        default=10\n",
    "        arg_type=Int\n",
    "        help=\"used to speed up torch.dataloader\"\n",
    "        \"--save_path\"\n",
    "        default=\".\"\n",
    "        arg_type=String\n",
    "        help=\"no need to set manually, will configure automatically\"\n",
    "        \"--max_steps\"\n",
    "        default=100000\n",
    "        arg_type=Int\n",
    "        help=\"maximum iterations to train\"\n",
    "        \"--warm_up_steps\"\n",
    "        default=nothing\n",
    "        arg_type=Int\n",
    "        help=\"no need to set manually, will configure automatically\"\n",
    "        \"--save_checkpoint_steps\"\n",
    "        default=50000\n",
    "        arg_type=Int\n",
    "        help=\"save checkpoints every xx steps\"\n",
    "        \"--valid_steps\"\n",
    "        default=10000\n",
    "        arg_type=Int\n",
    "        help=\"evaluate validation queries every xx steps\"\n",
    "        \"--log_steps\"\n",
    "        default=100\n",
    "        arg_type=Int\n",
    "        help=\"train log every xx steps\"\n",
    "        \"--test_log_steps\"\n",
    "        default=1000\n",
    "        arg_type=Int\n",
    "        help=\"valid/test log every xx steps\"\n",
    "        \"--nentity\"\n",
    "        arg_type=Int\n",
    "        default=0\n",
    "        help=\"DO NOT MANUALLY SET\"\n",
    "        \"--nrelation\"\n",
    "        arg_type=Int\n",
    "        default=0\n",
    "        help=\"DO NOT MANUALLY SET\"\n",
    "        \"--geo\"\n",
    "        default=\"vec\"\n",
    "        arg_type=String\n",
    "        help=\"the reasoning model, vec for GQE, box for Query2box, beta for BetaE\"\n",
    "        \"--print_on_screen\"\n",
    "        action= :store_false\n",
    "        \"--tasks\"\n",
    "        default=\"1p.2p.3p.2i.3i.ip.pi.2in.3in.inp.pin.pni.2u.up\"\n",
    "        arg_type=String\n",
    "        help=\"tasks connected by dot, refer to the BetaE paper for detailed meaning and structure of each task\"\n",
    "        \"--seed\"\n",
    "        default=0\n",
    "        arg_type=Int\n",
    "        help=\"random seed\"\n",
    "        \"--beta_mode\"\n",
    "        default=\"(1600,2)\"\n",
    "        arg_type=String\n",
    "        help=\"(hidden_dim,num_layer) for BetaE relational projection\"\n",
    "        \"--box_mode\"\n",
    "        default=\"(nothing,0.02)\"\n",
    "        arg_type=String\n",
    "        help=\"(offset activation,center_reg) for Query2box, center_reg balances the in_box dist and out_box dist\"\n",
    "        \"--prefix\"\n",
    "        default=nothing\n",
    "        arg_type=String\n",
    "        help=\"prefix of the log path\"\n",
    "        \"--checkpoint_path\"\n",
    "        default=nothing\n",
    "        arg_type=String\n",
    "        help=\"path for loading the checkpoints\"\n",
    "        \"--evaluate_union\"\n",
    "        default=\"DNF\"\n",
    "        arg_type=String\n",
    "        help=\"the way to evaluate union queries, transform it to disjunctive normal form (DNF) or use the De Morgan\\\"s laws (DM)\"\n",
    "    end\n",
    "\n",
    "    return parse_args(args, s)\n",
    "end\n",
    "\n",
    "#=\"\"\"\n",
    "Write logs to console and log file\n",
    "\"\"\"=#\n",
    "function set_logger(args)\n",
    "\n",
    "    if args[\"train\"] == true\n",
    "        log_file = joinpath(args[\"save_path\"], \"train.log\")\n",
    "    else\n",
    "        log_file = joinpath(args[\"save_path\"], \"test.log\")\n",
    "    end\n",
    "\n",
    "    log_io = open(log_file, \"w\");\n",
    "    datefmt=DateFormat(\"YY-mm-dd HH:MM:SS\");\n",
    "\n",
    "    timestamp_logger(logger) = TransformerLogger(logger) do log\n",
    "        merge(log, (; message = \"$(Dates.format(now(), datefmt)) $(log.message)\"))\n",
    "    end\n",
    "\n",
    "    file_logger = timestamp_logger(FileLogger(log_file));\n",
    "    global_logger(file_logger)\n",
    "\n",
    "    if args[\"print_on_screen\"]\n",
    "        time_loger = timestamp_logger(ConsoleLogger(stdout, Logging.Info));\n",
    "\n",
    "        tl = TeeLogger(file_logger, time_loger);\n",
    "        global_logger(tl)\n",
    "    end\n",
    "end\n",
    "\n",
    "#=\"\"\"\n",
    "Print the evaluation logs\n",
    "\"\"\"=#\n",
    "function log_metrics(mode, step, metrics)\n",
    "    for metric in metrics\n",
    "        @info \"$mode $metric at step $(step): $(metrics[metric.first])\"\n",
    "    end\n",
    "end\n",
    "\n",
    "#=\"\"\"\n",
    "Evaluate queries in dataloader\n",
    "\"\"\"=#\n",
    "function evaluate(model, tp_answers, fn_answers, args, dataloader, query_name_dict, mode, step, writer)\n",
    "\n",
    "    average_metrics = Dict{Float}()\n",
    "    all_metrics = Dict{Float}()\n",
    "\n",
    "    metrics = model.test_step(model, tp_answers, fn_answers, args, dataloader, query_name_dict)\n",
    "    num_query_structures = 0\n",
    "    num_queries = 0\n",
    "    for query_structure in metrics\n",
    "        log_metrics(mode * \" \" * query_name_dict[query_structure], step, metrics[query_structure])\n",
    "\n",
    "        for metric in metrics[query_structure]\n",
    "            writer.add_scalar(\"_\".join([mode, query_name_dict[query_structure], metric]), metrics[query_structure][metric], step)\n",
    "            all_metrics[\"_\".join([query_name_dict[query_structure], metric])] = metrics[query_structure][metric]\n",
    "            if metric != \"num_queries\"\n",
    "                average_metrics[metric] += metrics[query_structure][metric]\n",
    "            end\n",
    "        end\n",
    "        num_queries += metrics[query_structure][\"num_queries\"]\n",
    "        num_query_structures += 1\n",
    "    end\n",
    "\n",
    "    for metric in average_metrics\n",
    "        average_metrics[metric] /= num_query_structures\n",
    "        writer.add_scalar(\"_\".join([mode, \"average\", metric]), average_metrics[metric], step)\n",
    "        all_metrics[\"_\".join([\"average\", metric])] = average_metrics[metric]\n",
    "    end\n",
    "\n",
    "    log_metrics(\"$mode average\", step, average_metrics)\n",
    "    return all_metrics\n",
    "end\n",
    "\n",
    "function main(args)\n",
    "    global train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers\n",
    "\n",
    "    Random.seed!(args[\"seed\"])\n",
    "    tasks = split(args[\"tasks\"], \".\")\n",
    "    for task in tasks\n",
    "        if 'n' in task && args[\"geo\"] in [\"box\", \"vec\"]\n",
    "            @assert false \"Q2B and GQE cannot handle queries with negation\"\n",
    "        end\n",
    "    end\n",
    "    if args[\"evaluate_union\"] == \"DM\"\n",
    "        @assert args[\"geo\"] == \"beta\" \"only BetaE supports modeling union using De Morgan's Laws\"\n",
    "    end\n",
    "\n",
    "    cur_time = format_time()\n",
    "    if args[\"prefix\"] == nothing\n",
    "        prefix = \"logs\"\n",
    "    else\n",
    "        prefix = args[\"prefix\"]\n",
    "    end\n",
    "\n",
    "    @info (\"overwritting saving path: $(args[\"save_path\"])\")\n",
    "    args[\"save_path\"] = joinpath(prefix, last(split(args[\"data_path\"], \"/\")), args[\"tasks\"], args[\"geo\"])\n",
    "    geo = args[\"geo\"]\n",
    "    if geo in [\"box\"]\n",
    "        save_str = \"g-$(args[\"gamma\"])-mode-$(args[\"box_mode\"])\"\n",
    "    elseif geo in [\"vec\"]\n",
    "        save_str = \"g-$(args[\"gamma\"])\"\n",
    "    elseif geo == \"beta\"\n",
    "        save_str = \"g-$(args[\"gamma\"])-mode-$(args[\"beta_mode\"])\"\n",
    "    end\n",
    "\n",
    "    if args[\"checkpoint_path\"] != nothing\n",
    "        args[\"save_path\"] = args[\"checkpoint_path\"]\n",
    "    else\n",
    "        args[\"save_path\"] = joinpath(args[\"save_path\"], save_str, cur_time)\n",
    "    end\n",
    "\n",
    "    if ! ispath(args[\"save_path\"])\n",
    "        mkpath(args[\"save_path\"])\n",
    "    end\n",
    "\n",
    "    @info (\"logging to $(args[\"save_path\"])\")\n",
    "    if ! args[\"train\"] # if not training, then create tensorboard files in some tmp location\n",
    "        writer = TBLogger(\"./logs-debug/unused-tb\")\n",
    "    else\n",
    "        writer = TBLogger(args[\"save_path\"])\n",
    "    end\n",
    "    set_logger(args)\n",
    "\n",
    "    nentity, nrelation = open(joinpath(args[\"data_path\"], \"stats.txt\")) do f\n",
    "        entrel = readlines(f)\n",
    "        nentity = parse(Int, last(split(entrel[1], \" \")))\n",
    "        nrelation = parse(Int, last(split(entrel[2], \" \")))\n",
    "\n",
    "        (nentity, nrelation)\n",
    "    end\n",
    "\n",
    "    args[\"nentity\"] = nentity\n",
    "    args[\"nrelation\"] = nrelation\n",
    "\n",
    "    @info(repeat(\"-------------------------------\", 2))\n",
    "    @info(\"Geo: $(args[\"geo\"])\")\n",
    "    @info(\"Data Path: $(args[\"data_path\"])\")\n",
    "    @info(\"#entity: $(nentity)\")\n",
    "    @info(\"#relation: $(nrelation)\")\n",
    "    @info(\"#max steps: $(args[\"max_steps\"])\")\n",
    "    @info(\"Evaluate unoins using: $(args[\"evaluate_union\"])\")\n",
    "\n",
    "    #train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers,\n",
    "    #test_queries, test_hard_answers, test_easy_answers = KGDataset.load_data(args, name_query_dict)\n",
    "\n",
    "    local train_path_iterator, train_other_iterator\n",
    "    if args[\"train\"]\n",
    "        @info(\"Train asked...\")\n",
    "        train_path_queries = Dict{Any, Set}()\n",
    "        train_other_queries = Dict{Any, Set}()\n",
    "        query_path_list = [\"1p\", \"2p\", \"3p\"]\n",
    "        for query_structure in keys(train_queries)\n",
    "            print(query_structure)\n",
    "            if query_name_dict[query_structure] in query_path_list\n",
    "                train_path_queries[query_structure] = train_queries[query_structure]\n",
    "            else\n",
    "                train_other_queries[query_structure] = train_queries[query_structure]\n",
    "            end\n",
    "        end\n",
    "\n",
    "        train_path_queries = flatten_query(train_path_queries)\n",
    "        @info \"Flatten query length: $(length(train_path_queries)) typeof(query) $(typeof(train_path_queries))\"\n",
    "\n",
    "        train_dataset = KGDataset.TrainDataset(train_path_queries, train_answers, nentity, nrelation, args[\"negative_sample_size\"])\n",
    "        data_loader = MLUtils.DataLoader(train_dataset, batchsize = args[\"batch_size\"], collate = true, shuffle = false);\n",
    "        #for x in data_loader\n",
    "        #    @info \"data_loader loop....\" * \"$(size(x))\"\n",
    "        #end\n",
    "        train_path_iterator = KGDataset.SingleDirectionalOneShotIterator(data_loader);\n",
    "        #            num_workers=args.cpu_num,\n",
    "        #            collate_fn=TrainDataset.collate_fn));\n",
    "\n",
    "        if length(train_other_queries) > 0\n",
    "            train_other_queries = flatten_query(train_other_queries)\n",
    "            train_other_iterator = KGDataset.SingleDirectionalOneShotIterator(\n",
    "                MLUtils.DataLoader(KGDataset.TrainDataset(train_other_queries,\n",
    "                                                          train_answers,\n",
    "                                                          nentity,\n",
    "                                                          nrelation,\n",
    "                                                          args[\"negative_sample_size\"]),\n",
    "                                   batchsize=args[\"batch_size\"],\n",
    "                                   shuffle=true));\n",
    "            #                                       num_workers=args.cpu_num,\n",
    "            #                                       collate_fn=TrainDataset.collate_fn))\n",
    "        else\n",
    "            train_other_iterator = nothing\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if args[\"valid\"]\n",
    "        @info(\"Validation asked...\")\n",
    "\n",
    "        #for query_structure in keys(valid_queries)\n",
    "        #    @info query_name_dict[query_structure] * \": \" * \"$(length(valid_queries[query_structure]))\"\n",
    "        # end\n",
    "        valid_queries2 = flatten_query(valid_queries)\n",
    "        valid_dataloader = KGDataset.DataLoader(KGDataset.TestDataset(valid_queries2, nentity, nrelation),\n",
    "                                                batchsize=args[\"test_batch_size\"]);\n",
    "        #            num_workers=args.cpu_num,\n",
    "        #            collate_fn=TestDataset.collate_fn)\n",
    "    end\n",
    "\n",
    "    if args[\"test\"]\n",
    "        @info(\"Test ...\")\n",
    "\n",
    "        # for query_structure in keys(test_queries)\n",
    "        #    @info query_name_dict[query_structure] * \": \" * \"$(length(test_queries[query_structure]))\"\n",
    "        # end\n",
    "        test_queries = flatten_query(test_queries)\n",
    "        test_dataloader = KGDataset.DataLoader(\n",
    "            KGDataset.TestDataset(test_queries, nentity, nrelation),\n",
    "            batchsize=args[\"test_batch_size\"]);\n",
    "        #         num_workers=args.cpu_num,\n",
    "        #         collate_fn=TestDataset.collate_fn)\n",
    "    end\n",
    "\n",
    "    model = KGModel.KGReasoning(nentity,\n",
    "                                 nrelation,\n",
    "                                 args[\"hidden_dim\"],\n",
    "                                 args[\"gamma\"],\n",
    "                                 args[\"geo\"],\n",
    "                                 args[\"test_batch_size\"],\n",
    "                                 eval_tuple(args[\"box_mode\"]),\n",
    "                                 eval_tuple(args[\"beta_mode\"]),\n",
    "                                 query_name_dict,\n",
    "                                 args[\"cuda\"] == \"Yes\")\n",
    "\n",
    "    @info(\"Model Parameter Configuration:\")\n",
    "    for (lindex,layer) in enumerate(Flux.params(model)) #.named_parameters()\n",
    "        #@info(\"Parameter %s: %s, require_grad = %s\" % (name, str(param.size()), str(param.requires_grad)))\n",
    "        #if param.requires_grad\n",
    "        #    num_params += np.prod(param.size())\n",
    "        #end\n",
    "        num_params = 0\n",
    "        for (pindex, pa) in enumerate(Flux.params(layer))\n",
    "            @info(\"Parameter layer$lindex-$pindex: $(size(pa))\")\n",
    "            num_params += sum(length, Flux.params(layer))\n",
    "        end\n",
    "        @info(\"Parameter Number: $num_params\")\n",
    "    end\n",
    "\n",
    "    if args[\"cuda\"]\n",
    "        model = model.cuda()\n",
    "    end\n",
    "\n",
    "    local init_step, checkpoint, step, current_learning_rate, warn_up_steps\n",
    "    if args[\"train\"]\n",
    "        current_learning_rate = args[\"learning_rate\"]\n",
    "        opt_state = Flux.setup(Flux.Optimise.Adam(current_learning_rate), model)\n",
    "        warn_up_steps = floor(args[\"max_steps\"] / 2)\n",
    "    end\n",
    "\n",
    "    if args[\"checkpoint_path\"] != nothing\n",
    "        @info(\"Loading checkpoint $(args[\"checkpoint_path\"])...\")\n",
    "        checkpoint = Flux.loadmodel!(model, JLD2.load(joinPath(args[\"checkpoint_path\"], \"checkpoint\"), \"model_state\"))\n",
    "        init_step = checkpoint[\"step\"]\n",
    "        Flux.loadmodel!(model, checkpoint[\"model_state_dict\"])\n",
    "        #model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "        if args[\"train\"]\n",
    "            current_learning_rate = checkpoint[\"current_learning_rate\"]\n",
    "            warn_up_steps = checkpoint[\"warn_up_steps\"]\n",
    "            #optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        end\n",
    "        @info(\"Ramdomly Initializing $(args[\"geo\"]) Model...\")\n",
    "    else\n",
    "        @info(\"Ramdomly Initializing $(args[\"geo\"]) Model...\")\n",
    "        init_step = 0\n",
    "    end\n",
    "\n",
    "    step = init_step\n",
    "    if args[\"geo\"] == \"box\"\n",
    "        @info(\"box mode = $(args[\"box_mode\"])\")\n",
    "    elseif args[\"geo\"] == \"beta\"\n",
    "        @info(\"beta mode = $(args[\"beta_mode\"])\")\n",
    "    end\n",
    "    @info(\"tasks = $(args[\"tasks\"])\")\n",
    "    @info(\"init_step = $init_step\")\n",
    "    if args[\"train\"]\n",
    "        @info(\"learning_rate = $current_learning_rate\")\n",
    "    end\n",
    "    @info(\"batch_size = $(args[\"batch_size\"])\")\n",
    "    @info(\"hidden_dim = $(args[\"hidden_dim\"])\")\n",
    "    @info(\"gamma = $(args[\"gamma\"])\")\n",
    "\n",
    "\n",
    "    if args[\"train\"]\n",
    "        @info(\"Start Training...\")\n",
    "        training_logs = []\n",
    "        \n",
    "        # #Training Loop\n",
    "        local path_data; path_next=1; \n",
    "        local other_data; other_next=1;\n",
    "        for step in range(init_step, args[\"max_steps\"])\n",
    "            if step == 2 * floor(args[\"max_steps\"] / 3)\n",
    "                args[\"valid_steps\"] *= 4\n",
    "            end\n",
    "\n",
    "            (path_data, path_next) = iterate(train_path_iterator, path_next)\n",
    "            println(\"path_data: $(path_data),\\n path_next: $(path_next)\")\n",
    "            log = KGModule.train_step(model, opt_state, path_data, args, step)\n",
    "            for metric in log\n",
    "                writer.add_scalar(\"path_\" * metric, log[metric], step)\n",
    "            end\n",
    "            \n",
    "            if train_other_iterator != nothing\n",
    "                (other_data, other_next) = iterate(train_other_iterator, other_next)\n",
    "                log = KGModule.train_step(model, opt_state, other_data, args, step)\n",
    "                for metric in log\n",
    "                    @info \"metric : $(metric)\"\n",
    "                    writer.add_scalar(\"other_\"+metric, log[metric], step)\n",
    "                end\n",
    "                log = KGModule.train_step(model, opt_state, path_data, args, step)\n",
    "            end\n",
    "\n",
    "            training_logs.append(log)\n",
    "\n",
    "            if step >= warn_up_steps\n",
    "                current_learning_rate = current_learning_rate / 5\n",
    "                @info(\"Change learning_rate to $(current_learning_rate) at step $(step)\")\n",
    "\n",
    "                opt_state = Flux.setup(Flux.Optimiser.Adam(lr = current_learning_rate),\n",
    "                                       model)\n",
    "                warn_up_steps = warn_up_steps * 1.5\n",
    "            end\n",
    "\n",
    "            if step % args[\"save_checkpoint_steps\"] == 0\n",
    "                save_variable_list = (\n",
    "                    \"step\": step,\n",
    "                    \"current_learning_rate\": current_learning_rate,\n",
    "                    \"warm_up_steps\": warn_up_steps\n",
    "                )\n",
    "                JLD2.save(model, opt_state, save_variable_list, args)\n",
    "            end\n",
    "\n",
    "            if step % args[\"valid_steps\"] == 0 && step > 0\n",
    "                if args[\"do_valid\"]\n",
    "                    @info(\"Evaluating on Valid Dataset...\")\n",
    "                    valid_all_metrics = evaluate(model, valid_easy_answers, valid_hard_answers, args,\n",
    "                                                 valid_dataloader, query_name_dict, \"Valid\", step, writer)\n",
    "                end\n",
    "\n",
    "                if args[\"do_test\"]\n",
    "                    @info(\"Evaluating on Test Dataset...\")\n",
    "                    test_all_metrics = evaluate(model, test_easy_answers, test_hard_answers, args,\n",
    "                                                test_dataloader, query_name_dict, \"Test\", step, writer)\n",
    "                end\n",
    "            end\n",
    "\n",
    "            if step % args[\"log_steps\"] == 0\n",
    "                metrics = Dict()\n",
    "                for metric in training_logs[0].keys()\n",
    "                    metrics[metric] = sum([log[metric] for log in training_logs])/len(training_logs)\n",
    "                end\n",
    "\n",
    "                log_metrics(\"Training average\", step, metrics)\n",
    "                training_logs = []\n",
    "            end\n",
    "\n",
    "            save_variable_list = (\n",
    "                \"step\": step,\n",
    "                \"current_learning_rate\": current_learning_rate,\n",
    "                \"warm_up_steps\": warn_up_steps\n",
    "            )\n",
    "            JLD2.save(model, opt_state, save_variable_list, args)\n",
    "\n",
    "            try\n",
    "                print(step)\n",
    "            catch\n",
    "                step = 0\n",
    "            end\n",
    "        end\n",
    "        @info(\"Training finished!!\")\n",
    "    end\n",
    "\n",
    "    #    if args[\"test\"]\n",
    "    #        @info(\"Evaluating on Test Dataset...\")\n",
    "    #        test_all_metrics = evaluate(model, test_easy_answers, test_hard_answers, args, test_dataloader, query_name_dict, \"Test\", step, writer)\n",
    "    #    end\n",
    "    #\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fae9d4e0-94a3-4b76-a392-659c9c6ac87d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict{String, Any}(\"geo\" => \"beta\", \"test_log_steps\" => 1000, \"tasks\" => \"1p.2p.3p.2i.3i.ip.pi.2in.3in.inp.pin.pni.2u.up\", \"batch_size\" => 1, \"evaluate_union\" => \"DNF\", \"nentity\" => 0, \"nrelation\" => 0, \"print_on_screen\" => true, \"cpu\" => 1, \"valid\" => false, \"valid_steps\" => 15000, \"train\" => true, \"negative_sample_size\" => 128, \"checkpoint_path\" => nothing, \"prefix\" => nothing, \"cuda\" => false, \"warm_up_steps\" => nothing, \"hidden_dim\" => 800, \"beta_mode\" => \"(1600,2)\", \"learning_rate\" => 0.0001, \"box_mode\" => \"(nothing,0.02)\", \"data_path\" => \"dataset/FB15k-betae\", \"max_steps\" => 450001, \"save_checkpoint_steps\" => 50000, \"save_path\" => \".\", \"test\" => false, \"gamma\" => 24.0, \"log_steps\" => 100, \"seed\" => 0, \"test_batch_size\" => 1)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:01:29 overwritting saving path: .\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:01:29 logging to logs/FB15k-betae/1p.2p.3p.2i.3i.ip.pi.2in.3in.inp.pin.pni.2u.up/beta/g-24.0-mode-(1600,2)/2024.02.14\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:01:29 --------------------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:01:29 Geo: beta\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:01:29 Data Path: dataset/FB15k-betae\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:01:29 #entity: 14951\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:01:29 #relation: 2690\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:01:29 #max steps: 450001\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:01:29 Evaluate unoins using: DNF\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:01:29 Train asked...\n",
      "(\"e\", (\"r\", \"r\", \"r\"))((\"e\", (\"r\",)), (\"e\", (\"r\",)))((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"e\", (\"r\",)))(\"e\", (\"r\", \"r\"))(\"e\", (\"r\",))\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:01:36 Flatten query length: 821130 typeof(query) Vector{Any}\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Model Parameter Configuration:\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter layer1-1: (14951, 1)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter Number: 14951\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter layer2-1: (1600, 1600)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter Number: 2560000\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter layer3-1: (1600,)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter Number: 1600\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter layer4-1: (800, 1600)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter Number: 1280000\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter layer5-1: (800,)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter Number: 800\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter layer6-1: (1600, 1600)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter Number: 2560000\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter layer7-1: (1600,)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter Number: 1600\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter layer8-1: (1600, 1600)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter Number: 2560000\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter layer9-1: (1600,)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter Number: 1600\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter layer10-1: (1600, 2400)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter Number: 3840000\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter layer11-1: (1600,)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Parameter Number: 1600\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Ramdomly Initializing beta Model...\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 beta mode = (1600,2)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 tasks = 1p.2p.3p.2i.3i.ip.pi.2in.3in.inp.pin.pni.2u.up\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 init_step = 0\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 learning_rate = 0.0001\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 batch_size = 1\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 hidden_dim = 800\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 gamma = 24.0\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 Start Training...\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 TrainDataset [1] -> ((8300, (442,)), (\"e\", (\"r\",))) answer: Set(Any[401, 365])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 TrainDataset tail 365 subsampling_weight: 6\n",
      "getobs set mask at 2 9077\n",
      "getobs set mask at 2 5380\n",
      "getobs set mask at 2 19\n",
      "getobs set mask at 1 758\n",
      "getobs set mask at 2 5732\n",
      "getobs set mask at 2 1283\n",
      "getobs set mask at 2 3792\n",
      "getobs set mask at 1 9699\n",
      "getobs set mask at 2 4822\n",
      "getobs set mask at 2 14327\n",
      "getobs set mask at 2 12283\n",
      "getobs set mask at 1 7975\n",
      "getobs set mask at 2 13645\n",
      "getobs set mask at 1 10253\n",
      "getobs set mask at 2 13632\n",
      "getobs set mask at 1 11938\n",
      "getobs set mask at 1 2390\n",
      "getobs set mask at 2 10359\n",
      "getobs set mask at 2 14794\n",
      "getobs set mask at 2 8004\n",
      "getobs set mask at 2 12696\n",
      "getobs set mask at 1 11215\n",
      "getobs set mask at 2 7028\n",
      "getobs set mask at 1 5682\n",
      "getobs set mask at 1 12041\n",
      "getobs set mask at 1 5513\n",
      "getobs set mask at 2 14821\n",
      "getobs set mask at 2 9224\n",
      "getobs set mask at 1 3179\n",
      "getobs set mask at 1 3579\n",
      "getobs set mask at 1 1828\n",
      "getobs set mask at 2 14715\n",
      "getobs set mask at 1 3328\n",
      "getobs set mask at 1 4338\n",
      "getobs set mask at 1 14934\n",
      "getobs set mask at 1 4976\n",
      "getobs set mask at 1 7015\n",
      "getobs set mask at 1 2412\n",
      "getobs set mask at 2 12956\n",
      "getobs set mask at 2 1700\n",
      "getobs set mask at 2 1829\n",
      "getobs set mask at 2 11647\n",
      "getobs set mask at 2 41\n",
      "getobs set mask at 1 4814\n",
      "getobs set mask at 1 10518\n",
      "getobs set mask at 1 11922\n",
      "getobs set mask at 2 1762\n",
      "getobs set mask at 1 6728\n",
      "getobs set mask at 2 7934\n",
      "getobs set mask at 2 10768\n",
      "getobs set mask at 2 2190\n",
      "getobs set mask at 2 7701\n",
      "getobs set mask at 2 2312\n",
      "getobs set mask at 1 13344\n",
      "getobs set mask at 2 10666\n",
      "getobs set mask at 2 8227\n",
      "getobs set mask at 2 7243\n",
      "getobs set mask at 2 8110\n",
      "getobs set mask at 1 8876\n",
      "getobs set mask at 1 708\n",
      "getobs set mask at 1 7372\n",
      "getobs set mask at 1 2350\n",
      "getobs set mask at 1 4193\n",
      "getobs set mask at 1 7774\n",
      "getobs set mask at 2 8580\n",
      "getobs set mask at 2 3033\n",
      "getobs set mask at 2 13860\n",
      "getobs set mask at 2 5941\n",
      "getobs set mask at 1 6453\n",
      "getobs set mask at 2 10621\n",
      "getobs set mask at 2 8229\n",
      "getobs set mask at 1 8830\n",
      "getobs set mask at 1 12573\n",
      "getobs set mask at 2 397\n",
      "getobs set mask at 1 6152\n",
      "getobs set mask at 1 6152\n",
      "getobs set mask at 2 10385\n",
      "getobs set mask at 2 2177\n",
      "getobs set mask at 1 11121\n",
      "getobs set mask at 2 11069\n",
      "getobs set mask at 2 116\n",
      "getobs set mask at 2 2269\n",
      "getobs set mask at 2 8806\n",
      "getobs set mask at 1 7850\n",
      "getobs set mask at 2 11487\n",
      "getobs set mask at 1 5225\n",
      "getobs set mask at 2 5848\n",
      "getobs set mask at 1 2142\n",
      "getobs set mask at 1 14283\n",
      "getobs set mask at 2 3759\n",
      "getobs set mask at 1 7199\n",
      "getobs set mask at 1 5872\n",
      "getobs set mask at 2 8575\n",
      "getobs set mask at 2 2918\n",
      "getobs set mask at 1 13027\n",
      "getobs set mask at 2 11970\n",
      "getobs set mask at 1 7473\n",
      "getobs set mask at 1 12842\n",
      "getobs set mask at 1 670\n",
      "getobs set mask at 1 9239\n",
      "getobs set mask at 1 3132\n",
      "getobs set mask at 2 365\n",
      "getobs set mask at 1 1710\n",
      "getobs set mask at 2 5849\n",
      "getobs set mask at 1 7282\n",
      "getobs set mask at 1 4014\n",
      "getobs set mask at 2 3455\n",
      "getobs set mask at 1 6545\n",
      "getobs set mask at 1 579\n",
      "getobs set mask at 2 13210\n",
      "getobs set mask at 2 11163\n",
      "getobs set mask at 2 10204\n",
      "getobs set mask at 1 7461\n",
      "getobs set mask at 1 8822\n",
      "getobs set mask at 2 13155\n",
      "getobs set mask at 1 372\n",
      "getobs set mask at 2 12811\n",
      "getobs set mask at 1 1973\n",
      "getobs set mask at 2 921\n",
      "getobs set mask at 1 6837\n",
      "getobs set mask at 1 8162\n",
      "getobs set mask at 1 8258\n",
      "getobs set mask at 2 8129\n",
      "getobs set mask at 2 2818\n",
      "getobs set mask at 1 13770\n",
      "getobs set mask at 2 10251\n",
      "getobs set mask at 1 7225\n",
      "getobs set mask at 2 794\n",
      "getobs set mask at 1 1903\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-14 17:02:54 getobs one item -------------------------------------------------\n",
      "path_data: ([365.0], [7299, 14102, 3961, 5369, 7496, 6552, 13583, 14923, 14867, 3806, 1992, 12864, 8229, 11474, 14046, 11706, 11508, 13328, 1051, 13012, 14756, 219, 5496, 14928, 6253, 3603, 4662, 5580, 7909, 14342, 10119, 2434, 5889, 8510, 10445, 5619, 3432, 2117, 4592, 4624, 798, 5741, 12642, 9858, 13255, 13957, 9667, 815, 7561, 5594, 7653, 2957, 14591, 5145, 7564, 3586, 9472, 13910, 9867, 13081, 4408, 1419, 1163, 7411, 14858, 4118, 365, 8648, 845, 7124, 13687, 8934, 7448, 1452, 6118, 9322, 13412, 10273, 1470, 5945, 9006, 2925, 10167, 11588, 4735, 13706, 12408, 14339, 4287, 13331, 7547, 4110, 9043, 4806, 9726, 915, 2864, 14487, 5717, 10706, 12088, 2447, 7001, 5196, 7205, 2135, 11990, 5622, 10453, 6416, 8010, 8192, 14335, 14654, 4347, 449, 6410, 13099, 7415, 8319, 8674, 6985, 10535, 14161, 6399, 4956, 4288, 12771], [0.408248290463863], [8300, 442], (\"e\", (\"r\",))),\n",
      " path_next: 2\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching train_step(::KGReasoning, ::@NamedTuple{nentity::Tuple{}, nrelation::Tuple{}, hidden_dim::Tuple{}, epsilon::Tuple{}, geo::Tuple{}, use_cuda::Tuple{}, batch_entity_range::Optimisers.Leaf{Optimisers.Adam, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, query_name_dict::Dict{Tuple{Any, Tuple{String, Vararg{Any}}, Vararg{Tuple{String, Vararg{Tuple{String, Vararg{String}}}}}}, Tuple{}}, gamma::Tuple{}, embedding_range::Tuple{}, entity_dim::Tuple{}, relation_dim::Tuple{}, entity_embedding::Tuple{}, cen::Tuple{}, func::Tuple{}, entity_regularizer::@NamedTuple{base_add::Tuple{}, min_val::Tuple{}, max_val::Tuple{}}, projection_regularizer::@NamedTuple{base_add::Tuple{}, min_val::Tuple{}, max_val::Tuple{}}, offset_embedding::Tuple{}, center_net::@NamedTuple{dim::Tuple{}, layer1::@NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}, ::Tuple{}}, layer2::@NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}, ::Tuple{}}}, offset_net::Tuple{}, num_layers::Tuple{}, projection_net::@NamedTuple{entity_dim::Tuple{}, relation_dim::Tuple{}, hidden_dim::Tuple{}, num_layers::Tuple{}, layers::Dict{Symbol, @NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}, ::Tuple{}}}, projection_regularizer::@NamedTuple{base_add::Tuple{}, min_val::Tuple{}, max_val::Tuple{}}}}, ::Tuple{Vector{Float64}, Vector{Int64}, Vector{Float64}, Vector{Int64}, Tuple{String, Tuple{String}}}, ::Dict{String, Any}, ::Int64)\n\n\u001b[0mClosest candidates are:\n\u001b[0m  train_step(\u001b[91m::Main.KGModule.KGReasoning\u001b[39m, ::Any, ::Any, ::Any, ::Any)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[33mMain.KGModule\u001b[39m \u001b[90m/sata/sdb5/julia/pro_kgreasoning/src/\u001b[39m\u001b[90m\u001b[4mmodel.jl:858\u001b[24m\u001b[39m\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching train_step(::KGReasoning, ::@NamedTuple{nentity::Tuple{}, nrelation::Tuple{}, hidden_dim::Tuple{}, epsilon::Tuple{}, geo::Tuple{}, use_cuda::Tuple{}, batch_entity_range::Optimisers.Leaf{Optimisers.Adam, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, query_name_dict::Dict{Tuple{Any, Tuple{String, Vararg{Any}}, Vararg{Tuple{String, Vararg{Tuple{String, Vararg{String}}}}}}, Tuple{}}, gamma::Tuple{}, embedding_range::Tuple{}, entity_dim::Tuple{}, relation_dim::Tuple{}, entity_embedding::Tuple{}, cen::Tuple{}, func::Tuple{}, entity_regularizer::@NamedTuple{base_add::Tuple{}, min_val::Tuple{}, max_val::Tuple{}}, projection_regularizer::@NamedTuple{base_add::Tuple{}, min_val::Tuple{}, max_val::Tuple{}}, offset_embedding::Tuple{}, center_net::@NamedTuple{dim::Tuple{}, layer1::@NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}, ::Tuple{}}, layer2::@NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}, ::Tuple{}}}, offset_net::Tuple{}, num_layers::Tuple{}, projection_net::@NamedTuple{entity_dim::Tuple{}, relation_dim::Tuple{}, hidden_dim::Tuple{}, num_layers::Tuple{}, layers::Dict{Symbol, @NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}, ::Tuple{}}}, projection_regularizer::@NamedTuple{base_add::Tuple{}, min_val::Tuple{}, max_val::Tuple{}}}}, ::Tuple{Vector{Float64}, Vector{Int64}, Vector{Float64}, Vector{Int64}, Tuple{String, Tuple{String}}}, ::Dict{String, Any}, ::Int64)\n\n\u001b[0mClosest candidates are:\n\u001b[0m  train_step(\u001b[91m::Main.KGModule.KGReasoning\u001b[39m, ::Any, ::Any, ::Any, ::Any)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[33mMain.KGModule\u001b[39m \u001b[90m/sata/sdb5/julia/pro_kgreasoning/src/\u001b[39m\u001b[90m\u001b[4mmodel.jl:858\u001b[24m\u001b[39m\n",
      "",
      "Stacktrace:",
      " [1] main(args::Dict{String, Any})",
      "   @ Main ./In[20]:467",
      " [2] top-level scope",
      "   @ In[21]:10"
     ]
    }
   ],
   "source": [
    "#if abspath(PROGRAM_FILE) == @__FILE__\n",
    "    args = Vector{String}([\"--train\", \"--data_path\", \"dataset/FB15k-betae\",\n",
    "                           \"-n\", \"128\", \"-b\", \"1\", \"-d\", \"800\", \"-g\", \"24\",\"--learning_rate\",\n",
    "                           \"0.0001\", \"--max_steps\", \"450001\",\n",
    "                           \"--cpu\", \"1\", \"--geo\", \"beta\", \"--valid_steps\", \"15000\"])\n",
    "    structed_args = parse_cmdargs(args);\n",
    "    println(structed_args)\n",
    "    set_logger(structed_args);\n",
    "\n",
    "    main(structed_args)\n",
    "\n",
    "#end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1319ac7f-7b4e-4225-a383-b61883827348",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c5a157-b35a-4c26-9e7c-736d396d6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"src/main.jl\")\n",
    "\n",
    "args = Vector{String}([\"--train\", \"--data_path\", \"dataset/FB15k-betae\",\n",
    "                       \"-n\", \"128\", \"-b\", \"1\", \"-d\", \"800\", \"-g\", \"24\",\"--learning_rate\",\n",
    "                       \"0.0001\", \"--max_steps\", \"450001\",\n",
    "                       \"--cpu\", \"1\", \"--geo\", \"beta\", \"--valid_steps\", \"15000\"])\n",
    "structed_args = parse_cmdargs(args);\n",
    "println(structed_args)\n",
    "set_logger(structed_args);\n",
    "\n",
    "main(structed_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  },
  "name": "KGReasoning.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
