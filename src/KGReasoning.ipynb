{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11065693-20a5-462a-8ea3-f5a8f23835fb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "using Pkg;\n",
    "#=\n",
    "Pkg.add(\"Genie\")\n",
    "Pkg.add(\"Images\")\n",
    "Pkg.add(\"Flux\")\n",
    "Pkg.add(\"MLUtils\")\n",
    "Pkg.add(\"ArgParse\")\n",
    "Pkg.add(\"LoggingExtras\")\n",
    "Pkg.add(\"Dates\")\n",
    "Pkg.add(\"Printf\")\n",
    "Pkg.add(\"TensorBoardLogger\")\n",
    "Pkg.add(\"JLD2\");\n",
    "Pkg.add(\"BSON\");\n",
    "Pkg.add(\"Pickle\")\n",
    "Pkg.add(\"ProgressBars\")\n",
    "Pkg.add(\"Distributions\")\n",
    "Pkg.add(\"Revise\")\n",
    "Pkg.add(\"Zygote\")\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b62ebc-2bee-4d04-8e93-e5f0fccc0579",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "using Pickle;\n",
    "using ArgParse;\n",
    "using Random;\n",
    "using Logging, LoggingExtras, TensorBoardLogger;\n",
    "using Dates;\n",
    "using Printf;\n",
    "using ProgressBars;\n",
    "using Flux;\n",
    "using MLUtils;\n",
    "using Revise;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c67737-8630-4baf-a1d4-fa9f077c94ed",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cd(\"/sata/sdb5/julia/pro_kgreasoning\")\n",
    "\n",
    "f_dir = \"dataset\";\n",
    "f_model = \"FB15k-betae\";\n",
    "f_train_queries = \"train-queries.pkl\";\n",
    "f_train_answers = \"train-answers.pkl\";\n",
    "f_valid_queries = \"valid-queries.pkl\";\n",
    "f_valid_hard_answers = \"valid-hard-answers.pkl\";\n",
    "f_valid_easy_answers = \"valid-easy-answers.pkl\";\n",
    "f_test_queries = \"test-queries.pkl\";\n",
    "f_test_hard_answers = \"test-hard-answers.pkl\";\n",
    "f_test_easy_answers = \"test-easy-answers.pkl\";\n",
    "\n",
    "query_name_dict = Dict{Tuple, String}((\"e\",(\"r\",))=> \"1p\",\n",
    "                                    (\"e\", (\"r\", \"r\"))=> \"2p\",\n",
    "                                    (\"e\", (\"r\", \"r\", \"r\"))=> \"3p\",\n",
    "                                    ((\"e\", (\"r\",)), (\"e\", (\"r\",)))=> \"2i\",\n",
    "                                    ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"e\", (\"r\",)))=> \"3i\",\n",
    "                                    (((\"e\", (\"r\",)), (\"e\", (\"r\",))), (\"r\",))=> \"ip\",\n",
    "                                    ((\"e\", (\"r\", \"r\")), (\"e\", (\"r\",)))=> \"pi\",\n",
    "                                    ((\"e\", (\"r\",)), (\"e\", (\"r\", \"n\")))=> \"2in\",\n",
    "                                    ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"e\", (\"r\", \"n\")))=> \"3in\",\n",
    "                                    (((\"e\", (\"r\",)), (\"e\", (\"r\", \"n\"))), (\"r\",))=> \"inp\",\n",
    "                                    ((\"e\", (\"r\", \"r\")), (\"e\", (\"r\", \"n\")))=> \"pin\",\n",
    "                                    ((\"e\", (\"r\", \"r\", \"n\")), (\"e\", (\"r\",)))=> \"pni\",\n",
    "                                    ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"u\",))=> \"2u-DNF\",\n",
    "                                    (((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"u\",)), (\"r\",))=> \"up-DNF\",\n",
    "                                    (((\"e\", (\"r\", \"n\")), (\"e\", (\"r\", \"n\"))), (\"n\",))=> \"2u-DM\",\n",
    "                                    (((\"e\", (\"r\", \"n\")), (\"e\", (\"r\", \"n\"))), (\"n\", \"r\"))=> \"up-DM\"\n",
    "                                );\n",
    "name_query_dict = Dict{String, Tuple}((y => x) for (x, y) in query_name_dict);\n",
    "all_tasks = collect(keys(name_query_dict));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87586e14-fbf6-4bcd-9ceb-fd8c3ca2d8ad",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mloading data....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data: deleteing structure...:\n",
      " (((\"e\", (\"r\", \"n\")), (\"e\", (\"r\", \"n\"))), (\"n\", \"r\"))\n",
      "load_data: deleteing structure...:\n",
      " (((\"e\", (\"r\", \"n\")), (\"e\", (\"r\", \"n\"))), (\"n\",))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mload data....Done\n"
     ]
    }
   ],
   "source": [
    "include(\"src/utils.jl\")\n",
    "include(\"src/dataloader.jl\")\n",
    "\n",
    "using .KGDataset\n",
    "\n",
    "args = Dict{String, Any}(\"geo\" => \"beta\", \"test_log_steps\" => 1000, \n",
    "    \"tasks\" => \"1p.2p.3p.2i.3i.ip.pi.2in.3in.inp.pin.pni.2u.up\", \"batch_size\" => 2, \n",
    "    \"evaluate_union\" => \"DNF\", \"nentity\" => 0, \"nrelation\" => 0, \"print_on_screen\" => true, \n",
    "    \"cpu\" => 1, \"valid\" => false, \"valid_steps\" => 15000, \"train\" => true, \n",
    "    \"negative_sample_size\" => 32, \"checkpoint_path\" => nothing, \"prefix\" => nothing, \n",
    "    \"cuda\" => false, \"warm_up_steps\" => nothing, \"hidden_dim\" => 800, \"beta_mode\" => \"(1600,2)\", \n",
    "    \"learning_rate\" => 0.0001, \"box_mode\" => \"(nothing,0.02)\", \"data_path\" => \"dataset/FB15k-betae\", \n",
    "    \"max_steps\" => 450001, \"save_checkpoint_steps\" => 50000, \"save_path\" => \".\", \"test\" => false, \n",
    "    \"gamma\" => 24.0, \"log_steps\" => 100, \"seed\" => 0, \"test_batch_size\" => 1)\n",
    "\n",
    "train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, \n",
    "test_queries, test_hard_answers, test_easy_answers = KGDataset.load_data(args, name_query_dict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81fefe00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " flatten_queries length: 1505405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [1] -> ((2674, (218, 383, 347)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[7460, 6039, 1830, 3877, 6746, 3140, 6318, 783, 2979, 3284, 2461, 182, 2996, 9228])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 9228 subsampling_weight: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 24 int  24 max 64\n",
      "value: 1830\n",
      "getobs set mask at 45 int  45 max 64\n",
      "value: 2461\n",
      "getobs set mask at 28 int  28 max 64\n",
      "value: 2996\n",
      "getobs set mask at 59 int  59 max 64\n",
      "value: 9228\n",
      "getobs set mask at 23 int  23 max 64\n",
      "value: 783\n",
      "getobs set mask at 2 int  2 max 64\n",
      "value: 7460\n",
      "getobs set mask at 37 int  37 max 64\n",
      "value: 6746\n",
      "getobs set mask at 56 int  56 max 64\n",
      "value: 6318\n",
      "getobs set mask at 25 int  25 max 64\n",
      "value: 182\n",
      "getobs set mask at 41 int  41 max 64\n",
      "value: 9228\n",
      "getobs set mask at 53 int  53 max 64\n",
      "value: 2461\n",
      "getobs set mask at 22 int  22 max 64\n",
      "value: 3284\n",
      "getobs set mask at 8 int  8 max 64\n",
      "value: 3140\n",
      "getobs set mask at 12 int  12 max 64\n",
      "value: 783\n",
      "getobs set mask at 34 int  34 max 64\n",
      "value: 2979\n",
      "getobs set mask at 47 int  47 max 64\n",
      "value: 783\n",
      "getobs set mask at 22 int  22 max 64\n",
      "value: 3284\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 6318\n",
      "getobs set mask at 26 int  26 max 64\n",
      "value: 3877\n",
      "getobs set mask at 55 int  55 max 64\n",
      "value: 3877\n",
      "getobs set mask at 24 int  24 max 64\n",
      "value: 2996\n",
      "getobs set mask at 41 int  41 max 64\n",
      "value: 783\n",
      "getobs set mask at 46 int  46 max 64\n",
      "value: 3140\n",
      "getobs set mask at 31 int  31 max 64\n",
      "value: 9228\n",
      "getobs set mask at 3 int  3 max 64\n",
      "value: 3284\n",
      "getobs set mask at 16 int  16 max 64\n",
      "value: 182\n",
      "getobs set mask at 16 int  16 max 64\n",
      "value: 1830\n",
      "getobs set mask at 12 int  12 max 64\n",
      "value: 3877\n",
      "getobs set mask at 20 int  20 max 64\n",
      "value: 3140\n",
      "getobs set mask at 43 int  43 max 64\n",
      "value: 1830\n",
      "getobs set mask at 25 int  25 max 64\n",
      "value: 182\n",
      "getobs set mask at 1 int  1 max 64\n",
      "value: 6318\n",
      "getobs set mask at 5 int  5 max 64\n",
      "value: 7831\n",
      "getobs set mask at 54 int  54 max 64\n",
      "value: 11998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [2] -> ((253, (1219, 1074, 157)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[5553, 3927, 5520, 2014, 1954, 9625, 3049, 13006, 4865, 1659, 5767, 2775, 7077, 11998, 11729, 7831, 7726, 3295, 4495, 13524])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 4495 subsampling_weight: 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 37 int  37 max 64\n",
      "value: 5553\n",
      "getobs set mask at 35 int  35 max 64\n",
      "value: 5553\n",
      "getobs set mask at 28 int  28 max 64\n",
      "value: 1659\n",
      "getobs set mask at 14 int  14 max 64\n",
      "value: 7726\n",
      "getobs set mask at 29 int  29 max 64\n",
      "value: 3295\n",
      "getobs set mask at 40 int  40 max 64\n",
      "value: 11998\n",
      "getobs set mask at 61 int  61 max 64\n",
      "value: 7726\n",
      "getobs set mask at 47 int  47 max 64\n",
      "value: 3049\n",
      "getobs set mask at 4 int  4 max 64\n",
      "value: 7077\n",
      "getobs set mask at 22 int  22 max 64\n",
      "value: 4865\n",
      "getobs set mask at 59 int  59 max 64\n",
      "value: 13006\n",
      "getobs set mask at 21 int  21 max 64\n",
      "value: 3927\n",
      "getobs set mask at 45 int  45 max 64\n",
      "value: 11998\n",
      "getobs set mask at 47 int  47 max 64\n",
      "value: 2775\n",
      "getobs set mask at 44 int  44 max 64\n",
      "value: 9625\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 13006\n",
      "getobs set mask at 41 int  41 max 64\n",
      "value: 7726\n",
      "getobs set mask at 60 int  60 max 64\n",
      "value: 5553\n",
      "getobs set mask at 42 int  42 max 64\n",
      "value: 13006\n",
      "getobs set mask at 56 int  56 max 64\n",
      "value: 5767\n",
      "getobs set mask at 39 int  39 max 64\n",
      "value: 1954\n",
      "getobs set mask at 27 int  27 max 64\n",
      "value: 7726\n",
      "getobs set mask at 56 int  56 max 64\n",
      "value: 2775\n",
      "getobs set mask at 59 int  59 max 64\n",
      "value: 11729\n",
      "getobs set mask at 27 int  27 max 64\n",
      "value: 2014\n",
      "getobs set mask at 34 int  34 max 64\n",
      "value: 7831\n",
      "getobs set mask at 46 int  46 max 64\n",
      "value: 13524\n",
      "getobs set mask at 27 int  27 max 64\n",
      "value: 3927\n",
      "getobs set mask at 63 int  63 max 64\n",
      "value: 7077\n",
      "getobs set mask at 39 int  39 max 64\n",
      "value: 4865\n",
      "getobs set mask at 11 int  11 max 64\n",
      "value: 8179\n",
      "getobs set mask at 31 int  31 max 64\n",
      "value: 3531\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 10444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [3] -> ((7206, (65, 1509, 1650)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[6037, 3531, 10444, 8179])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 6037 subsampling_weight: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 43 int  43 max 64\n",
      "value: 10444\n",
      "getobs set mask at 42 int  42 max 64\n",
      "value: 10444\n",
      "getobs set mask at 32 int  32 max 64\n",
      "value: 10444\n",
      "getobs set mask at 11 int  11 max 64\n",
      "value: 3531\n",
      "getobs set mask at 55 int  55 max 64\n",
      "value: 3531\n",
      "getobs set mask at 3 int  3 max 64\n",
      "value: 8179\n",
      "getobs set mask at 4 int  4 max 64\n",
      "value: 10444\n",
      "getobs set mask at 42 int  42 max 64\n",
      "value: 8179\n",
      "getobs set mask at 59 int  59 max 64\n",
      "value: 3531\n",
      "getobs set mask at 45 int  45 max 64\n",
      "value: 8179\n",
      "getobs set mask at 14 int  14 max 64\n",
      "value: 8179\n",
      "getobs set mask at 44 int  44 max 64\n",
      "value: 8179\n",
      "getobs set mask at 51 int  51 max 64\n",
      "value: 8179\n",
      "getobs set mask at 36 int  36 max 64\n",
      "value: 3531\n",
      "getobs set mask at 2 int  2 max 64\n",
      "value: 6037\n",
      "getobs set mask at 32 int  32 max 64\n",
      "value: 8179\n",
      "getobs set mask at 28 int  28 max 64\n",
      "value: 10444\n",
      "getobs set mask at 1 int  1 max 64\n",
      "value: 6037\n",
      "getobs set mask at 42 int  42 max 64\n",
      "value: 3531\n",
      "getobs set mask at 23 int  23 max 64\n",
      "value: 10444\n",
      "getobs set mask at 27 int  27 max 64\n",
      "value: 10444\n",
      "getobs set mask at 20 int  20 max 64\n",
      "value: 8179\n",
      "getobs set mask at 52 int  52 max 64\n",
      "value: 8179\n",
      "getobs set mask at 25 int  25 max 64\n",
      "value: 8179\n",
      "getobs set mask at 23 int  23 max 64\n",
      "value: 6037\n",
      "getobs set mask at 38 int  38 max 64\n",
      "value: 10444\n",
      "getobs set mask at 29 int  29 max 64\n",
      "value: 6037\n",
      "getobs set mask at 41 int  41 max 64\n",
      "value: 8179\n",
      "getobs set mask at 6 int  6 max 64\n",
      "value: 8179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [4] -> ((9713, (205, 613, 109)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[697, 1308, 1659, 7941])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 1308 subsampling_weight: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 57 int  57 max 64\n",
      "value: 7941\n",
      "getobs set mask at 37 int  37 max 64\n",
      "value: 1308\n",
      "getobs set mask at 61 int  61 max 64\n",
      "value: 1659\n",
      "getobs set mask at 25 int  25 max 64\n",
      "value: 7941\n",
      "getobs set mask at 20 int  20 max 64\n",
      "value: 7941\n",
      "getobs set mask at 20 int  20 max 64\n",
      "value: 1308\n",
      "getobs set mask at 31 int  31 max 64\n",
      "value: 1659\n",
      "getobs set mask at 45 int  45 max 64\n",
      "value: 1659\n",
      "getobs set mask at 35 int  35 max 64\n",
      "value: 1308\n",
      "getobs set mask at 12 int  12 max 64\n",
      "value: 1659\n",
      "getobs set mask at 40 int  40 max 64\n",
      "value: 697\n",
      "getobs set mask at 16 int  16 max 64\n",
      "value: 7941\n",
      "getobs set mask at 11 int  11 max 64\n",
      "value: 7941\n",
      "getobs set mask at 50 int  50 max 64\n",
      "value: 1659\n",
      "getobs set mask at 16 int  16 max 64\n",
      "value: 1308\n",
      "getobs set mask at 5 int  5 max 64\n",
      "value: 1659\n",
      "getobs set mask at 15 int  15 max 64\n",
      "value: 1308\n",
      "getobs set mask at 21 int  21 max 64\n",
      "value: 7941\n",
      "getobs set mask at 31 int  31 max 64\n",
      "value: 1308\n",
      "getobs set mask at 13 int  13 max 64\n",
      "value: 1308\n",
      "getobs set mask at 3 int  3 max 64\n",
      "value: 7941\n",
      "getobs set mask at 57 int  57 max 64\n",
      "value: 1308\n",
      "getobs set mask at 36 int  36 max 64\n",
      "value: 7941\n",
      "getobs set mask at 40 int  40 max 64\n",
      "value: 1308\n",
      "getobs set mask at 58 int  58 max 64\n",
      "value: 7941\n",
      "getobs set mask at 47 int  47 max 64\n",
      "value: 697\n",
      "getobs set mask at 2 int  2 max 64\n",
      "value: 7941\n",
      "getobs set mask at 35 int  35 max 64\n",
      "value: 697\n",
      "getobs set mask at 2 int  2 max 64\n",
      "value: 1659\n",
      "getobs set mask at 40 int  40 max 64\n",
      "value: 1308\n",
      "getobs set mask at 11 int  11 max 64\n",
      "value: 1308\n",
      "getobs set mask at 26 int  26 max 64\n",
      "value: 7941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([9228.0 4495.0 6037.0 1308.0], [965653 480458 273664 25168; 1178975 1365843 619868 1088278; 1337604 696182 654479 186166; 443539 705501 1098602 1283478; 395299 184725 1305820 1222434; 229330 1142227 1065141 1080549; 816757 976524 1168553 310292; 1088249 90436 967398 949089; 1328058 32492 1123873 890133; 333547 868970 166899 1315969; 500689 103834 692535 771453; 320349 87735 161967 318634; 2167 687086 696853 808506; 745036 1014506 1074453 937721; 1154488 1323650 33505 160412; 74993 886751 863601 1137579; 425462 1176962 1470113 617559; 1414316 100417 781567 195934; 71982 1148382 1406915 305586; 502436 368545 554920 435478; 95728 696587 600681 1178552; 522957 326491 288654 188909; 1001501 850622 775914 971016; 9371 752811 488182 1465378; 981742 317860 773213 1079195; 328994 821568 1036272 586168; 1363535 377234 502640 1294739; 17814 1265809 1323464 1458487; 497610 1026423 35772 697429; 1217278 1092085 1074311 1126622; 125377 317728 1032631 150756; 534495 777030 235538 949983], [0.23570226039551584 0.2041241452319315 0.3535533905932738 0.3535533905932738], [2674 253 7206 9713; 218 1219 65 205; 383 1074 1509 613; 347 157 1650 109], ([\"e\", \"e\", \"e\", \"e\"], ([\"r\", \"r\", \"r\", \"r\"], [\"r\", \"r\", \"r\", \"r\"], [\"r\", \"r\", \"r\", \"r\"])))\n",
      "-----------------\n",
      "getobs set mask at 58 int  58 max 64\n",
      "value: 13535\n",
      "getobs set mask at 3 int  3 max 64\n",
      "value: 11764\n",
      "getobs set mask at 33 int  33 max 64\n",
      "value: 677\n",
      "getobs set mask at 21 int  21 max 64\n",
      "value: 6047\n",
      "getobs set mask at 15 int  15 max 64\n",
      "value: 5247\n",
      "getobs set mask at 7 int  7 max 64\n",
      "value: 2892\n",
      "getobs set mask at 63 int  63 max 64\n",
      "value: 11764\n",
      "getobs set mask at 41 int  41 max 64\n",
      "value: 2029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [5] -> ((3, (1310, 1195, 1315)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[4267, 11764, 631, 677, 13535, 6931, 13925, 2029, 2892, 5247, 2065, 8726, 2683, 6047, 5253, 3532, 5980])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 4267 subsampling_weight: 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 15 int  15 max 64\n",
      "value: 6931\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 5253\n",
      "getobs set mask at 6 int  6 max 64\n",
      "value: 13535\n",
      "getobs set mask at 41 int  41 max 64\n",
      "value: 677\n",
      "getobs set mask at 22 int  22 max 64\n",
      "value: 677\n",
      "getobs set mask at 50 int  50 max 64\n",
      "value: 8726\n",
      "getobs set mask at 1 int  1 max 64\n",
      "value: 631\n",
      "getobs set mask at 28 int  28 max 64\n",
      "value: 2029\n",
      "getobs set mask at 5 int  5 max 64\n",
      "value: 5247\n",
      "getobs set mask at 63 int  63 max 64\n",
      "value: 11764\n",
      "getobs set mask at 62 int  62 max 64\n",
      "value: 5980\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 2065\n",
      "getobs set mask at 13 int  13 max 64\n",
      "value: 13535\n",
      "getobs set mask at 11 int  11 max 64\n",
      "value: 4267\n",
      "getobs set mask at 58 int  58 max 64\n",
      "value: 13925\n",
      "getobs set mask at 27 int  27 max 64\n",
      "value: 6047\n",
      "getobs set mask at 3 int  3 max 64\n",
      "value: 2683\n",
      "getobs set mask at 23 int  23 max 64\n",
      "value: 4267\n",
      "getobs set mask at 19 int  19 max 64\n",
      "value: 4267\n",
      "getobs set mask at 22 int  22 max 64\n",
      "value: 5980\n",
      "getobs set mask at 39 int  39 max 64\n",
      "value: 5980\n",
      "getobs set mask at 44 int  44 max 64\n",
      "value: 6931\n",
      "getobs set mask at 38 int  38 max 64\n",
      "value: 11764\n",
      "getobs set mask at 60 int  60 max 64\n",
      "value: 5247\n",
      "getobs set mask at 39 int  39 max 64\n",
      "value: 12404\n",
      "getobs set mask at 56 int  56 max 64\n",
      "value: 3262\n",
      "getobs set mask at 38 int  38 max 64\n",
      "value: 10666\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 9704\n",
      "getobs set mask at 20 int  20 max 64\n",
      "value: 1798\n",
      "getobs set mask at 32 int  32 max 64\n",
      "value: 13091\n",
      "getobs set mask at 41 int  41 max 64\n",
      "value: 4184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [6] -> ((2535, (161, 336, 700)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[13133, 8095, 6459, 719, 13501, 13106, 2688, 11269, 2915, 9696, 10882, 10989, 14673, 5674, 4115, 14570, 6806, 8053, 2486, 8340, 9603, 11670, 10162, 4634, 177, 10916, 2550, 3655, 111, 10467, 8552, 13184, 12240, 8663, 8382, 6444, 9439, 14111, 10406, 4464, 2506, 4741, 11475, 13890, 4346, 8902, 3341, 3319, 10525, 2767, 920, 278, 1574, 5115, 10081, 7169, 13767, 10714, 14096, 1139, 11635, 14319, 5698, 247, 3955, 8723, 397, 10143, 13538, 11261, 14043, 12643, 14735, 6581, 2766, 6997, 10127, 5717, 154, 6972, 13692, 10870, 8041, 3116, 10826, 2433, 245, 1138, 13858, 12824, 6420, 6925, 13917, 14730, 11524, 14148, 14593, 1967, 4051, 7126, 12220, 9710, 4334, 6637, 11958, 13265, 758, 11406, 12478, 5645, 2044, 11743, 10083, 14295, 706, 176, 6885, 6460, 13259, 1798, 2394, 1068, 1548, 4882, 11125, 118, 12522, 11153, 12672, 5459, 7074, 8611, 10980, 7580, 10704, 7425, 13463, 14193, 7971, 9823, 11885, 4279, 10617, 9100, 9704, 13849, 11934, 583, 5546, 1304, 11669, 11572, 14155, 7219, 14258, 13883, 7650, 900, 3623, 12695, 7893, 12219, 12381, 13608, 1018, 1160, 3553, 9229, 13466, 10431, 13786, 13510, 11448, 10625, 1925, 10346, 1416, 11060, 14447, 1413, 9341, 1492, 14293, 12789, 2983, 4632, 13887, 2972, 14565, 1713, 6834, 9660, 6490, 10433, 3636, 7919, 14074, 12445, 11389, 8545, 7295, 2409, 1923, 13340, 3198, 2028, 10834, 4035, 3171, 12517, 1440, 1307, 9097, 11503, 3296, 8976, 12538, 3894, 3897, 12405, 8176, 8651, 1976, 11873, 3780, 13015, 7740, 658, 7162, 13197, 1432, 2018, 539, 12568, 443, 9921, 14318, 12164, 2407, 13589, 1785, 1079, 7625, 10666, 10383, 3262, 7488, 1043, 12633, 0, 13065, 12169, 12827, 5238, 8656, 2843, 7099, 13678, 10047, 5074, 11951, 2687, 9813, 891, 8616, 6068, 13091, 12180, 4184, 4266, 12544, 11731, 13352, 14129, 3839, 5637, 2389, 10743, 545, 3266, 8554, 12644, 8696, 5641, 10035, 12936, 7561, 9623, 5872, 12072, 1153, 4168, 9702, 12446, 8246, 9138, 1277, 7892, 14316, 2100, 496, 9198, 4960, 1014, 12655, 913, 12097, 7070, 11399, 9388, 11111, 11914, 9391, 1063, 10968, 12404, 12849, 8497, 635, 9874, 239, 8054, 3700, 13889, 2008, 205, 12267, 4521, 1410, 3939, 58, 4038, 7156, 12052, 12513, 13956, 13020, 13089, 1264, 13978, 10948, 5778, 13636, 750, 2574, 5483, 10924, 1833, 12424, 3647, 11482, 11760, 13430, 1291, 13847, 8205, 11947, 9551, 10757, 8981, 13790, 3639, 803, 6633, 9423, 6000, 2328, 11457, 12700, 8208, 7497, 14157, 5667, 1675, 9179, 229, 4270, 12601, 192, 5650, 3796, 11569, 7509, 10930, 6471, 11056, 5846, 6168, 1966, 4759, 6237, 96, 8334, 14431, 4545, 5335, 8165, 12571, 8133, 5516, 11246, 504, 8003, 11979, 7286, 12676, 2469])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 13015 subsampling_weight: 411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 25 int  25 max 64\n",
      "value: 14673\n",
      "getobs set mask at 39 int  39 max 64\n",
      "value: 14155\n",
      "getobs set mask at 33 int  33 max 64\n",
      "value: 3700\n",
      "getobs set mask at 17 int  17 max 64\n",
      "value: 3639\n",
      "getobs set mask at 31 int  31 max 64\n",
      "value: 111\n",
      "getobs set mask at 59 int  59 max 64\n",
      "value: 11448\n",
      "getobs set mask at 59 int  59 max 64\n",
      "value: 10162\n",
      "getobs set mask at 53 int  53 max 64\n",
      "value: 154\n",
      "getobs set mask at 8 int  8 max 64\n",
      "value: 658\n",
      "getobs set mask at 53 int  53 max 64\n",
      "value: 8165\n",
      "getobs set mask at 26 int  26 max 64\n",
      "value: 13089\n",
      "getobs set mask at 20 int  20 max 64\n",
      "value: 8616\n",
      "getobs set mask at 28 int  28 max 64\n",
      "value: 10882\n",
      "getobs set mask at 29 int  29 max 64\n",
      "value: 6237\n",
      "getobs set mask at 63 int  63 max 64\n",
      "value: 13636\n",
      "getobs set mask at 35 int  35 max 64\n",
      "value: 2687\n",
      "getobs set mask at 31 int  31 max 64\n",
      "value: 12849\n",
      "getobs set mask at 62 int  62 max 64\n",
      "value: 1018\n",
      "getobs set mask at 63 int  63 max 64\n",
      "value: 12643\n",
      "getobs set mask at 6 int  6 max 64\n",
      "value: 1713\n",
      "getobs set mask at 26 int  26 max 64\n",
      "value: 8205\n",
      "getobs set mask at 2 int  2 max 64\n",
      "value: 177\n",
      "getobs set mask at 44 int  44 max 64\n",
      "value: 12052\n",
      "getobs set mask at 40 int  40 max 64\n",
      "value: 11246\n",
      "getobs set mask at 57 int  57 max 64\n",
      "value: 3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [7] -> ((2828, (1471, 1233, 385)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[2143])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 2143 subsampling_weight: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 48 int  48 max 64\n",
      "value: 2143\n",
      "getobs set mask at 28 int  28 max 64\n",
      "value: 2143\n",
      "getobs set mask at 38 int  38 max 64\n",
      "value: 2143\n",
      "getobs set mask at 9 int  9 max 64\n",
      "value: 2143\n",
      "getobs set mask at 39 int  39 max 64\n",
      "value: 2143\n",
      "getobs set mask at 11 int  11 max 64\n",
      "value: 2143\n",
      "getobs set mask at 32 int  32 max 64\n",
      "value: 2143\n",
      "getobs set mask at 16 int  16 max 64\n",
      "value: 2143\n",
      "getobs set mask at 6 int  6 max 64\n",
      "value: 2143\n",
      "getobs set mask at 26 int  26 max 64\n",
      "value: 2143\n",
      "getobs set mask at 52 int  52 max 64\n",
      "value: 2143\n",
      "getobs set mask at 44 int  44 max 64\n",
      "value: 2143\n",
      "getobs set mask at 55 int  55 max 64\n",
      "value: 2143\n",
      "getobs set mask at 1 int  1 max 64\n",
      "value: 2143\n",
      "getobs set mask at 2 int  2 max 64\n",
      "value: 2143\n",
      "getobs set mask at 58 int  58 max 64\n",
      "value: 2143\n",
      "getobs set mask at 10 int  10 max 64\n",
      "value: 2143\n",
      "getobs set mask at 11 int  11 max 64\n",
      "value: 2143\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 2143\n",
      "getobs set mask at 5 int  5 max 64\n",
      "value: 2143\n",
      "getobs set mask at 2 int  2 max 64\n",
      "value: 2143\n",
      "getobs set mask at 62 int  62 max 64\n",
      "value: 2143\n",
      "getobs set mask at 28 int  28 max 64\n",
      "value: 2143\n",
      "getobs set mask at 31 int  31 max 64\n",
      "value: 2143\n",
      "getobs set mask at 17 int  17 max 64\n",
      "value: 2143\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 2143\n",
      "getobs set mask at 13 int  13 max 64\n",
      "value: 2143\n",
      "getobs set mask at 37 int  37 max 64\n",
      "value: 2143\n",
      "getobs set mask at 20 int  20 max 64\n",
      "value: 2143\n",
      "getobs set mask at 4 int  4 max 64\n",
      "value: 2143\n",
      "getobs set mask at 47 int  47 max 64\n",
      "value: 2143\n",
      "getobs set mask at 51 int  51 max 64\n",
      "value: 2143\n",
      "getobs set mask at 44 int  44 max 64\n",
      "value: 4259\n",
      "getobs set mask at 32 int  32 max 64\n",
      "value: 7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [8] -> ((4542, (94, 1166, 330)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[7141, 4259, 9332])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 9332 subsampling_weight: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 52 int  52 max 64\n",
      "value: 4259\n",
      "getobs set mask at 41 int  41 max 64\n",
      "value: 9332\n",
      "getobs set mask at 27 int  27 max 64\n",
      "value: 7141\n",
      "getobs set mask at 22 int  22 max 64\n",
      "value: 9332\n",
      "getobs set mask at 63 int  63 max 64\n",
      "value: 9332\n",
      "getobs set mask at 12 int  12 max 64\n",
      "value: 7141\n",
      "getobs set mask at 8 int  8 max 64\n",
      "value: 9332\n",
      "getobs set mask at 8 int  8 max 64\n",
      "value: 4259\n",
      "getobs set mask at 44 int  44 max 64\n",
      "value: 4259\n",
      "getobs set mask at 49 int  49 max 64\n",
      "value: 9332\n",
      "getobs set mask at 20 int  20 max 64\n",
      "value: 7141\n",
      "getobs set mask at 31 int  31 max 64\n",
      "value: 4259\n",
      "getobs set mask at 7 int  7 max 64\n",
      "value: 9332\n",
      "getobs set mask at 5 int  5 max 64\n",
      "value: 7141\n",
      "getobs set mask at 18 int  18 max 64\n",
      "value: 4259\n",
      "getobs set mask at 26 int  26 max 64\n",
      "value: 9332\n",
      "getobs set mask at 35 int  35 max 64\n",
      "value: 7141\n",
      "getobs set mask at 50 int  50 max 64\n",
      "value: 9332\n",
      "getobs set mask at 33 int  33 max 64\n",
      "value: 9332\n",
      "getobs set mask at 25 int  25 max 64\n",
      "value: 4259\n",
      "getobs set mask at 37 int  37 max 64\n",
      "value: 9332\n",
      "getobs set mask at 11 int  11 max 64\n",
      "value: 4259\n",
      "getobs set mask at 42 int  42 max 64\n",
      "value: 9332\n",
      "getobs set mask at 50 int  50 max 64\n",
      "value: 7141\n",
      "getobs set mask at 28 int  28 max 64\n",
      "value: 7141\n",
      "getobs set mask at 31 int  31 max 64\n",
      "value: 9332\n",
      "getobs set mask at 17 int  17 max 64\n",
      "value: 9332\n",
      "getobs set mask at 20 int  20 max 64\n",
      "value: 7141\n",
      "getobs set mask at 33 int  33 max 64\n",
      "value: 7141\n",
      "getobs set mask at 63 int  63 max 64\n",
      "value: 9332\n",
      "([4267.0 13015.0 2143.0 9332.0], [158438 324575 68129 611210; 639320 1158471 820598 928245; 1355581 1032656 1260725 577812; 124730 953840 89797 696298; 457320 1034580 1106561 490142; 190295 434882 589918 900616; 485166 278650 915233 1200096; 710196 836165 919684 1102785; 1502855 385174 1189696 526178; 251633 389092 836514 867654; 2013 472995 758324 948399; 1148749 1468955 1487779 1447642; 1406404 1255976 675352 1255673; 717554 807596 127656 430216; 421589 36935 329402 1346924; 1468209 1376303 680308 988932; 42193 979584 796440 111251; 750447 1315990 1380978 163953; 1295162 669323 785675 458396; 1355902 1333683 1134248 1030343; 587946 1185915 13137 1437012; 815481 991080 704404 1502373; 889427 1182719 573395 1487592; 569826 306151 1157612 237837; 114814 1339631 322196 1106713; 917480 697235 1152728 597803; 856768 982634 1066119 835077; 1369425 1321360 1233609 673970; 795205 1390490 1024628 1032972; 670166 953710 949861 1332480; 1050062 1408624 947123 285223; 1422234 663143 98409 760445], [0.21821789023599236 0.04932636236669901 0.4472135954999579 0.3779644730092272], [3 2535 2828 4542; 1310 161 1471 94; 1195 336 1233 1166; 1315 700 385 330], ([\"e\", \"e\", \"e\", \"e\"], ([\"r\", \"r\", \"r\", \"r\"], [\"r\", \"r\", \"r\", \"r\"], [\"r\", \"r\", \"r\", \"r\"])))\n",
      "-----------------\n",
      "getobs set mask at 21 int  21 max 64\n",
      "value: 761\n",
      "getobs set mask at 34 int  34 max 64\n",
      "value: 3590\n",
      "getobs set mask at 12 int  12 max 64\n",
      "value: 6534\n",
      "getobs set mask at 13 int  13 max 64\n",
      "value: 5917\n",
      "getobs set mask at 6 int  6 max 64\n",
      "value: 14528\n",
      "getobs set mask at 54 int  54 max 64\n",
      "value: 496\n",
      "getobs set mask at 51 int  51 max 64\n",
      "value: 2418\n",
      "getobs set mask at 22 int  22 max 64\n",
      "value: 8632\n",
      "getobs set mask at 35 int  35 max 64\n",
      "value: 2216\n",
      "getobs set mask at 27 int  27 max 64\n",
      "value: 3572\n",
      "getobs set mask at 47 int  47 max 64\n",
      "value: 5324\n",
      "getobs set mask at 16 int  16 max 64\n",
      "value: 7519\n",
      "getobs set mask at 12 int  12 max 64\n",
      "value: 11128\n",
      "getobs set mask at 23 int  23 max 64\n",
      "value: 1923\n",
      "getobs set mask at 3 int  3 max 64\n",
      "value: 8566\n",
      "getobs set mask at 56 int  56 max 64\n",
      "value: 9420\n",
      "getobs set mask at 14 int  14 max 64\n",
      "value: 714\n",
      "getobs set mask at 41 int  41 max 64\n",
      "value: 4185\n",
      "getobs set mask at 3 int  3 max 64\n",
      "value: 1563\n",
      "getobs set mask at 13 int  13 max 64\n",
      "value: 7642\n",
      "getobs set mask at 42 int  42 max 64\n",
      "value: 7383\n",
      "getobs set mask at 49 int  49 max 64\n",
      "value: 12333\n",
      "getobs set mask at 18 int  18 max 64\n",
      "value: 278\n",
      "getobs set mask at 48 int  48 max 64\n",
      "value: 6285\n",
      "getobs set mask at 8 int  8 max 64\n",
      "value: 4488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [9] -> ((10531, (37, 460, 684)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[12704, 1144, 6459, 10157, 8232, 3424, 983, 9062, 6836, 1882, 11594, 4001, 4115, 12071, 1381, 14017, 12255, 4414, 8758, 12098, 5917, 14401, 10593, 14832, 6505, 14835, 2667, 12, 10916, 9082, 75, 3484, 3655, 111, 715, 41, 11647, 10483, 11803, 12483, 11193, 13661, 13176, 14309, 3572, 4535, 5324, 414, 4185, 3341, 3521, 7383, 2767, 9252, 2670, 7611, 3651, 278, 14185, 7128, 4024, 655, 9277, 13399, 14065, 3303, 247, 8639, 1688, 8723, 397, 2695, 13149, 13431, 8502, 6581, 258, 14817, 4844, 5570, 2766, 3338, 5219, 4713, 14563, 3788, 2114, 13095, 354, 7391, 9698, 10114, 11342, 3116, 3628, 1034, 5874, 482, 416, 6420, 4216, 11253, 3590, 1071, 8110, 5749, 2738, 4488, 5312, 9139, 13871, 7905, 14361, 4080, 4280, 5031, 7642, 6637, 13156, 9276, 3381, 12333, 8467, 14355, 2044, 14321, 4697, 5942, 11619, 706, 176, 6660, 7903, 11472, 9951, 1798, 9641, 1068, 36, 2279, 9821, 10307, 118, 9929, 10364, 1746, 25, 14456, 10962, 11043, 9274, 12923, 14937, 3041, 5163, 3120, 10800, 14667, 11629, 10857, 11752, 9704, 10708, 11934, 5546, 8566, 1304, 3848, 1563, 303, 9116, 580, 2916, 11018, 1018, 1989, 13618, 1925, 11048, 9959, 999, 9756, 3770, 223, 1416, 13179, 1413, 14539, 1492, 2774, 678, 14417, 4336, 4826, 800, 2972, 1313, 12018, 10745, 5034, 6490, 714, 3636, 11133, 2418, 7085, 11592, 11666, 6117, 1923, 13361, 14351, 5813, 10635, 7982, 9002, 12518, 10227, 2561, 1231, 6675, 2104, 5032, 13851, 7519, 10634, 9501, 8651, 7368, 3242, 3817, 9040, 7113, 658, 7643, 4512, 3055, 1732, 5504, 2588, 10438, 2778, 539, 13387, 4020, 14757, 9314, 12568, 9293, 9420, 443, 7196, 4971, 2254, 14240, 307, 1785, 144, 6993, 7308, 7682, 13080, 8906, 1795, 1043, 2579, 0, 329, 14502, 344, 2656, 1611, 14546, 7466, 1929, 372, 1412, 7566, 2714, 1792, 14498, 2927, 11363, 545, 4003, 3266, 13582, 5641, 14663, 3279, 14365, 2977, 1348, 190, 5215, 761, 8492, 3244, 4056, 7767, 3339, 14339, 12552, 4338, 8246, 3223, 314, 10742, 5272, 1277, 10621, 10204, 496, 4148, 1164, 3996, 6285, 1014, 9063, 3108, 3477, 11188, 9766, 11200, 4664, 10968, 1063, 12757, 1587, 7629, 2216, 13758, 14528, 7029, 11921, 1410, 1133, 58, 13073, 4919, 5251, 3123, 4358, 3942, 8213, 9590, 2574, 10767, 76, 11756, 3647, 7936, 6802, 140, 7356, 1613, 8506, 13996, 14462, 803, 10036, 7130, 8629, 6014, 6653, 11457, 14501, 6804, 6510, 11852, 14248, 6534, 1358, 981, 2146, 9657, 13296, 3693, 4418, 4938, 5558, 679, 3273, 3854, 14122, 12187, 6381, 13637, 9825, 6168, 546, 10975, 2589, 11128, 96, 14505, 5125, 14490, 13502, 8632, 14572, 10622, 2587, 2925, 1314, 504, 2095, 14156, 4496, 5281, 13725])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 176 subsampling_weight: 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 40 int  40 max 64\n",
      "value: 14156\n",
      "getobs set mask at 50 int  50 max 64\n",
      "value: 4488\n",
      "getobs set mask at 13 int  13 max 64\n",
      "value: 3942\n",
      "getobs set mask at 63 int  63 max 64\n",
      "value: 10483\n",
      "getobs set mask at 58 int  58 max 64\n",
      "value: 10593\n",
      "getobs set mask at 5 int  5 max 64\n",
      "value: 5942\n",
      "getobs set mask at 25 int  25 max 64\n",
      "value: 715\n",
      "getobs set mask at 12 int  12 max 64\n",
      "value: 4089\n",
      "getobs set mask at 48 int  48 max 64\n",
      "value: 8036\n",
      "getobs set mask at 7 int  7 max 64\n",
      "value: 5804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [10] -> ((12842, (356, 289, 697)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[4089, 8036, 9701, 2554, 541, 6931, 2214, 5804])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 2554 subsampling_weight: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 63 int  63 max 64\n",
      "value: 2214\n",
      "getobs set mask at 47 int  47 max 64\n",
      "value: 4089\n",
      "getobs set mask at 33 int  33 max 64\n",
      "value: 9701\n",
      "getobs set mask at 31 int  31 max 64\n",
      "value: 2554\n",
      "getobs set mask at 9 int  9 max 64\n",
      "value: 5804\n",
      "getobs set mask at 56 int  56 max 64\n",
      "value: 2214\n",
      "getobs set mask at 48 int  48 max 64\n",
      "value: 5804\n",
      "getobs set mask at 17 int  17 max 64\n",
      "value: 5804\n",
      "getobs set mask at 59 int  59 max 64\n",
      "value: 2554\n",
      "getobs set mask at 25 int  25 max 64\n",
      "value: 541\n",
      "getobs set mask at 41 int  41 max 64\n",
      "value: 6931\n",
      "getobs set mask at 14 int  14 max 64\n",
      "value: 4089\n",
      "getobs set mask at 36 int  36 max 64\n",
      "value: 2554\n",
      "getobs set mask at 47 int  47 max 64\n",
      "value: 4089\n",
      "getobs set mask at 58 int  58 max 64\n",
      "value: 4089\n",
      "getobs set mask at 49 int  49 max 64\n",
      "value: 5804\n",
      "getobs set mask at 43 int  43 max 64\n",
      "value: 9701\n",
      "getobs set mask at 47 int  47 max 64\n",
      "value: 2554\n",
      "getobs set mask at 58 int  58 max 64\n",
      "value: 2554\n",
      "getobs set mask at 44 int  44 max 64\n",
      "value: 4089\n",
      "getobs set mask at 19 int  19 max 64\n",
      "value: 6931\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 2214\n",
      "getobs set mask at 7 int  7 max 64\n",
      "value: 9701\n",
      "getobs set mask at 52 int  52 max 64\n",
      "value: 2554\n",
      "getobs set mask at 9 int  9 max 64\n",
      "value: 2554\n",
      "getobs set mask at 43 int  43 max 64\n",
      "value: 9701\n",
      "getobs set mask at 44 int  44 max 64\n",
      "value: 6931\n",
      "getobs set mask at 19 int  19 max 64\n",
      "value: 9701\n",
      "getobs set mask at 5 int  5 max 64\n",
      "value: 8036\n",
      "getobs set mask at 53 int  53 max 64\n",
      "value: 4813\n",
      "getobs set mask at 18 int  18 max 64\n",
      "value: 2414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [11] -> ((9077, (280, 313, 272)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[2102, 1194, 1251, 4589, 4774, 4937, 2392, 30, 4245, 5306, 1312, 12185, 6832, 1598, 6436, 185, 8096, 5766, 1166, 9483, 877, 11888, 9039, 6914, 333, 8145, 1899, 4293, 4813, 4927, 3200, 3970, 3314, 3129, 6082, 2539, 4294, 850, 7017, 188, 3884, 8011, 8015, 7734, 3793, 2275, 1597, 1049, 1602, 1001, 3440, 1212, 6223, 2053, 1171, 3564, 211, 6215, 1322, 4203, 3336, 9188, 3261, 1281, 4077, 5291, 3128, 3199, 4144, 31, 1728, 3335, 7710, 4059, 653, 2112, 10243, 814, 902, 3563, 2414, 212, 4222, 1791, 2990, 11334, 815, 4669, 2748, 994, 163, 1790, 2121, 7001, 6671, 2404, 4529, 335, 509, 5626, 1709, 6828, 2111, 2413, 11505, 8652, 2675, 6477, 334, 7544, 508, 2054, 2059, 4703, 1723, 741, 10381])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 9039 subsampling_weight: 121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 37 int  37 max 64\n",
      "value: 741\n",
      "getobs set mask at 7 int  7 max 64\n",
      "value: 741\n",
      "getobs set mask at 63 int  63 max 64\n",
      "value: 11888\n",
      "getobs set mask at 46 int  46 max 64\n",
      "value: 3129\n",
      "getobs set mask at 17 int  17 max 64\n",
      "value: 1166\n",
      "getobs set mask at 46 int  46 max 64\n",
      "value: 653\n",
      "getobs set mask at 48 int  48 max 64\n",
      "value: 5766\n",
      "getobs set mask at 8 int  8 max 64\n",
      "value: 334\n",
      "getobs set mask at 34 int  34 max 64\n",
      "value: 2102\n",
      "getobs set mask at 34 int  34 max 64\n",
      "value: 814\n",
      "getobs set mask at 10 int  10 max 64\n",
      "value: 1001\n",
      "getobs set mask at 52 int  52 max 64\n",
      "value: 5306\n",
      "getobs set mask at 18 int  18 max 64\n",
      "value: 1001\n",
      "getobs set mask at 12 int  12 max 64\n",
      "value: 508\n",
      "getobs set mask at 27 int  27 max 64\n",
      "value: 3261\n",
      "getobs set mask at 41 int  41 max 64\n",
      "value: 2112\n",
      "getobs set mask at 51 int  51 max 64\n",
      "value: 163\n",
      "getobs set mask at 34 int  34 max 64\n",
      "value: 1049\n",
      "getobs set mask at 24 int  24 max 64\n",
      "value: 6671\n",
      "getobs set mask at 13 int  13 max 64\n",
      "value: 3563\n",
      "getobs set mask at 40 int  40 max 64\n",
      "value: 10243\n",
      "getobs set mask at 31 int  31 max 64\n",
      "value: 2121\n",
      "getobs set mask at 28 int  28 max 64\n",
      "value: 2990\n",
      "getobs set mask at 20 int  20 max 64\n",
      "value: 1049\n",
      "getobs set mask at 35 int  35 max 64\n",
      "value: 4589\n",
      "getobs set mask at 19 int  19 max 64\n",
      "value: 2054\n",
      "getobs set mask at 46 int  46 max 64\n",
      "value: 1728\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 1171\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 335\n",
      "getobs set mask at 6 int  6 max 64\n",
      "value: 2054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [12] -> ((2965, (270, 508, 1352)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[4185])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 4185 subsampling_weight: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 14 int  14 max 64\n",
      "value: 4185\n",
      "getobs set mask at 21 int  21 max 64\n",
      "value: 4185\n",
      "getobs set mask at 35 int  35 max 64\n",
      "value: 4185\n",
      "getobs set mask at 41 int  41 max 64\n",
      "value: 4185\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 4185\n",
      "getobs set mask at 52 int  52 max 64\n",
      "value: 4185\n",
      "getobs set mask at 48 int  48 max 64\n",
      "value: 4185\n",
      "getobs set mask at 56 int  56 max 64\n",
      "value: 4185\n",
      "getobs set mask at 27 int  27 max 64\n",
      "value: 4185\n",
      "getobs set mask at 25 int  25 max 64\n",
      "value: 4185\n",
      "getobs set mask at 16 int  16 max 64\n",
      "value: 4185\n",
      "getobs set mask at 1 int  1 max 64\n",
      "value: 4185\n",
      "getobs set mask at 17 int  17 max 64\n",
      "value: 4185\n",
      "getobs set mask at 46 int  46 max 64\n",
      "value: 4185\n",
      "getobs set mask at 64 int  64 max 64\n",
      "value: 4185\n",
      "getobs set mask at 55 int  55 max 64\n",
      "value: 4185\n",
      "getobs set mask at 42 int  42 max 64\n",
      "value: 4185\n",
      "getobs set mask at 49 int  49 max 64\n",
      "value: 4185\n",
      "getobs set mask at 23 int  23 max 64\n",
      "value: 4185\n",
      "getobs set mask at 62 int  62 max 64\n",
      "value: 4185\n",
      "getobs set mask at 46 int  46 max 64\n",
      "value: 4185\n",
      "getobs set mask at 14 int  14 max 64\n",
      "value: 4185\n",
      "getobs set mask at 33 int  33 max 64\n",
      "value: 4185\n",
      "getobs set mask at 51 int  51 max 64\n",
      "value: 4185\n",
      "getobs set mask at 56 int  56 max 64\n",
      "value: 4185\n",
      "getobs set mask at 14 int  14 max 64\n",
      "value: 4185\n",
      "getobs set mask at 5 int  5 max 64\n",
      "value: 4185\n",
      "getobs set mask at 13 int  13 max 64\n",
      "value: 4185\n",
      "getobs set mask at 42 int  42 max 64\n",
      "value: 4185\n",
      "getobs set mask at 64 int  64 max 64\n",
      "value: 4185\n",
      "getobs set mask at 25 int  25 max 64\n",
      "value: 4185\n",
      "getobs set mask at 60 int  60 max 64\n",
      "value: 4185\n",
      "([176.0 2554.0 9039.0 4185.0], [30916 213838 644433 380042; 849038 1235731 879429 352316; 1066217 43537 536529 1410610; 581422 352397 1133190 589827; 566111 1079374 715690 14014; 581406 346419 674173 49569; 186937 639754 461018 1133385; 559578 874047 867844 1026284; 450598 1449965 228642 1377794; 960157 1493790 1463609 906689; 387984 712227 491364 627717; 39845 238980 376299 906049; 1125647 820275 642272 1463289; 758868 1242255 458456 137026; 1002268 1045769 690891 1123165; 480233 1125149 965497 817478; 941138 287332 1489674 239754; 218630 279155 1230598 451232; 1327333 161835 971377 519259; 133726 773369 1437618 263222; 421704 1084247 1202333 459454; 537250 682068 1455502 730085; 298357 866719 136654 15844; 1379840 328508 684670 58582; 161293 1256285 187178 1476346; 110997 1348577 1401144 6745; 470876 872696 813751 1443459; 123232 981928 1281753 502745; 776146 730788 70261 80146; 432828 259707 1381046 8742; 1204664 513771 1394208 290662; 833860 234349 502329 1496229], [0.049088069367381595 0.28867513459481287 0.09090909090909091 0.4472135954999579], [10531 12842 9077 2965; 37 356 280 270; 460 289 313 508; 684 697 272 1352], ([\"e\", \"e\", \"e\", \"e\"], ([\"r\", \"r\", \"r\", \"r\"], [\"r\", \"r\", \"r\", \"r\"], [\"r\", \"r\", \"r\", \"r\"])))\n",
      "-----------------\n",
      "getobs set mask at 61 int  61 max 64\n",
      "value: 8409\n",
      "getobs set mask at 12 int  12 max 64\n",
      "value: 7073\n",
      "getobs set mask at 23 int  23 max 64\n",
      "value: 10453\n",
      "getobs set mask at 63 int  63 max 64\n",
      "value: 7493\n",
      "getobs set mask at 19 int  19 max 64\n",
      "value: 2859\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 5474\n",
      "getobs set mask at 29 int  29 max 64\n",
      "value: 400\n",
      "getobs set mask at 33 int  33 max 64\n",
      "value: 9286\n",
      "getobs set mask at 32 int  32 max 64\n",
      "value: 7073\n",
      "getobs set mask at 5 int  5 max 64\n",
      "value: 8585\n",
      "getobs set mask at 28 int  28 max 64\n",
      "value: 3993\n",
      "getobs set mask at 36 int  36 max 64\n",
      "value: 2638\n",
      "getobs set mask at 51 int  51 max 64\n",
      "value: 8307\n",
      "getobs set mask at 37 int  37 max 64\n",
      "value: 3993\n",
      "getobs set mask at 7 int  7 max 64\n",
      "value: 802\n",
      "getobs set mask at 25 int  25 max 64\n",
      "value: 3431\n",
      "getobs set mask at 54 int  54 max 64\n",
      "value: 3035\n",
      "getobs set mask at 11 int  11 max 64\n",
      "value: 66\n",
      "getobs set mask at 26 int  26 max 64\n",
      "value: 6114\n",
      "getobs set mask at 60 int  60 max 64\n",
      "value: 9234\n",
      "getobs set mask at 27 int  27 max 64\n",
      "value: 7073\n",
      "getobs set mask at 1 int  1 max 64\n",
      "value: 8409\n",
      "getobs set mask at 51 int  51 max 64\n",
      "value: 5474\n",
      "getobs set mask at 36 int  36 max 64\n",
      "value: 1687\n",
      "getobs set mask at 21 int  21 max 64\n",
      "value: 3074\n",
      "getobs set mask at 49 int  49 max 64\n",
      "value: 7612\n",
      "getobs set mask at 4 int  4 max 64\n",
      "value: 10288\n",
      "getobs set mask at 59 int  59 max 64\n",
      "value: 9166\n",
      "getobs set mask at 48 int  48 max 64\n",
      "value: 11527\n",
      "getobs set mask at 57 int  57 max 64\n",
      "value: 1055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [13] -> ((8114, (1121, 61, 15)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[2099, 114, 4805, 5126, 10330, 5794, 10963, 3357, 5485, 10453, 9182, 1106, 6522, 6114, 3074, 7475, 8708, 7959, 10112, 7073, 4953, 7612, 8585, 365, 2952, 5348, 3989, 3986, 557, 3035, 970, 2424, 8990, 7414, 1844, 6214, 4505, 3305, 3719, 2710, 9614, 7445, 1340, 2638, 4210, 2859, 12028, 11527, 3777, 802, 1654, 6464, 6253, 3127, 4223, 4205, 6258, 873, 3451, 10397, 66, 6003, 9528, 2733, 2140, 5971, 4836, 5474, 4170, 788, 1779, 6791, 2243, 6757, 4314, 1272, 7202, 5178, 7332, 4859, 11785, 754, 4055, 11492, 7745, 19, 7248, 4074, 1436, 11170, 8920, 5915, 2400, 7334, 445, 6001, 3643, 2116, 10288, 12863, 8329, 10436, 3918, 8018, 209, 4800, 772, 3431, 3968, 649, 3678, 6309, 1185, 9286, 7986, 1055, 252, 1187, 9234, 9208, 4914, 8517, 10201, 13246, 7493, 2135, 8008, 1687, 8307, 4391, 7832, 9869, 8409, 6397, 400, 480, 113, 9728, 9166, 7908, 4981, 3993, 592])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 3035 subsampling_weight: 147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 38 int  38 max 64\n",
      "value: 3989\n",
      "getobs set mask at 44 int  44 max 64\n",
      "value: 1844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [14] -> ((7269, (74, 738, 183)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[403, 101])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 101 subsampling_weight: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 2 int  2 max 64\n",
      "value: 403\n",
      "getobs set mask at 52 int  52 max 64\n",
      "value: 101\n",
      "getobs set mask at 63 int  63 max 64\n",
      "value: 101\n",
      "getobs set mask at 55 int  55 max 64\n",
      "value: 101\n",
      "getobs set mask at 14 int  14 max 64\n",
      "value: 101\n",
      "getobs set mask at 23 int  23 max 64\n",
      "value: 101\n",
      "getobs set mask at 14 int  14 max 64\n",
      "value: 403\n",
      "getobs set mask at 11 int  11 max 64\n",
      "value: 101\n",
      "getobs set mask at 39 int  39 max 64\n",
      "value: 101\n",
      "getobs set mask at 5 int  5 max 64\n",
      "value: 403\n",
      "getobs set mask at 19 int  19 max 64\n",
      "value: 101\n",
      "getobs set mask at 61 int  61 max 64\n",
      "value: 101\n",
      "getobs set mask at 47 int  47 max 64\n",
      "value: 403\n",
      "getobs set mask at 32 int  32 max 64\n",
      "value: 101\n",
      "getobs set mask at 37 int  37 max 64\n",
      "value: 101\n",
      "getobs set mask at 16 int  16 max 64\n",
      "value: 101\n",
      "getobs set mask at 1 int  1 max 64\n",
      "value: 403\n",
      "getobs set mask at 35 int  35 max 64\n",
      "value: 101\n",
      "getobs set mask at 55 int  55 max 64\n",
      "value: 403\n",
      "getobs set mask at 13 int  13 max 64\n",
      "value: 403\n",
      "getobs set mask at 21 int  21 max 64\n",
      "value: 101\n",
      "getobs set mask at 46 int  46 max 64\n",
      "value: 403\n",
      "getobs set mask at 19 int  19 max 64\n",
      "value: 403\n",
      "getobs set mask at 54 int  54 max 64\n",
      "value: 101\n",
      "getobs set mask at 24 int  24 max 64\n",
      "value: 403\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 101\n",
      "getobs set mask at 20 int  20 max 64\n",
      "value: 101\n",
      "getobs set mask at 64 int  64 max 64\n",
      "value: 403\n",
      "getobs set mask at 56 int  56 max 64\n",
      "value: 101\n",
      "getobs set mask at 12 int  12 max 64\n",
      "value: 101\n",
      "getobs set mask at 55 int  55 max 64\n",
      "value: 101\n",
      "getobs set mask at 43 int  43 max 64\n",
      "value: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [15] -> ((11432, (1163, 732, 679)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[6534])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 6534 subsampling_weight: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 20 int  20 max 64\n",
      "value: 6534\n",
      "getobs set mask at 58 int  58 max 64\n",
      "value: 6534\n",
      "getobs set mask at 25 int  25 max 64\n",
      "value: 6534\n",
      "getobs set mask at 62 int  62 max 64\n",
      "value: 6534\n",
      "getobs set mask at 4 int  4 max 64\n",
      "value: 6534\n",
      "getobs set mask at 44 int  44 max 64\n",
      "value: 6534\n",
      "getobs set mask at 37 int  37 max 64\n",
      "value: 6534\n",
      "getobs set mask at 55 int  55 max 64\n",
      "value: 6534\n",
      "getobs set mask at 1 int  1 max 64\n",
      "value: 6534\n",
      "getobs set mask at 38 int  38 max 64\n",
      "value: 6534\n",
      "getobs set mask at 32 int  32 max 64\n",
      "value: 6534\n",
      "getobs set mask at 29 int  29 max 64\n",
      "value: 6534\n",
      "getobs set mask at 31 int  31 max 64\n",
      "value: 6534\n",
      "getobs set mask at 37 int  37 max 64\n",
      "value: 6534\n",
      "getobs set mask at 56 int  56 max 64\n",
      "value: 6534\n",
      "getobs set mask at 38 int  38 max 64\n",
      "value: 6534\n",
      "getobs set mask at 48 int  48 max 64\n",
      "value: 6534\n",
      "getobs set mask at 49 int  49 max 64\n",
      "value: 6534\n",
      "getobs set mask at 54 int  54 max 64\n",
      "value: 6534\n",
      "getobs set mask at 62 int  62 max 64\n",
      "value: 6534\n",
      "getobs set mask at 7 int  7 max 64\n",
      "value: 6534\n",
      "getobs set mask at 13 int  13 max 64\n",
      "value: 6534\n",
      "getobs set mask at 8 int  8 max 64\n",
      "value: 6534\n",
      "getobs set mask at 56 int  56 max 64\n",
      "value: 6534\n",
      "getobs set mask at 35 int  35 max 64\n",
      "value: 6534\n",
      "getobs set mask at 43 int  43 max 64\n",
      "value: 6534\n",
      "getobs set mask at 17 int  17 max 64\n",
      "value: 6534\n",
      "getobs set mask at 58 int  58 max 64\n",
      "value: 6534\n",
      "getobs set mask at 17 int  17 max 64\n",
      "value: 6534\n",
      "getobs set mask at 40 int  40 max 64\n",
      "value: 6534\n",
      "getobs set mask at 24 int  24 max 64\n",
      "value: 6534\n",
      "getobs set mask at 26 int  26 max 64\n",
      "value: 6534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset [16] -> ((8760, (57, 228, 81)), (\"e\", (\"r\", \"r\", \"r\"))) answer: Set(Any[9967])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTrainDataset tail 9967 subsampling_weight: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getobs set mask at 55 int  55 max 64\n",
      "value: 9967\n",
      "getobs set mask at 23 int  23 max 64\n",
      "value: 9967\n",
      "getobs set mask at 62 int  62 max 64\n",
      "value: 9967\n",
      "getobs set mask at 3 int  3 max 64\n",
      "value: 9967\n",
      "getobs set mask at 25 int  25 max 64\n",
      "value: 9967\n",
      "getobs set mask at 63 int  63 max 64\n",
      "value: 9967\n",
      "getobs set mask at 36 int  36 max 64\n",
      "value: 9967\n",
      "getobs set mask at 6 int  6 max 64\n",
      "value: 9967\n",
      "getobs set mask at 17 int  17 max 64\n",
      "value: 9967\n",
      "getobs set mask at 42 int  42 max 64\n",
      "value: 9967\n",
      "getobs set mask at 54 int  54 max 64\n",
      "value: 9967\n",
      "getobs set mask at 51 int  51 max 64\n",
      "value: 9967\n",
      "getobs set mask at 50 int  50 max 64\n",
      "value: 9967\n",
      "getobs set mask at 49 int  49 max 64\n",
      "value: 9967\n",
      "getobs set mask at 15 int  15 max 64\n",
      "value: 9967\n",
      "getobs set mask at 41 int  41 max 64\n",
      "value: 9967\n",
      "getobs set mask at 56 int  56 max 64\n",
      "value: 9967\n",
      "getobs set mask at 27 int  27 max 64\n",
      "value: 9967\n",
      "getobs set mask at 11 int  11 max 64\n",
      "value: 9967\n",
      "getobs set mask at 19 int  19 max 64\n",
      "value: 9967\n",
      "getobs set mask at 43 int  43 max 64\n",
      "value: 9967\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 9967\n",
      "getobs set mask at 23 int  23 max 64\n",
      "value: 9967\n",
      "getobs set mask at 30 int  30 max 64\n",
      "value: 9967\n",
      "getobs set mask at 47 int  47 max 64\n",
      "value: 9967\n",
      "getobs set mask at 13 int  13 max 64\n",
      "value: 9967\n",
      "getobs set mask at 22 int  22 max 64\n",
      "value: 9967\n",
      "getobs set mask at 53 int  53 max 64\n",
      "value: 9967\n",
      "getobs set mask at 18 int  18 max 64\n",
      "value: 9967\n",
      "getobs set mask at 62 int  62 max 64\n",
      "value: 9967\n",
      "getobs set mask at 44 int  44 max 64\n",
      "value: 9967\n",
      "getobs set mask at 41 int  41 max 64\n",
      "value: 9967\n",
      "([3035.0 101.0 6534.0 9967.0], [1425552 128842 205927 1336229; 322186 515084 1085267 989237; 1490309 1373849 205794 431883; 1434354 481849 884293 608597; 19128 528736 168842 1223987; 384844 260943 619541 1268823; 1442249 153892 1120047 1080338; 696357 1152230 92043 774222; 397903 321560 1396555 951212; 39164 692992 630142 1267669; 1446485 692809 1444543 475577; 605884 353282 19016 1277018; 587010 304732 324414 572624; 1199148 504153 679445 860927; 400427 857866 601011 1195195; 117806 1173636 911781 269553; 111888 1007476 519575 782912; 365174 571020 825658 1159466; 119399 651590 618499 859695; 85829 363028 1010148 223444; 575529 140791 156039 697818; 18234 172408 1193082 65302; 575002 313563 802474 710314; 23895 258304 1160161 436830; 542822 457644 1007145 1453407; 1317403 492124 1106285 1424601; 1252463 858987 725238 957869; 1297991 337967 371220 1018521; 720758 186432 121486 138747; 1163711 1301273 887806 209008; 1040743 1297751 613570 1214328; 1194801 1315422 394734 430237], [0.08247860988423225 0.408248290463863 0.4472135954999579 0.4472135954999579], [8114 7269 11432 8760; 1121 74 1163 57; 61 738 732 228; 15 183 679 81], ([\"e\", \"e\", \"e\", \"e\"], ([\"r\", \"r\", \"r\", \"r\"], [\"r\", \"r\", \"r\", \"r\"], [\"r\", \"r\", \"r\", \"r\"])))\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mgetobs one item -------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "flatten_queries = flatten_query(train_queries)\n",
    "t = length(flatten_queries)\n",
    "println(\" flatten_queries length: $(t)\")\n",
    "train_dataset = KGDataset.TrainDataset(flatten_queries, train_answers, t, t, 32)\n",
    "train_data_loader = MLUtils.DataLoader(train_dataset, batchsize = 4, collate = true, shuffle = false);\n",
    "\n",
    "idx = 1\n",
    "for d in train_data_loader\n",
    "    println(d)\n",
    "    println(\"-----------------\")\n",
    "    idx += 1\n",
    "    if idx > 4\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b876a522-b879-45f3-8604-d5854a74afa3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jupy_load_data (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function jupy_load_data(args, tasks, all_tasks, query_dict)\n",
    "    @info \"loading data....\"\n",
    "\n",
    "    data_path = args[\"data_path\"];\n",
    "    train_queries = Pickle.load(open(joinpath(data_path, f_train_queries)));\n",
    "    train_answers = Pickle.load(open(joinpath(data_path, f_train_answers)));\n",
    "    valid_queries = Pickle.load(open(joinpath(data_path, f_valid_queries)));\n",
    "    valid_hard_answers = Pickle.load(open(joinpath(data_path, f_valid_hard_answers)));\n",
    "    valid_easy_answers = Pickle.load(open(joinpath(data_path, f_valid_easy_answers)));\n",
    "    test_queries = Pickle.load(open(joinpath(data_path, f_test_queries)));\n",
    "    test_hard_answers = Pickle.load(open(joinpath(data_path, f_test_hard_answers)));\n",
    "    test_easy_answers = Pickle.load(open(joinpath(data_path, f_test_easy_answers)));\n",
    "\n",
    "    # remove tasks not in args.tasks\n",
    "    for name in all_tasks\n",
    "        if 'u' in name\n",
    "            name, evaluate_union = split(name, \"-\")\n",
    "        else\n",
    "            evaluate_union = args[\"evaluate_union\"]\n",
    "        end\n",
    "        if !(name in tasks) || evaluate_union != args[\"evaluate_union\"]\n",
    "            query_structure = query_dict[eval(if !('u' in name) name else join([name, evaluate_union], \"-\") end)]\n",
    "            #println(\"load_data: deleteing structure...:\\n $(query_structure)\")\n",
    "            if haskey(train_queries, query_structure)\n",
    "                delete!(train_queries, query_structure);\n",
    "            end\n",
    "            if haskey(valid_queries, query_structure)\n",
    "                delete!(valid_queries, query_structure);\n",
    "            end\n",
    "            if haskey(test_queries, query_structure)\n",
    "                delete!(test_queries, query_structure)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    @info \"load data....Done\"\n",
    "    return train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "678871bc-e742-48d5-9ad7-fc150f5235a0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Print the evaluation logs\n",
    "\"\"\"\n",
    "function log_metrics(mode, step, metrics)\n",
    "    for metric in metrics\n",
    "        @info \"$mode $metric at step $(step): $(metrics[metric.first])\"\n",
    "    end\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    Evaluate queries in dataloader\n",
    "\"\"\"\n",
    "function evaluate(model, tp_answers, fn_answers, args, dataloader, query_name_dict, mode, step, writer)\n",
    "\n",
    "    average_metrics = Dict{Float}()\n",
    "    all_metrics = Dict{Float}()\n",
    "\n",
    "    metrics = model.test_step(model, tp_answers, fn_answers, args, dataloader, query_name_dict)\n",
    "    num_query_structures = 0\n",
    "    num_queries = 0\n",
    "    for query_structure in metrics\n",
    "        log_metrics(mode * \" \" * query_name_dict[query_structure], step, metrics[query_structure])\n",
    "\n",
    "        for metric in metrics[query_structure]\n",
    "            writer.add_scalar(\"_\".join([mode, query_name_dict[query_structure], metric]), metrics[query_structure][metric], step)\n",
    "            all_metrics[\"_\".join([query_name_dict[query_structure], metric])] = metrics[query_structure][metric]\n",
    "            if metric != \"num_queries\"\n",
    "                average_metrics[metric] += metrics[query_structure][metric]\n",
    "            end\n",
    "        end\n",
    "        num_queries += metrics[query_structure][\"num_queries\"]\n",
    "        num_query_structures += 1\n",
    "    end\n",
    "\n",
    "    for metric in average_metrics\n",
    "        average_metrics[metric] /= num_query_structures\n",
    "        writer.add_scalar(\"_\".join([mode, \"average\", metric]), average_metrics[metric], step)\n",
    "        all_metrics[\"_\".join([\"average\", metric])] = average_metrics[metric]\n",
    "    end\n",
    "\n",
    "    log_metrics(\"$mode average\", step, average_metrics)\n",
    "    return all_metrics\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e852c1c-8fc9-4f9e-9677-8ab2fbf21a15",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flatten (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function format_time()\n",
    "    return Dates.format(Dates.now(), \"YY.mm.dd\")\n",
    "end\n",
    "\n",
    "#---Evaluate a tuple string into a tuple.\n",
    "function eval_tuple(arg_return)\n",
    "    if typeof(arg_return) <: Tuple\n",
    "        return arg_return\n",
    "    end\n",
    "\n",
    "    if !(arg_return[1] in (\"(\", \"[\"))\n",
    "        arg_return = eval(arg_return)\n",
    "    else\n",
    "        splitted = split(arg_return[2:length(arg_return)-1], \", \")\n",
    "        List = []\n",
    "        for item in splitted\n",
    "            try\n",
    "                item = eval(item)\n",
    "            catch err\n",
    "                pass\n",
    "            end\n",
    "            if item == \"\"\n",
    "                continue\n",
    "            end\n",
    "            append!(List, item)\n",
    "        end\n",
    "        arg_return = tuple(List)\n",
    "    return arg_return\n",
    "    end\n",
    "end\n",
    "\n",
    "function flatten_query(queries)\n",
    "    all_queries = []\n",
    "    for query_structure in keys(queries)\n",
    "        list_queries = collect(queries[query_structure])\n",
    "        #ttt = [(query, query_structure) for query in list_queries]\n",
    "        #println(\"query_structure key: $(query_structure) queries length: $(length(list_queries)) tuple length: $(length(ttt))\");\n",
    "        append!(all_queries, [(query, query_structure) for query in list_queries])\n",
    "    end\n",
    "    return all_queries\n",
    "end\n",
    "\n",
    "function flatten(l)\n",
    "    collect(Iterators.flatten(l))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe8f4885-5008-4dfa-a0f4-e0cc6540b449",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.KGDataset13"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module KGDataset\n",
    "\n",
    "using Main\n",
    "import MLUtils: DataLoader\n",
    "\n",
    "export numobs, getobs, TrainDataset, TestDataset, SingleDirectionalOneShotIterator\n",
    "\n",
    "abstract type Dataset end\n",
    "struct TrainDataset <: Dataset\n",
    "    queries::Vector{Any}\n",
    "    answer::Dict{Any, Any}\n",
    "    nentity::Int\n",
    "    nrelation::Int\n",
    "    negative_sample_size::Int\n",
    "    count::Dict{Tuple, Int}\n",
    "end\n",
    "#=\n",
    "function collate_fn(data::TrainDataset)\n",
    "    positive_sample = cat([_[0] for _ in data], dim=0)\n",
    "    negative_sample = stack([_[1] for _ in data], dim=0)\n",
    "    subsample_weight = cat([_[2] for _ in data], dim=0)\n",
    "    query = [_[3] for _ in data]\n",
    "    query_structure = [_[4] for _ in data]\n",
    "    return positive_sample, negative_sample, subsample_weight, query, query_structure\n",
    "end\n",
    "=#\n",
    "function count_frequency(queries, answer, start=4)\n",
    "    count = Dict{Tuple, Int}()\n",
    "    for (query, _) in queries\n",
    "        #println(\"$(query) -- $(length(answer[query]))\")\n",
    "        count[query] = start + length(answer[query])\n",
    "    end\n",
    "    return count\n",
    "end\n",
    "\n",
    "function TrainDataset(queries, answers, nentity, nrelation, negtaive_sample_size)\n",
    "    count = count_frequency(queries, answers);\n",
    "    return TrainDataset(queries, answers, nentity, nrelation, negtaive_sample_size, count)\n",
    "end\n",
    "\n",
    "function numobs(data::TrainDataset)\n",
    "    return length(data.queries)\n",
    "end\n",
    "\n",
    "function getobs(data::TrainDataset, idx::Int)\n",
    "\n",
    "    query = data.queries[idx][1]\n",
    "    query_structure = data.queries[idx][2]\n",
    "    @info \"TrainDataset [$(idx)] -> $(data.queries[idx]) answer: $(data.answer[query])\"\n",
    "    tail = rand(collect(data.answer[query]))\n",
    "    subsampling_weight = data.count[query]\n",
    "    @info \"TrainDataset tail $(tail) subsampling_weight: $(subsampling_weight)\"\n",
    "    subsampling_weight = sqrt.(1 ./ [subsampling_weight])\n",
    "    negative_sample_list = []\n",
    "    negative_sample_size = 0\n",
    "    while negative_sample_size < data.negative_sample_size\n",
    "        negative_sample = rand(1:data.nentity, data.negative_sample_size*2)\n",
    "        # check whether the items in ar1 belong to ar2, return a vector\n",
    "        # has the same length with ar1, filled with true or false\n",
    "        #mask = np.in1d(negative_sample, data.answer[query],\n",
    "        #               assume_unique=true, invert=true)\n",
    " \n",
    "        avail_index = indexin(negative_sample, collect(data.answer[query]))\n",
    "        #println(\"avail_index: $(avail_index)\")\n",
    "        mask = falses(data.negative_sample_size * 2)\n",
    "        #println(\"mask: $(mask)\")\n",
    "        map(avail_index) do x\n",
    "            if x != nothing\n",
    "                println(\"getobs: set mask at $x\")\n",
    "                mask[Int(x)] = true\n",
    "            end \n",
    "        end\n",
    "        reverse!(mask)\n",
    "        negative_sample = negative_sample[mask]\n",
    "        append!(negative_sample_list, negative_sample)\n",
    "        negative_sample_size += length(negative_sample)\n",
    "    end\n",
    "    negative_sample = stack(negative_sample_list)[1:data.negative_sample_size]\n",
    "    negative_sample = negative_sample # original: torch.from_numpy\n",
    "    positive_sample = convert.(Float64, [tail])\n",
    "\n",
    "    return positive_sample, negative_sample, subsampling_weight, Main.flatten(query), query_structure\n",
    "end\n",
    "\n",
    "struct SingleDirectionalOneShotIterator\n",
    "    data_loader::DataLoader\n",
    "end\n",
    "\n",
    "function Base.iterate(iter::SingleDirectionalOneShotIterator)\n",
    "    state = 1\n",
    "    if length(iter.data_loader.data.queries) <= 0\n",
    "        return nothing\n",
    "    end\n",
    "\n",
    "    return ( getobs(iter.data_loader.data, state), state + 1 )\n",
    "end\n",
    "\n",
    "function Base.iterate(iter::SingleDirectionalOneShotIterator, state = 1)\n",
    "    if length(iter.data_loader.data.queries) < state\n",
    "        return nothing\n",
    "    end\n",
    "\n",
    "    return ( getobs(iter.data_loader.data, state), state + 1 )\n",
    "end\n",
    "\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae66064-914a-4244-a018-fa77ddeeadfd",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "using Revise\n",
    "using MLUtils;\n",
    "\n",
    "using .KGDataset13\n",
    "\n",
    "train_flatten_queries = flatten_query(train_queries);\n",
    "println(\"length of train_flatten_queries: $(length(train_flatten_queries))\")\n",
    "println(\"length of train_answers: $(length(train_answers))\")\n",
    "negative_sample_size = 32\n",
    "batch_size = 1\n",
    "nentity=sum([length(q) for q in train_flatten_queries])\n",
    "nrelation=sum([length(q) for q in train_flatten_queries])\n",
    "data_set = KGDataset13.TrainDataset(train_flatten_queries, train_answers, nentity, nrelation, negative_sample_size);\n",
    "#DataLoader(data; [batchsize, buffer, collate, parallel, partial, rng, shuffle])\n",
    "data_loader = MLUtils.DataLoader(data_set, batchsize = batch_size, collate = true, shuffle=false);\n",
    "#println(typeof(data_loader.data))\n",
    "#println(\"numobs, getobs.....\")\n",
    "train_path_iterator = KGDataset13.SingleDirectionalOneShotIterator(data_loader);\n",
    "\n",
    "data_index = 1\n",
    "for item in train_path_iterator\n",
    "    println(\"for loop: --$(item)\")\n",
    "    data_index += 1\n",
    "    if data_index >= 2\n",
    "        break\n",
    "    end\n",
    "end\n",
    "\n",
    "(item, next)  = iterate(train_path_iterator,data_index)\n",
    "println(item)\n",
    "\n",
    "(item, next)  = iterate(train_path_iterator, next)\n",
    "println(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd7e27-170a-4a7d-836e-18e03b0c89c5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "module KGModule\n",
    "\n",
    "using Zygote: AbstractFFTs\n",
    "export Identity, normDims, BoxOffsetIntersection, CenterIntersection, BetaIntersection,\n",
    "    BetaProjection, Regularizer, KGReasoning, train_step\n",
    "\n",
    "using Flux;\n",
    "using Zygote;\n",
    "using Statistics;\n",
    "using Distributions;\n",
    "using MLUtils;\n",
    "\n",
    "include(\"src/utils.jl\")\n",
    "\n",
    "function Identity(x)\n",
    "    return x;\n",
    "end\n",
    "\n",
    "function normDims(itr, p::Real=2; dim)\n",
    "    sum(itr .^ p; dims=dim).^(1 / p)\n",
    "end\n",
    "\n",
    "struct BoxOffsetIntersection\n",
    "    dim::Int\n",
    "    layer1::Flux.Dense\n",
    "    layer2::Flux.Dense\n",
    "end\n",
    "\n",
    "function BoxOffsetIntersection(dim::Int)\n",
    "    layer1 = Flux.Dense(dim => dim);\n",
    "    layer2 = Flux.Dense(dim => dim);\n",
    "\n",
    "    return BoxOffsetIntersection(dim, layer1, layer2);\n",
    "end\n",
    "\n",
    "#Function-like Object\n",
    "function (m::BoxOffsetIntersection)(embeddings)\n",
    "    @show embeddings\n",
    "    layer1_act = Flux.relu(m.layer1(embeddings))\n",
    "    @show layer1_act\n",
    "    layer1_mean = mean(layer1_act, dims=length(size(layer1_act)))\n",
    "    @show layer1_mean\n",
    "    gate = Flux.sigmoid(m.layer2(layer1_mean))\n",
    "    @show gate\n",
    "    offset = minimum(embeddings, dims=length(size(layer1_act)))\n",
    "\n",
    "    return offset .* gate\n",
    "end\n",
    "\n",
    "Flux.@functor BoxOffsetIntersection\n",
    "\n",
    "struct CenterIntersection\n",
    "    dim::Int\n",
    "    layer1::Flux.Dense\n",
    "    layer2::Flux.Dense\n",
    "end\n",
    "\n",
    "function CenterIntersection(dim::Int)\n",
    "    layer1 = Flux.Dense(dim => dim)\n",
    "    layer2 = Flux.Dense(dim => dim)\n",
    "\n",
    "    #Flux.Dense is initialized by  xavier defaultly\n",
    "    return CenterIntersection(dim, layer1, layer2)\n",
    "end\n",
    "\n",
    "function (m::CenterIntersection)(embeddings)\n",
    "    layer1_act = Flux.relu(m.layer1(embeddings)) # ( dim, num_conj)\n",
    "    attention = Flux.softmax(m.layer2(layer1_act), dims=length(size(layer1_act))) # (dim, num_conj, )\n",
    "    embedding = sum(attention * embeddings, dims=length(size(layer1_act)))\n",
    "\n",
    "    return embedding\n",
    "end\n",
    "\n",
    "Flux.@functor CenterIntersection\n",
    "\n",
    "struct BetaIntersection\n",
    "    dim::Int\n",
    "    layer1::Flux.Dense\n",
    "    layer2::Flux.Dense\n",
    "end\n",
    "\n",
    "function BetaIntersection(dim::Int)\n",
    "    layer1 = Flux.Dense(2 * dim, 2 * dim)\n",
    "    layer2 = Flux.Dense(2 * dim, dim)\n",
    "\n",
    "    return BetaIntersection(dim, layer1, layer2)\n",
    "end\n",
    "\n",
    "function (m::BetaIntersection)(alpha_embeddings, beta_embeddings)\n",
    "    all_embeddings = cat(length(size(alpha_embeddings)), alpha_embeddings, beta_embeddings)\n",
    "    layer1_act = Flux.relu(m.layer1(all_embeddings)) # (num_conj, batch_size, 2 * dim)\n",
    "    attention = Flux.softmax(m.layer2(layer1_act), dims=length(size(alpha_embeddings))) # (num_conj, batch_size, dim)\n",
    "\n",
    "    alpha_embedding = sum(attention * alpha_embeddings, dims=length(size(alpha_embeddings)))\n",
    "    beta_embedding = sum(attention * beta_embeddings, dims=length(size(alpha_embeddings)))\n",
    "\n",
    "    return alpha_embedding, beta_embedding\n",
    "end\n",
    "\n",
    "Flux.@functor BetaIntersection\n",
    "\n",
    "struct Regularizer\n",
    "    base_add::AbstractFloat\n",
    "    min_val::AbstractFloat\n",
    "    max_val::AbstractFloat\n",
    "end\n",
    "\n",
    "function (m::Regularizer)(entity_embedding)\n",
    "    return clamp(entity_embedding + m.base_add, m.min_val, m.max_val)\n",
    "end\n",
    "\n",
    "Flux.@functor Regularizer\n",
    "\n",
    "struct BetaProjection\n",
    "    entity_dim::Int\n",
    "    relation_dim::Int\n",
    "    hidden_dim::Int\n",
    "    num_layers::Int\n",
    "\n",
    "    layers::Dict{Symbol, Flux.Dense}\n",
    "    projection_regularizer\n",
    "end\n",
    "\n",
    "function Base.setproperty!(m::BetaProjection, property::Symbol, value)\n",
    "    getfield(m, :layers)[property] = value\n",
    "end\n",
    "\n",
    "function Base.getproperty(m::BetaProjection, property::Symbol, value)\n",
    "    return getfield(m, :layers)[property]\n",
    "end\n",
    "\n",
    "function Base.propertynames(m::BetaProjection, private = false)\n",
    "    return keys(getproperty(m, :layers))\n",
    "end\n",
    "\n",
    "function BetaProjection(entity_dim, relation_dim, hidden_dim, projection_regularizer, num_layers)\n",
    "    layer1 = Flux.Dense((entity_dim + relation_dim) => hidden_dim) # 1st layer\n",
    "    layer0 = Flux.Dense(hidden_dim => entity_dim) # final layer\n",
    "\n",
    "    layers = Dict{Symbol, Flux.Dense}()\n",
    "    layers[:layer1] = Flux.Dense((entity_dim + relation_dim) => hidden_dim) # 1st layer\n",
    "    layers[:layer0]  = Flux.Dense(hidden_dim => entity_dim) # final layer\n",
    "    for nl in range(2, num_layers)\n",
    "        layers[Symbol(\"layer$(nl)\")] = Flux.Dense(hidden_dim, hidden_dim)\n",
    "    end\n",
    "\n",
    "    return BetaProjection(entity_dim, relation_dim, hidden_dim, num_layers,\n",
    "                          layers, projection_regularizer)\n",
    "\n",
    "end\n",
    "\n",
    "function (m::BetaProjection)(e_embedding, r_embedding)\n",
    "    x = cat(1, e_embedding, r_embedding)\n",
    "    for nl in range(1, m.num_layers)\n",
    "        x = Flux.relu(getproperty(m, Symbol(\"layer$(nl)\")(x)))\n",
    "    end\n",
    "    x = getproperty(m, :layer0)(x)\n",
    "    x = m.projection_regularizer(x)\n",
    "\n",
    "    return x\n",
    "end\n",
    "\n",
    "Flux.@functor BetaProjection\n",
    "\n",
    "struct KGReasoning\n",
    "    nentity::Int\n",
    "    nrelation::Int\n",
    "    hidden_dim::Int\n",
    "    epsilon::AbstractFloat\n",
    "    geo::String\n",
    "    use_cuda::Bool\n",
    "    batch_entity_range #TODO type and initialize\n",
    "    query_name_dict::Dict{Tuple, String}\n",
    "    ############################################\n",
    "    gamma # nn.Parameter\n",
    "    embedding_range # nn.Parameter\n",
    "\n",
    "    entity_dim::Int\n",
    "    relation_dim::Int\n",
    "\n",
    "    entity_embedding # nn.Parameter\n",
    "    cen\n",
    "    func\n",
    "    entity_regularizer\n",
    "    projection_regularizer\n",
    "\n",
    "    offset_embedding\n",
    "    center_net\n",
    "    offset_net\n",
    "    #hidden_dim\n",
    "    num_layers\n",
    "    #center_net\n",
    "    projection_net\n",
    "end\n",
    "\n",
    "Flux.@functor KGReasoning\n",
    "\n",
    "function KGReasoning(nentity, nrelation, hidden_dim, gamma, geo, test_batch_size=1,\n",
    "                     box_mode=nothing, beta_mode=nothing, query_name_dict=nothing, use_cuda=false)\n",
    "    epsilon = 2.0\n",
    "\n",
    "    batch_entity_range = repeat(convert.(Float32, range(0, nentity - 1)), 1, test_batch_size)\n",
    "\n",
    "    gamma = Zygote.Params([gamma])\n",
    "    embedding_range = Zygote.Params([(gamma .+ epsilon) / hidden_dim]);\n",
    "\n",
    "    entity_dim = hidden_dim\n",
    "    relation_dim = hidden_dim\n",
    "\n",
    "    activation, cen, func = repeat([nothing], 3)\n",
    "    entity_embedding , entity_regularizer, projection_regularizer = repeat([nothing], 3)\n",
    "    if geo == \"box\"\n",
    "        entity_embedding = Zygote.Params(zeros(nentity, entity_dim)) # centor for entities\n",
    "        activation, cen = box_mode\n",
    "        cen = cen # hyperparameter that balances the in-box distance and the out-box distance\n",
    "        if activation == \"none\"\n",
    "            func = Identity;\n",
    "        elseif activation == \"relu\"\n",
    "            func = Flux.relu;\n",
    "        elseif activation == \"softplus\"\n",
    "            func = Flux.softplus;\n",
    "        end\n",
    "    elseif geo == \"vec\"\n",
    "        #entity_embedding = Flux.params(zeros(nentity, entity_dim)) # center for entities\n",
    "        entity_embedding = Zygote.Params(Flux.glorot_uniform(nentity, entity_dim))\n",
    "    elseif geo == \"beta\"\n",
    "        #entity_embedding = Flux.params(zeros(nentity, self.entity_dim * 2)) # alpha and beta\n",
    "        entity_embedding = Zygote.Params(Flux.glorot_uniform(nentity, entity_dim * 2))\n",
    "        entity_regularizer = Regularizer(1, 0.05, 1e9) # make sure the parameters of beta embeddings are positive\n",
    "        projection_regularizer = Regularizer(1, 0.05, 1e9) # make sure the parameters of beta embeddings after relation projection are positive\n",
    "    end\n",
    "    #nn.init.uniform_(\n",
    "    #    tensor=self.entity_embedding,\n",
    "    #    ###########################TODO##################################\n",
    "    #    a = -embedding_range,\n",
    "    #    b = embedding_range\n",
    "    #)\n",
    "    #relation_embedding = Flux.params(zeros(nrelation, relation_dim))\n",
    "    relation_embedding = Zygote.Params(Flux.glorot_uniform(nrelation, relation_dim))\n",
    "    #nn.init.uniform_(\n",
    "    #    tensor=relation_embedding,\n",
    "    #    a = -embedding_range,\n",
    "    #    b = embedding_range\n",
    "    #)\n",
    "\n",
    "    num_layers, offset_embedding, center_net, offset_net, projection_net = repeat([nothing], 6)\n",
    "    if geo == \"box\"\n",
    "        offset_embedding = Zygote.Params(Flux.glorot_uniform(nrelation, entity_dim))\n",
    "        #self.offset_embedding = nn.Parameter(torch.zeros(nrelation, self.entity_dim))\n",
    "        #nn.init.uniform_(\n",
    "        #    tensor=self.offset_embedding,\n",
    "        #    a=0.,\n",
    "        #    b=self.embedding_range.item()\n",
    "        #)\n",
    "        center_net = CenterIntersection(entity_dim)\n",
    "        offset_net = BoxOffsetIntersection(entity_dim)\n",
    "    elseif geo == \"vec\"\n",
    "        center_net = CenterIntersection(entity_dim)\n",
    "    elseif geo == \"beta\"\n",
    "        hidden_dim, num_layers = eval_tuple(beta_mode)\n",
    "\n",
    "        center_net = BetaIntersection(entity_dim)\n",
    "        projection_net = BetaProjection(entity_dim * 2,\n",
    "                                        relation_dim,\n",
    "                                        hidden_dim,\n",
    "                                        projection_regularizer,\n",
    "                                        num_layers)\n",
    "    end\n",
    "\n",
    "    return KGReasoning(nentity, nrelation, hidden_dim, epsilon, geo, use_cuda, batch_entity_range,\n",
    "                       query_name_dict, gamma, embedding_range, entity_dim, relation_dim, entity_embedding,\n",
    "                       cen, func, entity_regularizer, projection_regularizer, offset_embedding,\n",
    "                       center_net, offset_net, num_layers, projection_net);\n",
    "end\n",
    "\n",
    "function forward(m::KGReasoning, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    if m.geo == \"box\"\n",
    "        return forward_box(m, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    elseif m.geo == \"vec\"\n",
    "        return forward_vec(m, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    elseif m.geo == \"beta\"\n",
    "        return forward_beta(m, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    end\n",
    "end\n",
    "\n",
    "####\n",
    "# embed a batch of queries with same structure using Query2box\n",
    "# queries: a flattened batch of queries\n",
    "####\n",
    "function embed_query_box(m::KGReasoning, queries, query_structure, idx)\n",
    "    #@printf (queries)\n",
    "    #@printf (query_structure)\n",
    "    all_relation_flag = true\n",
    "     # whether the current query tree has mfferged to one branch and only need to do relation traversal,\n",
    "     # e.g., path queries or conjunctive queries after the intersection\n",
    "    for r in last(query_structure)\n",
    "        if !(r in [\"r\", \"n\"])\n",
    "            all_relation_flag = false\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if all_relation_flag\n",
    "        if query_structure[0] == \"e\"\n",
    "            embedding = m.entity_embedding[:, queries[:, idx]]\n",
    "            #embedding = torch.index_select(m.entity_embedding, dim=0, index=queries[:, idx])\n",
    "            offset_embedding = zeros(size(embedding))\n",
    "            if m.use_cuda\n",
    "                offset_embedding = zeros(size(embedding)) .|> gpu\n",
    "            end\n",
    "            idx += 1\n",
    "        else\n",
    "            embedding, offset_embedding, idx = embed_query_box(m, queries, query_structure[0], idx)\n",
    "        end\n",
    "\n",
    "        for i in range(1, length(last(query_structure)))\n",
    "            if last(query_structure)[i] == \"n\"\n",
    "                @assert false \"box cannot handle queries with negation\"\n",
    "            else\n",
    "                r_embedding = m.ralation_embedding[:, queries[:, idx]]\n",
    "                #r_embedding = torch.index_select(self.relation_embedding, dim=0, index=queries[:, idx])\n",
    "                r_offset_embedding = offset_bedding[:, queries[:, idx]]\n",
    "                #r_offset_embedding = torch.index_select(self.offset_embedding, dim=0, index=queries[:, idx])\n",
    "                embedding += r_embedding\n",
    "                offset_embedding += m.func(r_offset_embedding)\n",
    "            end\n",
    "            idx += 1\n",
    "        end\n",
    "    else\n",
    "        embedding_list = []\n",
    "        offset_embedding_list = []\n",
    "        for i in range(1, length(query_structure))\n",
    "            embedding, offset_embedding, idx = embed_query_box(m, queries, query_structure[i], idx)\n",
    "            push!(embedding_list, embedding)\n",
    "            push!(offset_embedding_list, offset_embedding)\n",
    "        end\n",
    "        embedding = m.center_net(vcat(embedding_list))\n",
    "        offset_embedding = m.offset_net(vcat(offset_embedding_list))\n",
    "    end\n",
    "    return embedding, offset_embedding, idx\n",
    "end\n",
    "\n",
    "#=\n",
    "Iterative embed a batch of queries with same structure using GQE\n",
    "queries: a flattened batch of queries\n",
    "=#\n",
    "function embed_query_vec(m::KGReasoning, queries, query_structure, idx)\n",
    "\n",
    "    all_relation_flag = true\n",
    "    # whether the current query tree has merged to one branch and only need to do relation traversal,\n",
    "    # e.g., path queries or conjunctive queries after the intersection\n",
    "    for ele in last(query_structure)\n",
    "        if !(ele in [\"r\", \"n\"])\n",
    "            all_relation_flag = false\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    if all_relation_flag\n",
    "        if query_structure[1] == \"e\"\n",
    "            embedding = m.entity_embedding[:,queries[:, idx]]\n",
    "            #embedding = torch.index_select(self.entity_embedding, dim=0, index=queries[:, idx])\n",
    "            idx += 1\n",
    "        else\n",
    "            embedding, idx = embed_query_vec(m, queries, query_structure[0], idx)\n",
    "        end\n",
    "\n",
    "        for i in range(length(last(query_structure)))\n",
    "            if last(query_structure)[i] == \"n\"\n",
    "                @assert false  \"vec cannot handle queries with negation\"\n",
    "            else\n",
    "                r_embedding = m.relation_embedding[:, queries[:, idx]]\n",
    "                #r_embedding = torch.index_select(self.relation_embedding, dim=0, index=queries[:, idx])\n",
    "                embedding += r_embedding\n",
    "            end\n",
    "            idx += 1\n",
    "        end\n",
    "    else\n",
    "        embedding_list = []\n",
    "        for i in range(1, length(query_structure))\n",
    "            embedding, idx = embed_query_vec(m, queries, query_structure[i], idx)\n",
    "            push!(dembedding_list, embedding)\n",
    "        end\n",
    "        embedding = m.center_net(vcat(embedding_list))\n",
    "    end\n",
    "    return embedding, idx\n",
    "end\n",
    "\n",
    "#=\n",
    "Iterative embed a batch of queries with same structure using BetaE\n",
    "queries: a flattened batch of queries\n",
    "=#\n",
    "function embed_query_beta(m::KGReasoning, queries, query_structure, idx)\n",
    "\n",
    "    all_relation_flag = true\n",
    "    # whether the current query tree has merged to one branch and only need to do relation traversal,\n",
    "    # e.g., path queries or conjunctive queries after the intersection\n",
    "    for ele in last(query_structure)\n",
    "        if !(ele in [\"r\", \"n\"])\n",
    "            all_relation_flag = false\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    if all_relation_flag\n",
    "        if query_structure[1] == \"e\"\n",
    "            embedding = m.entity_regularizer(selectdim(m.entity_embedding, dims=ndims(m.entity_embedding), queries[:, idx]))\n",
    "            #embedding = m.entity_regularizer(torch.index_select(self.entity_embedding, dim=0, index=queries[:, idx]))\n",
    "            idx += 1\n",
    "        else\n",
    "            alpha_embedding, beta_embedding, idx = m.embed_query_beta(m, queries, query_structure[1], idx)\n",
    "            embedding = cat(alpha_embedding, beta_embedding, dim=0)\n",
    "        end\n",
    "        for i in range(1, length(last(query_structure)))\n",
    "            if last(query_structure)[i] == \"n\"\n",
    "                @assert (queries[:, idx] == -2).all()\n",
    "                embedding = 1 ./ embedding\n",
    "            else\n",
    "                r_embedding = m.relation_embedding(queries[:, idx], :)\n",
    "                #r_embedding = torch.index_select(self.relation_embedding, dim=0, index=queries[:, idx])\n",
    "                embedding = m.projection_net(embedding, r_embedding)\n",
    "            end\n",
    "            idx += 1\n",
    "        end\n",
    "        ###############################TODO####################################\n",
    "        alpha_embedding, beta_embedding = chunk(embedding, 2, dim=ndims(embedding))\n",
    "    else\n",
    "        alpha_embedding_list = []\n",
    "        beta_embedding_list = []\n",
    "        for i in range(1, length(query_structure))\n",
    "            alpha_embedding, beta_embedding, idx = embed_query_beta(m, queries, query_structure[i], idx)\n",
    "            push!(alpha_embedding_list, alpha_embedding)\n",
    "            push!(beta_embedding_list, beta_embedding)\n",
    "        end\n",
    "        alpha_embedding, beta_embedding = m.center_net(cat(alpha_embedding_list), cat(beta_embedding_list))\n",
    "    end\n",
    "    return alpha_embedding, beta_embedding, idx\n",
    "end\n",
    "\n",
    "#============================================\n",
    "    transform 2u queries to two 1p queries\n",
    "    transform up queries to two 2p queries\n",
    "============================================#\n",
    "function transform_union_query(m::KGReasoning, queries, query_structure)\n",
    "\n",
    "    if m.query_name_dict[query_structure] == \"2u-DNF\"\n",
    "        queries = queries[:, 1:(size(queries, 2) - 1)] # remove union -1\n",
    "    elseif m.query_name_dict[query_structure] == \"up-DNF\"\n",
    "        queries = cat(cat(queries[:, 1:2], queries[:, 5:6], dims=1), cat(queries[:, 2:4], queries[:, 5:6], dims=1), dims=1)\n",
    "    end\n",
    "    queries = reshape(queries, :, size(queries)[1]*2)\n",
    "    return queries\n",
    "end\n",
    "\n",
    "function transform_union_structure(m::KGReasoning, query_structure)\n",
    "    if m.query_name_dict[query_structure] == \"2u-DNF\"\n",
    "        return (\"e\", (\"r\",))\n",
    "    elseif m.query_name_dict[query_structure] == \"up-DNF\"\n",
    "        return (\"e\", (\"r\", \"r\"))\n",
    "    end\n",
    "end\n",
    "\n",
    "function cal_logit_beta(m::KGReasoning, entity_embedding, query_dist)\n",
    "    ##########################TODO#######################################\n",
    "    alpha_embedding, beta_embedding = chunk(entity_embedding, 2)\n",
    "    entity_dist = Distributions.Beta(alpha_embedding, beta_embedding)\n",
    "    logit = m.gamma - normDims(Distributions.KLDivergence(entity_dist, query_dist), 1)\n",
    "    return logit\n",
    "end\n",
    "\n",
    "function forward_beta(m::KGReasoning, positive_sample, negative_sample, subsampling_weight,\n",
    "                      batch_queries_dict, batch_idxs_dict)\n",
    "    all_idxs, all_alpha_embeddings, all_beta_embeddings = [], [], []\n",
    "    all_union_idxs, all_union_alpha_embeddings, all_union_beta_embeddings = [], [], []\n",
    "    for query_structure in batch_queries_dict\n",
    "        if \"u\" in m.query_name_dict[query_structure] && \"DNF\" in m.query_name_dict[query_structure]\n",
    "            alpha_embedding, beta_embedding, _ = \\\n",
    "                embed_query_beta(m, transform_union_query(m, batch_queries_dict[query_structure],\n",
    "                                                            query_structure),\n",
    "                                 transform_union_structure(m, query_structure),\n",
    "                                 0)\n",
    "            push!(all_union_idxs, batch_idxs_dict[query_structure])\n",
    "            #all_union_idxs.extend(batch_idxs_dict[query_structure])\n",
    "            push!(all_union_alpha_embeddings, alpha_embedding)\n",
    "            push!(all_union_beta_embeddings, beta_embedding)\n",
    "        else\n",
    "            alpha_embedding, beta_embedding, _ = embed_query_beta(m, batch_queries_dict[query_structure],\n",
    "                                                                  query_structure,\n",
    "                                                                  0)\n",
    "            push!(all_idxs, batch_idxs_dict[query_structure])\n",
    "            #all_idxs.extend(batch_idxs_dict[query_structure])\n",
    "            push!(all_alpha_embeddings, alpha_embedding)\n",
    "            push!(all_beta_embeddings, beta_embedding)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if length(all_alpha_embeddings) > 0\n",
    "        #all_alpha_embeddings = torch.cat(all_alpha_embeddings, dim=0).unsqueeze(1)\n",
    "        all_alpha_embeddfings = reduce((x, y) -> cat(x, y, dims=ndims(x)), all_alpha_embeddings)\n",
    "        all_beta_embeddings = reduce(all_beta_embeddings) do x, y\n",
    "                                         cat(x, y, dims=ndims(x))\n",
    "                                     end\n",
    "        all_beta_embeddings= unsqueeze(all_beta_embeddings, dims = ndims(all_beta_embeddings))\n",
    "        all_dists = Distributions.Beta(all_alpha_embeddings, all_beta_embeddings)\n",
    "    end\n",
    "\n",
    "    if len(all_union_alpha_embeddings) > 0\n",
    "        #all_union_alpha_embeddings = torch.cat(all_union_alpha_embeddings, dim=0).unsqueeze(1)\n",
    "        #all_union_beta_embeddings = torch.cat(all_union_beta_embeddings, dim=0).unsqueeze(1)\n",
    "        #all_union_alpha_embeddings = all_union_alpha_embeddings.view(all_union_alpha_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        #all_union_beta_embeddings = all_union_beta_embeddings.view(all_union_beta_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        #all_union_dists = torch.distributions.beta.Beta(all_union_alpha_embeddings, all_union_beta_embeddings)\n",
    "        all_union_alpha_embeddings = reduce(all_union_alpha_embeddings) do x, y\n",
    "                                             cat(x, y, dim=ndims(x))\n",
    "                                         end\n",
    "        #all_union_alpha_embeddings = cat(all_union_alpha_embeddings, dims = ndims(all_union_alpha_embeddings) + 1)\n",
    "        all_union_alpha_embeddings = unsqueeze(all_union_alpha_embeddings, dims = ndims(all_union_alpha_embeddings))\n",
    "        all_union_beta_embeddings = reduce(all_union_beta_embeddings) do x, y\n",
    "                                             cat(x, y, dim=ndims(x))\n",
    "                                         end\n",
    "        all_union_beta_embeddings = unsqueeze(all_union_beta_embeddings, dims = ndims(all_union_beta_embeddings))\n",
    "        #################################################################################################\n",
    "        #all_union_alpha_embeddings = all_union_alpha_embeddings.view(all_union_alpha_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        #all_union_beta_embeddings = all_union_beta_embeddings.view(all_union_beta_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        all_union_alpha_embeddings = reshape(all_union_alpha_embeddings, :, 1, 2,\n",
    "                                             div(size(all_union_alpha_embeddings, ndims(all_union_alpha_embedding)), 2))\n",
    "        all_union_beta_embeddings = reshape(all_union_beta_embeddings, :, 1, 2,\n",
    "                                             div(size(all_union_beta_embeddings, ndims(all_union_beta_embedding)), 2))\n",
    "\n",
    "        all_union_dists = Distributions.Beta(all_union_alpha_embeddings, all_union_beta_embeddings)\n",
    "    end\n",
    "\n",
    "    if typeof(subsampling_weight) != typeof(nothing)\n",
    "        subsampling_weight = subsampling_weight[all_idxs+all_union_idxs]\n",
    "    end\n",
    "\n",
    "    if typeof(positive_sample) != type(None)\n",
    "        if length(all_alpha_embeddings) > 0\n",
    "            positive_sample_regular = positive_sample[all_idxs] # positive samples for non-union queries in this batch\n",
    "            entity_embedding_select = selectdim(m.entity_embedding,\n",
    "                                                ndims(m.entity_embedding),\n",
    "                                                positive_sample_regular);\n",
    "            positive_embedding = m.entity_regularizer(unsqueeze(entity_embedding_select,\n",
    "                                                                ndims(entity_embedding_select)))\n",
    "            positive_logit = cal_logit_beta(m, positive_embedding, all_dists)\n",
    "        else\n",
    "            positive_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_alpha_embeddings) > 0\n",
    "            positive_sample_union = positive_sample[all_union_idxs] # positive samples for union queries in this batch\n",
    "\n",
    "            entity_embedding_select = selectdim(m.entity_embedding,\n",
    "                                                ndims(m.entity_embedding),\n",
    "                                                positive_sample_union);\n",
    "            entity_embedding_select_unsqueeze = unsqueeze(entity_embedding_select,\n",
    "                                                        dims=ndims(entity_embedding_select) - 1);\n",
    "            positive_embedding = m.entity_regularizer(entity_embedding_select_unsqueeze)\n",
    "            positive_union_logit = cal_logit_beta(m, positive_embedding, all_union_dists)\n",
    "            positive_union_logit = max(positive_union_logit, dim=1)[0]\n",
    "        else\n",
    "            positive_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "        positive_logit = cat(positive_logit, positive_union_logit, dims=ndims(positive_logit))\n",
    "    else\n",
    "        positive_logit = nothing\n",
    "    end\n",
    "\n",
    "    if typeof(negative_sample) != typeof(nothing)\n",
    "        if length(all_alpha_embeddings) > 0\n",
    "            negative_sample_regular = negative_sample[all_idxs]\n",
    "            batch_size, negative_size = negative_sample_regular.shape\n",
    "            #negative_embedding = self.entity_regularizer(torch.index_select(self.entity_embedding, dim=0, index=negative_sample_regular.view(-1)).view(batch_size, negative_size, -1))\n",
    "            negative_embedding = m.entity_regularizer(reshape(reshape(selectdim(m.entity_embedding, ndims(m.entity_embedding), negative_sample_regular), :), :, negative_size, batch_size))\n",
    "            negative_logit = cal_logit_beta(m, negative_embedding, all_dists)\n",
    "        else\n",
    "            ########################## TODO ##################################\n",
    "            #negative_logit = torch.Tensor([]).to(self.entity_embedding.device)\n",
    "            negative_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_alpha_embeddings) > 0\n",
    "            negative_sample_union = negative_sample[all_union_idxs]\n",
    "            batch_size, negative_size = size(negative_sample_union)\n",
    "            negative_embedding = m.entity_regularizer(reshape(reshape(selectdim(m.entity_embedding, 0, negative_sample_union), :), (:, negative_size, 1, batch_size)))\n",
    "            negative_union_logit = cal_logit_beta(m, negative_embedding, all_union_dists)\n",
    "            negative_union_logit = max(negative_union_logit, dim=2)[0]\n",
    "        else\n",
    "            ######################### TODO  ###################################\n",
    "            negative_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        negative_logit = cat(negative_logit, negative_union_logit, dim=ndims(negative_logit))\n",
    "    else\n",
    "        negative_logit = nothing\n",
    "    end\n",
    "\n",
    "    return positive_logit, negative_logit, subsampling_weight, all_idxs+all_union_idxs\n",
    "end\n",
    "\n",
    "function cal_logit_box(m::KGReasoning, entity_embedding, query_center_embedding, query_offset_embedding)\n",
    "    delta = abs(entity_embedding - query_center_embedding)\n",
    "    distance_out = Flux.relu(delta - query_offset_embedding)\n",
    "    distance_in = min(delta, query_offset_embedding)\n",
    "    logit = m.gamma - normDims(distance_out, 1; dims=0) - m.cen * normDims(distance_in, 1, dims=0)\n",
    "    return logit\n",
    "end\n",
    "\n",
    "function forward_box(m::KGReasoning, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    all_center_embeddings, all_offset_embeddings, all_idxs = [], [], []\n",
    "    all_union_center_embeddings, all_union_offset_embeddings, all_union_idxs = [], [], []\n",
    "    for query_structure in batch_queries_dict\n",
    "        if \"u\" in m.query_name_dict[query_structure]\n",
    "            center_embedding, offset_embedding, _ = \\\n",
    "                embed_query_box(m, m.transform_union_query(batch_queries_dict[query_structure],\n",
    "                                                                query_structure),\n",
    "                                transform_union_structure(m, query_structure),\n",
    "                                0)\n",
    "            push!(all_union_center_embeddings, center_embedding)\n",
    "            push!(all_union_offset_embeddings, offset_embedding)\n",
    "            push!(all_union_idxs, batch_idxs_dict[query_structure])\n",
    "        else\n",
    "            center_embedding, offset_embedding, _ = embed_query_box(m, batch_queries_dict[query_structure],\n",
    "                                                                    query_structure,\n",
    "                                                                    0)\n",
    "            push!(all_center_embeddings, center_embedding)\n",
    "            push!(all_offset_embeddings, offset_embedding)\n",
    "            push!(all_idxs, batch_idxs_dict[query_structure])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if length(all_center_embeddings) > 0 && length(all_offset_embeddings) > 0\n",
    "        all_center_embeddings_cat = reduce(all_center_embeddings) do x, y\n",
    "                                          cat(x, y, dims=ndims(x))\n",
    "                                    end\n",
    "        all_center_embeddings_cat_unsqueeze = unsqueeze(all_center_embeddings_cat,\n",
    "                                          dims = ndims(all_center_embeddings_cat) - 1)\n",
    "\n",
    "        all_offset_embeddings_cat = reduce(all_offset_embeddings) do x, y\n",
    "                                          cat(x, y, dims=ndims(x))\n",
    "                                    end\n",
    "        all_offset_embeddings_cat_unsqueeze = unsqueeze(all_offset_embeddings_cat,\n",
    "                                                        dims = ndims(all_offset_embeddings_cat) - 1)\n",
    "        #all_offset_embeddings = torch.cat(all_offset_embeddings, dim=0).unsqueeze(1)\n",
    "    end\n",
    "\n",
    "    if length(all_union_center_embeddings) > 0 && length(all_union_offset_embeddings) > 0\n",
    "        #all_union_center_embeddings = torch.cat(all_union_center_embeddings, dim=0).unsqueeze(1)\n",
    "        #all_union_offset_embeddings = torch.cat(all_union_offset_embeddings, dim=0).unsqueeze(1)\n",
    "        all_union_center_embeddings_cat = reduce(all_union_center_embeddings) do x, y\n",
    "                                              cat(x, y, dims=ndims(x))\n",
    "                                          end\n",
    "        all_union_center_embeddings_cat_unsqueeze = unsqueeze(all_union_center_embeddings_cat,\n",
    "                                                              dims = ndims(all_union_center_embeddings_cat) - 1)\n",
    "        all_union_offset_embeddings_cat = reduce(all_union_offset_embeddings) do x, y\n",
    "                                              cat(x, y, dims=ndims(x))\n",
    "                                          end\n",
    "        all_union_offset_embeddings_cat_unsqueeze = unsqueeze(all_union_offset_embeddings_cat,\n",
    "                                                              dims = ndims(all_offset_embeddings_cat) - 1)\n",
    "        #all_union_center_embeddings = all_union_center_embeddings.view(all_union_center_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        #all_union_offset_embeddings = all_union_offset_embeddings.view(all_union_offset_embeddings.shape[0]//2, 2, 1, -1)\n",
    "        all_union_center_embeddings = reshape(all_union_center_embeddings_cat_unsqueeze,\n",
    "                                              :, 1, 2, div(ndims(all_union_center_embeddings_cat_unsqueeze), 2))\n",
    "        all_union_offset_embeddings = reshape(all_union_offset_embeddings_cat_unsqueeze,\n",
    "                                              :, 1, 2, div(ndims(all_union_offset_embeddings_cat_unsqueeze), 2))\n",
    "    end\n",
    "\n",
    "    if typeof(subsampling_weight) != typeof(nothing)\n",
    "        subsampling_weight = subsampling_weight[all_idxs+all_union_idxs]\n",
    "    end\n",
    "\n",
    "    if typeof(positive_sample) != typeof(nothing)\n",
    "        if length(all_center_embeddings) > 0\n",
    "            positive_sample_regular = positive_sample[all_idxs]\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), positive_sample_regular)\n",
    "            positive_embedding = unsqueeze(entity_embedding_select, ndims(entity_embedding_select) - 1)\n",
    "            positive_logit = cal_logit_box(m, positive_embedding, all_center_embeddings, all_offset_embeddings)\n",
    "        else\n",
    "            #positive_logit = torch.Tensor([]).to(self.entity_embedding.device)\n",
    "            positive_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_center_embeddings) > 0\n",
    "            positive_sample_union = positive_sample[all_union_idxs]\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), positive_sample_union)\n",
    "            entity_embedding_select_unquezze = unsqueeze(entity_embedding_select, ndims(entity_embedding_select) - 1)\n",
    "            positive_embedding = unsqueeze(entity_embedding_select_unquezze, ndims(entity_embedding_select_unquezze) - 1)\n",
    "            positive_union_logit = cal_logit_box(m, positive_embedding, all_union_center_embeddings, all_union_offset_embeddings)\n",
    "            positive_union_logit = max(positive_union_logit, dims=ndims(positive_union_logit) - 1)[1]\n",
    "        else\n",
    "            #positive_union_logit = torch.Tensor([]).to(self.entity_embedding.device)\n",
    "            positive_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "        positive_logit = reduce([positive_logit, positive_union_logit]) do x, y\n",
    "                              cat(x, y, dim=ndims(x))\n",
    "                         end\n",
    "    else\n",
    "        positive_logit = nothing\n",
    "    end\n",
    "\n",
    "    if typeof(negative_sample) != typeof(nothing)\n",
    "        if len(all_center_embeddings) > 0\n",
    "            negative_sample_regular = negative_sample[all_idxs]\n",
    "            batch_size, negative_size = size(negative_sample_regular)\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), reshape(negative_sample_regular, :))\n",
    "            negative_embedding = reshape(entity_embedding_select, :, negative_size, batch_size)\n",
    "            negative_logit = cal_logit_box(m, negative_embedding, all_center_embeddings, all_offset_embeddings)\n",
    "        else\n",
    "            #negative_logit = torch.Tensor([]).to(self.entity_embedding.device)\n",
    "            negative_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_center_embeddings) > 0\n",
    "            negative_sample_union = negative_sample[all_union_idxs]\n",
    "            batch_size, negative_size = size(negative_sample_union)\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), reshape(negative_sample_union, :))\n",
    "            negative_embedding = reshape(entity_embedding_select, :, negative_size, 1, batch_size)\n",
    "            negative_union_logit = cal_logit_box(m, negative_embedding, all_union_center_embeddings, all_union_offset_embeddings)\n",
    "            negative_union_logit = max(negative_union_logit, dims=ndims(negative_union_logit) - 1)[1]\n",
    "        else\n",
    "            #negative_union_logit = torch.Tensor([]).to(self.entity_embedding.device)\n",
    "            negative_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "        negative_logit = reduce([negative_logit, negative_union_logit]) do x, y\n",
    "                              cat(x, y, dim=ndims(x))\n",
    "                         end\n",
    "    else\n",
    "        negative_logit = nothing\n",
    "    end\n",
    "\n",
    "    return positive_logit, negative_logit, subsampling_weight, all_idxs+all_union_idxs\n",
    "end\n",
    "\n",
    "function cal_logit_vec(m::KGReasoning, entity_embedding, query_embedding)\n",
    "    distance = entity_embedding - query_embedding\n",
    "    logit = m.gamma - normDims(distance, 1, dim=2)\n",
    "    return logit\n",
    "end\n",
    "\n",
    "function forward_vec(m::KGReasoning, positive_sample, negative_sample, subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "    all_center_embeddings, all_idxs = [], []\n",
    "    all_union_center_embeddings, all_union_idxs = [], []\n",
    "    for query_structure in batch_queries_dict\n",
    "        if \"u\" in m.query_name_dict[query_structure]\n",
    "            center_embedding, _ = embed_query_vec(m, transform_union_query(m, batch_queries_dict[query_structure],\n",
    "                                                                           query_structure),\n",
    "                                                  transform_union_structure(query_structure), 0)\n",
    "            push!(all_union_center_embeddings, center_embedding)\n",
    "            append!(all_union_idxs, batch_idxs_dict[query_structure])\n",
    "        else\n",
    "            center_embedding, _ = embed_query_vec(m, batch_queries_dict[query_structure], query_structure, 0)\n",
    "            push!(all_center_embeddings, center_embedding)\n",
    "            append!(all_idxs, batch_idxs_dict[query_structure])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if length(all_center_embeddings) > 0\n",
    "        all_center_embeddings_cat = reduce(all_center_embeddings) do x, y\n",
    "                                        cat(x, y, dims = ndims(x))\n",
    "                                    end\n",
    "        all_center_embeddings = unsqueeze(all_center_embeddings_cat, ndims(all_center_embeddings_cat) - 1)\n",
    "    end\n",
    "\n",
    "    if length(all_union_center_embeddings) > 0\n",
    "        all_union_center_embeddings_cat = reduce(all_union_center_embeddings) do x, y\n",
    "                                              cat(x, y, dims = ndims(x))\n",
    "                                          end\n",
    "        all_union_center_embeddings_unsqueeze = unsqueeze(all_union_center_embeddings_cat, ndims(all_union_center_embeddings_cat) - 1)\n",
    "        #all_union_center_embeddings = torch.cat(all_union_center_embeddings, dim=0).unsqueeze(1)\n",
    "        all_union_center_embeddings = reshape(all_union_center_embeddings_unsqueeze,\n",
    "                                              :, 1, 2, div(size(all_union_center_embeddings,\n",
    "                                                                ndims(all_union_center_embeddings)),\n",
    "                                                           2))\n",
    "    end\n",
    "\n",
    "    if typeof(subsampling_weight) != typeof(nothing)\n",
    "        subsampling_weight = subsampling_weight[all_idxs+all_union_idxs]\n",
    "    end\n",
    "\n",
    "    if typeof(positive_sample) != typeof(nothing)\n",
    "        if length(all_center_embeddings) > 0\n",
    "            positive_sample_regular = positive_sample[all_idxs]\n",
    "            positive_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), positive_sample_regular)\n",
    "            positive_embedding = unsqueeze(positive_embedding_select, ndims(positive_embedding_select) - 1)\n",
    "            positive_logit = cal_logit_vec(m, positive_embedding, all_center_embeddings)\n",
    "        else\n",
    "            positive_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_center_embeddings) > 0\n",
    "            positive_sample_union = positive_sample[all_union_idxs]\n",
    "            positive_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding), positive_sample_regular)\n",
    "            positive_embedding_unsqueeze = unsqueeze(positive_embedding_select, ndims(positive_embedding_select) - 1)\n",
    "            positive_embedding = unsqueeze(positive_embedding_unsqueeze, ndims(positive_embedding_unsqueeze) - 1)\n",
    "            positive_union_logit = cal_logit_vec(m, positive_embedding, all_union_center_embeddings)\n",
    "            positive_union_logit = max(positive_union_logit, dims=ndims(positive_union_logit) - 1)[1]\n",
    "        else\n",
    "            positive_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "        positive_logit = reduce([positive_logit, positive_union_logit]) do x, y\n",
    "                             cat(x, y, dims=ndims(x))\n",
    "                         end\n",
    "    else\n",
    "        positive_logit = nothing\n",
    "    end\n",
    "\n",
    "    if typeof(negative_sample) != typeof(nothing)\n",
    "        if length(all_center_embeddings) > 0\n",
    "            negative_sample_regular = negative_sample[all_idxs]\n",
    "            batch_size, negative_size = size(negative_sample_regular)\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, 0, reshape(negative_sample_regular, :))\n",
    "            negative_embedding = reshape(entity_embedding_select, :, negative_size, batch_size)\n",
    "            negative_logit = cal_logit_vec(m, negative_embedding, all_center_embeddings)\n",
    "        else\n",
    "            negative_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        if length(all_union_center_embeddings) > 0\n",
    "            negative_sample_union = negative_sample[all_union_idxs]\n",
    "            batch_size, negative_size = size(negative_sample_union)\n",
    "            entity_embedding_select = selectdim(m.entity_embedding, ndims(m.entity_embedding, reshape(negative_sample_union, :)))\n",
    "            negative_embedding = reshape(entity_embedding_select, :, negtive_size, 1, batch_size)\n",
    "            negative_union_logit = cal_logit_vec(m, negative_embedding, all_union_center_embeddings)\n",
    "            negative_union_logit = max(negative_union_logit, dim=ndims(negative_union_logit) -1)[0]\n",
    "        else\n",
    "            negative_union_logit = [] .|> Flux.get_device()\n",
    "        end\n",
    "\n",
    "        negative_logit = reduce([negative_logit, negative_union_logit]) do x, y\n",
    "                             cat(x, y, dim=ndims(x))\n",
    "                         end\n",
    "    else\n",
    "        negative_logit = nothing\n",
    "    end\n",
    "\n",
    "    return positive_logit, negative_logit, subsampling_weight, all_idxs+all_union_idxs\n",
    "end\n",
    "#=================================================================================\n",
    "function mean_loss(y_bar)\n",
    "    negative_logsigmoid = Flux.logsigmoid(-y_bar[:negative_logit])\n",
    "    negative_score = mean.(negative_logsigmoid, dims=ndims(negative_logsigmoid))\n",
    "    positive_logsigmoid =Flux.logsigmoid(-y_bar[:positive_logit])\n",
    "    positive_score = squeeze(positive_logsigmoid, dim=ndims(positive_logsigmoid))\n",
    "    positive_sample_loss = - sum(y_bar[:subsampling_weight] * positive_score)\n",
    "    negative_sample_loss = - sum(y_bar[:subsampling_weight] * negative_score)\n",
    "    positive_sample_loss /= sum(y_bar[:subsampling_weight])\n",
    "    negative_sample_loss /= sum(y_bar[:subsampling_weight])\n",
    "\n",
    "    loss = (positive_sample_loss + negative_sample_loss)/2\n",
    "end\n",
    "===============================================================================#\n",
    "\n",
    "function loss()\n",
    "    return 0\n",
    "end\n",
    "\n",
    "# @staticmethod\n",
    "function train_step(model::KGReasoning, opt_state, data, args, step)\n",
    "    #opti_stat = Flux.setup(model, optimizer)\n",
    "\n",
    "    opti_stat = Flux.train!(model, data, opt_state) do\n",
    "\n",
    "        ########################################################################################################\n",
    "        #model.train() # set model as train mode\n",
    "        #optimizer.zero_grad() # clear grad, set to zero\n",
    "\n",
    "        positive_sample, negative_sample, subsampling_weight, batch_queries, query_structures = next(train_iterator)\n",
    "        print(\"train_step chunk :$(batch_queries)\\n state: $(query_structures)\")\n",
    "        #batch_queries_dict = collections.defaultdict(list)\n",
    "        #batch_idxs_dict = collections.defaultdict(list)\n",
    "        batch_queries_dict = Dict{Any, Any}()\n",
    "        batch_idxs_dict = Dict{Any, Any}()\n",
    "        for (i, query) in enumerate(batch_queries) # group queries with same structure\n",
    "            push!(get!(batch_queries_dict, query_structures[i], []), query)\n",
    "            push!(get!(batch_idxs_dict, query_structures[i], []), i)\n",
    "        end\n",
    "\n",
    "        for query_structure in batch_queries_dict\n",
    "            if args[\"cuda\"]\n",
    "                batch_queries_dict[query_structure] = Int64.(batch_queries_dict[query_structure]) .|> gpu\n",
    "            else\n",
    "                batch_queries_dict[query_structure] = Int64.(batch_queries_dict[query_structure])\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if args[\"cuda\"]\n",
    "            positive_sample = positive_sample |> gpu\n",
    "            negative_sample = negative_sample |> gpu\n",
    "            subsampling_weight = subsampling_weight |> gpu\n",
    "        end\n",
    "\n",
    "        opt_grads = Flux.gradient(model) do m\n",
    "            positive_logit, negative_logit,\n",
    "            subsampling_weight, _ = model(positive_sample, negative_sample,\n",
    "                                          subsampling_weight, batch_queries_dict, batch_idxs_dict)\n",
    "            negative_logsigmoid = Flux.logsigmoid(negative_logit)\n",
    "            negative_score = mean.(negative_logsigmoid, dims=ndims(negative_logsigmoid))\n",
    "            positive_logsigmoid =Flux.logsigmoid(positive_logit)\n",
    "            positive_score = squeeze(positive_logsigmoid, dim=ndims(positive_logsigmoid))\n",
    "            positive_sample_loss = - sum(subsampling_weight * positive_score)\n",
    "            negative_sample_loss = - sum(subsampling_weight * negative_score)\n",
    "            positive_sample_loss /= sum(subsampling_weight)\n",
    "            negative_sample_loss /= sum(subsampling_weight)\n",
    "\n",
    "            loss = (positive_sample_loss + negative_sample_loss)/2\n",
    "        end\n",
    "    end\n",
    "    #=========================================================================\n",
    "    negative_score = F.logsigmoid(-negative_logit).mean(dim=1)\n",
    "    positive_score = F.logsigmoid(positive_logit).squeeze(dim=1)\n",
    "    positive_sample_loss = - (subsampling_weight * positive_score).sum()\n",
    "    negative_sample_loss = - (subsampling_weight * negative_score).sum()\n",
    "    positive_sample_loss /= subsampling_weight.sum()\n",
    "    negative_sample_loss /= subsampling_weight.sum()\n",
    "\n",
    "    loss = (positive_sample_loss + negative_sample_loss)/2\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    ==========================================================================#\n",
    "    log = Dict{\n",
    "        \"positive_sample_loss\": positive_sample_loss.item(),\n",
    "        \"negative_sample_loss\": negative_sample_loss.item(),\n",
    "        \"loss\": loss.item(),\n",
    "    }\n",
    "    return log\n",
    "end\n",
    "\n",
    "#@staticmethod\n",
    "function test_step(model, easy_answers, hard_answers, args, test_dataloader, query_name_dict, save_result=False, save_str=\"\", save_empty=False)\n",
    "#    model.eval()\n",
    "\n",
    "    step = 0\n",
    "    total_steps = length(test_dataloader)\n",
    "    #logs = collections.defaultdict(list)\n",
    "    logs = Dict()\n",
    "\n",
    "    #with torch.no_grad():\n",
    "    for (negative_sample, queries, queries_unflatten, query_structures) in tqdm(test_dataloader)\n",
    "        batch_queries_dict = Dict() #collections.defaultdict(list)\n",
    "        batch_idxs_dict = Dict() #collections.defaultdict(list)\n",
    "        for (i, query) in enumerate(queries)\n",
    "            push!(batch_queries_dict[query_structures[i]], query)\n",
    "            push!(batch_idxs_dict[query_structures[i]], i)\n",
    "        end\n",
    "\n",
    "        for query_structure in batch_queries_dict\n",
    "            if args[\"cuda\"]\n",
    "                batch_queries_dict[query_structure] = Int64.(batch_queries_dict[query_structure]) .|> gpu\n",
    "            else\n",
    "                batch_queries_dict[query_structure] = Int64.(batch_queries_dict[query_structure])\n",
    "            end\n",
    "        end\n",
    "\n",
    "        if args[\"cuda\"]\n",
    "            negative_sample = negative_sample .|> gpu\n",
    "        end\n",
    "\n",
    "        _, negative_logit, _, idxs = model(None, negative_sample, None, batch_queries_dict, batch_idxs_dict)\n",
    "        queries_unflatten = [queries_unflatten[i] for i in idxs]\n",
    "        query_structures = [query_structures[i] for i in idxs]\n",
    "        argsort = sortperm(negative_logit, dim=ndims(negative_logit)-1, rev=true)\n",
    "        ranking = Float32.(copy(argsort))\n",
    "        if length(argsort) == args[\"test_batch_size\"] # if it is the same shape with test_batch_size, we can reuse batch_entity_range without creating a new one\n",
    "            #ranking = ranking.scatter_(1, argsort, model.batch_entity_range) # achieve the ranking of all entities\n",
    "            ranking = getindex(model.batch_entity_range, argsort)\n",
    "        else # otherwise, create a new torch Tensor for batch_entity_range\n",
    "            if args[\"cuda\"]\n",
    "                #ranking = ranking.scatter_(1,\n",
    "                #                           argsort,\n",
    "                #                           torch.arange(model.nentity).to(torch.float).repeat(argsort.shape[0],\n",
    "                #                                                                              1).cuda()\n",
    "                #                           ) # achieve the ranking of all entities\n",
    "                target = repeat(Float32.(collect(1:model.nentity)), 1, size(argsort, ndims(argsort)))\n",
    "                ranking = getindex(argsort, target) |> gpu\n",
    "            else\n",
    "                #ranking = ranking.scatter_(1,\n",
    "                #                           argsort,\n",
    "                #                           torch.arange(model.nentity).to(torch.float).repeat(argsort.shape[0],\n",
    "                #                                                                              1)\n",
    "                #                           ) # achieve the ranking of all entities\n",
    "                target = repeat(Float32.(collect(1:model.nentity)), 1, size(argsort, ndims(argsort)))\n",
    "                ranking = getindex(argsort, target)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        for (idx, (i, query, query_structure)) in enumerate(zip(argsort[:, ndims(argsort)], queries_unflatten, query_structures))\n",
    "            hard_answer = hard_answers[query]\n",
    "            easy_answer = easy_answers[query]\n",
    "            num_hard = length(hard_answer)\n",
    "            num_easy = length(easy_answer)\n",
    "            @assert length(hard_answer.intersection(easy_answer)) == 0\n",
    "            cur_ranking = ranking[idx, list(easy_answer) + list(hard_answer)]\n",
    "            cur_ranking, indices = sortperm(cur_ranking)\n",
    "            masks = indices >= num_easy\n",
    "            if args[\"cuda\"]\n",
    "                answer_list = Float32.(collect(1:(num_hard + num_easy))) .|> gpu\n",
    "            else\n",
    "                answer_list = Float32.(collect(1:(num_hard + num_easy)))\n",
    "            end\n",
    "            cur_ranking = cur_ranking .- answer_list + 1 # filtered setting\n",
    "            cur_ranking = cur_ranking[masks] # only take indices that belong to the hard answers\n",
    "\n",
    "            mrr = collect(mean(1 ./ cur_ranking))\n",
    "            h1 = collect(Float32.(mean((cur_ranking <= 1))))\n",
    "            h3 = collect(Float32.(mean((cur_ranking <= 3))))\n",
    "            h10 = collect(Float32.(mean((cur_ranking <= 10))))\n",
    "\n",
    "            push!(get!(logs, query_structure, Dict()), Dict(\n",
    "                \"MRR\"=> mrr,\n",
    "                \"HITS1\"=> h1,\n",
    "                \"HITS3\"=> h3,\n",
    "                \"HITS10\"=> h10,\n",
    "                \"num_hard_answer\"=> num_hard\n",
    "            ))\n",
    "        end\n",
    "\n",
    "        if step % args.test_log_steps == 0\n",
    "            @info(\"Evaluating the model... ($step/$total_steps)\")\n",
    "        end\n",
    "        step += 1\n",
    "    end\n",
    "\n",
    "    #metrics = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "    metrics = Dict()\n",
    "    for query_structure in logs\n",
    "        for metric in keys(logs[query_structure][0])\n",
    "            if metric in [\"num_hard_answer\"]\n",
    "                continue\n",
    "            end\n",
    "            metrics[:query_structure][:metric] = sum([log[metric] for log in logs[query_structure]])/length(logs[query_structure])\n",
    "        end\n",
    "        metrics[:query_structure][\"num_queries\"] = length(logs[query_structure])\n",
    "    end\n",
    "\n",
    "    return metrics\n",
    "end\n",
    "\n",
    "end #end module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ac1d9-3402-4f31-9c64-373b7fca53e7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Revise\n",
    "\n",
    "using MLUtils\n",
    "using Random\n",
    "using ArgParse\n",
    "using LoggingExtras, TensorBoardLogger\n",
    "using Dates\n",
    "using Flux, JLD2\n",
    "\n",
    "#println(\"working directory: {$(pwd())}\")\n",
    "\n",
    "include(\"src/dataloader.jl\")\n",
    "include(\"src/model.jl\")\n",
    "include(\"src/utils.jl\")\n",
    "\n",
    "using .KGDataset\n",
    "using .KGModel\n",
    "\n",
    "f_dir = \"dataset\";\n",
    "f_model = \"FB15k-betae\";\n",
    "\n",
    "query_name_dict = Dict{Tuple, String}((\"e\",(\"r\",))=> \"1p\",\n",
    "                                      (\"e\", (\"r\", \"r\"))=> \"2p\",\n",
    "                                      (\"e\", (\"r\", \"r\", \"r\"))=> \"3p\",\n",
    "                                      ((\"e\", (\"r\",)), (\"e\", (\"r\",)))=> \"2i\",\n",
    "                                      ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"e\", (\"r\",)))=> \"3i\",\n",
    "                                      (((\"e\", (\"r\",)), (\"e\", (\"r\",))), (\"r\",))=> \"ip\",\n",
    "                                      ((\"e\", (\"r\", \"r\")), (\"e\", (\"r\",)))=> \"pi\",\n",
    "                                      ((\"e\", (\"r\",)), (\"e\", (\"r\", \"n\")))=> \"2in\",\n",
    "                                      ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"e\", (\"r\", \"n\")))=> \"3in\",\n",
    "                                      (((\"e\", (\"r\",)), (\"e\", (\"r\", \"n\"))), (\"r\",))=> \"inp\",\n",
    "                                      ((\"e\", (\"r\", \"r\")), (\"e\", (\"r\", \"n\")))=> \"pin\",\n",
    "                                      ((\"e\", (\"r\", \"r\", \"n\")), (\"e\", (\"r\",)))=> \"pni\",\n",
    "                                      ((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"u\",))=> \"2u-DNF\",\n",
    "                                      (((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"u\",)), (\"r\",))=> \"up-DNF\",\n",
    "                                      (((\"e\", (\"r\", \"n\")), (\"e\", (\"r\", \"n\"))), (\"n\",))=> \"2u-DM\",\n",
    "                                      (((\"e\", (\"r\", \"n\")), (\"e\", (\"r\", \"n\"))), (\"n\", \"r\"))=> \"up-DM\"\n",
    "                                      );\n",
    "name_query_dict = Dict{String, Tuple}((y => x) for (x, y) in query_name_dict);\n",
    "all_tasks = collect(keys(name_query_dict));\n",
    "\n",
    "function parse_cmdargs(args::Vector{String})\n",
    "    s = ArgParseSettings(\n",
    "        description = \"Training and Testing Knowledge Graph Embedding Models\",\n",
    "        usage = \"julia --project=[/path/to/project] src/$(@__FILE__) [<args>] [-h | --help]\"\n",
    "    )\n",
    "\n",
    "    @add_arg_table s begin\n",
    "        \"--cuda\"\n",
    "        action= :store_true\n",
    "        help=\"use GPU\"\n",
    "        \"--train\"\n",
    "        action= :store_true\n",
    "        help=\"do train\"\n",
    "        \"--valid\"\n",
    "        action= :store_true\n",
    "        help=\"do valid\"\n",
    "        \"--test\"\n",
    "        action= :store_true\n",
    "        help=\"do test\"\n",
    "        \"--data_path\"\n",
    "        arg_type=String\n",
    "        default= nothing\n",
    "        help=\"KG data path\"\n",
    "        \"-n\", \"--negative_sample_size\"\n",
    "        default=128\n",
    "        arg_type=Int\n",
    "        help=\"negative entities sampled per query\"\n",
    "        \"-d\", \"--hidden_dim\"\n",
    "        default=500\n",
    "        arg_type=Int\n",
    "        help=\"embedding dimension\"\n",
    "        \"-g\", \"--gamma\"\n",
    "        default=12.0\n",
    "        arg_type=Float64\n",
    "        help=\"margin in the loss\"\n",
    "        \"-b\", \"--batch_size\"\n",
    "        default=1024\n",
    "        arg_type=Int\n",
    "        help=\"batch size of queries\"\n",
    "        \"--test_batch_size\"\n",
    "        default=1\n",
    "        arg_type=Int\n",
    "        help=\"valid/test batch size\"\n",
    "        \"--learning_rate\"\n",
    "        default=0.0001\n",
    "        arg_type=Float64\n",
    "        \"--cpu\"\n",
    "        default=10\n",
    "        arg_type=Int\n",
    "        help=\"used to speed up torch.dataloader\"\n",
    "        \"--save_path\"\n",
    "        default=\".\"\n",
    "        arg_type=String\n",
    "        help=\"no need to set manually, will configure automatically\"\n",
    "        \"--max_steps\"\n",
    "        default=100000\n",
    "        arg_type=Int\n",
    "        help=\"maximum iterations to train\"\n",
    "        \"--warm_up_steps\"\n",
    "        default=nothing\n",
    "        arg_type=Int\n",
    "        help=\"no need to set manually, will configure automatically\"\n",
    "        \"--save_checkpoint_steps\"\n",
    "        default=50000\n",
    "        arg_type=Int\n",
    "        help=\"save checkpoints every xx steps\"\n",
    "        \"--valid_steps\"\n",
    "        default=10000\n",
    "        arg_type=Int\n",
    "        help=\"evaluate validation queries every xx steps\"\n",
    "        \"--log_steps\"\n",
    "        default=100\n",
    "        arg_type=Int\n",
    "        help=\"train log every xx steps\"\n",
    "        \"--test_log_steps\"\n",
    "        default=1000\n",
    "        arg_type=Int\n",
    "        help=\"valid/test log every xx steps\"\n",
    "        \"--nentity\"\n",
    "        arg_type=Int\n",
    "        default=0\n",
    "        help=\"DO NOT MANUALLY SET\"\n",
    "        \"--nrelation\"\n",
    "        arg_type=Int\n",
    "        default=0\n",
    "        help=\"DO NOT MANUALLY SET\"\n",
    "        \"--geo\"\n",
    "        default=\"vec\"\n",
    "        arg_type=String\n",
    "        help=\"the reasoning model, vec for GQE, box for Query2box, beta for BetaE\"\n",
    "        \"--print_on_screen\"\n",
    "        action= :store_false\n",
    "        \"--tasks\"\n",
    "        default=\"1p.2p.3p.2i.3i.ip.pi.2in.3in.inp.pin.pni.2u.up\"\n",
    "        arg_type=String\n",
    "        help=\"tasks connected by dot, refer to the BetaE paper for detailed meaning and structure of each task\"\n",
    "        \"--seed\"\n",
    "        default=0\n",
    "        arg_type=Int\n",
    "        help=\"random seed\"\n",
    "        \"--beta_mode\"\n",
    "        default=\"(1600,2)\"\n",
    "        arg_type=String\n",
    "        help=\"(hidden_dim,num_layer) for BetaE relational projection\"\n",
    "        \"--box_mode\"\n",
    "        default=\"(nothing,0.02)\"\n",
    "        arg_type=String\n",
    "        help=\"(offset activation,center_reg) for Query2box, center_reg balances the in_box dist and out_box dist\"\n",
    "        \"--prefix\"\n",
    "        default=nothing\n",
    "        arg_type=String\n",
    "        help=\"prefix of the log path\"\n",
    "        \"--checkpoint_path\"\n",
    "        default=nothing\n",
    "        arg_type=String\n",
    "        help=\"path for loading the checkpoints\"\n",
    "        \"--evaluate_union\"\n",
    "        default=\"DNF\"\n",
    "        arg_type=String\n",
    "        help=\"the way to evaluate union queries, transform it to disjunctive normal form (DNF) or use the De Morgan\\\"s laws (DM)\"\n",
    "    end\n",
    "\n",
    "    return parse_args(args, s)\n",
    "end\n",
    "\n",
    "#=\"\"\"\n",
    "Write logs to console and log file\n",
    "\"\"\"=#\n",
    "function set_logger(args)\n",
    "\n",
    "    if args[\"train\"] == true\n",
    "        log_file = joinpath(args[\"save_path\"], \"train.log\")\n",
    "    else\n",
    "        log_file = joinpath(args[\"save_path\"], \"test.log\")\n",
    "    end\n",
    "\n",
    "    log_io = open(log_file, \"w\");\n",
    "    datefmt=DateFormat(\"YY-mm-dd HH:MM:SS\");\n",
    "\n",
    "    timestamp_logger(logger) = TransformerLogger(logger) do log\n",
    "        merge(log, (; message = \"$(Dates.format(now(), datefmt)) $(log.message)\"))\n",
    "    end\n",
    "\n",
    "    file_logger = timestamp_logger(FileLogger(log_file));\n",
    "    global_logger(file_logger)\n",
    "\n",
    "    if args[\"print_on_screen\"]\n",
    "        time_loger = timestamp_logger(ConsoleLogger(stdout, Logging.Info));\n",
    "\n",
    "        tl = TeeLogger(file_logger, time_loger);\n",
    "        global_logger(tl)\n",
    "    end\n",
    "end\n",
    "\n",
    "#=\"\"\"\n",
    "Print the evaluation logs\n",
    "\"\"\"=#\n",
    "function log_metrics(mode, step, metrics)\n",
    "    for metric in metrics\n",
    "        @info \"$mode $metric at step $(step): $(metrics[metric.first])\"\n",
    "    end\n",
    "end\n",
    "\n",
    "#=\"\"\"\n",
    "Evaluate queries in dataloader\n",
    "\"\"\"=#\n",
    "function evaluate(model, tp_answers, fn_answers, args, dataloader, query_name_dict, mode, step, writer)\n",
    "\n",
    "    average_metrics = Dict{Float}()\n",
    "    all_metrics = Dict{Float}()\n",
    "\n",
    "    metrics = model.test_step(model, tp_answers, fn_answers, args, dataloader, query_name_dict)\n",
    "    num_query_structures = 0\n",
    "    num_queries = 0\n",
    "    for query_structure in metrics\n",
    "        log_metrics(mode * \" \" * query_name_dict[query_structure], step, metrics[query_structure])\n",
    "\n",
    "        for metric in metrics[query_structure]\n",
    "            writer.add_scalar(\"_\".join([mode, query_name_dict[query_structure], metric]), metrics[query_structure][metric], step)\n",
    "            all_metrics[\"_\".join([query_name_dict[query_structure], metric])] = metrics[query_structure][metric]\n",
    "            if metric != \"num_queries\"\n",
    "                average_metrics[metric] += metrics[query_structure][metric]\n",
    "            end\n",
    "        end\n",
    "        num_queries += metrics[query_structure][\"num_queries\"]\n",
    "        num_query_structures += 1\n",
    "    end\n",
    "\n",
    "    for metric in average_metrics\n",
    "        average_metrics[metric] /= num_query_structures\n",
    "        writer.add_scalar(\"_\".join([mode, \"average\", metric]), average_metrics[metric], step)\n",
    "        all_metrics[\"_\".join([\"average\", metric])] = average_metrics[metric]\n",
    "    end\n",
    "\n",
    "    log_metrics(\"$mode average\", step, average_metrics)\n",
    "    return all_metrics\n",
    "end\n",
    "\n",
    "function main(args)\n",
    "    global train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers, test_queries, test_hard_answers, test_easy_answers\n",
    "\n",
    "    Random.seed!(args[\"seed\"])\n",
    "    tasks = split(args[\"tasks\"], \".\")\n",
    "    for task in tasks\n",
    "        if 'n' in task && args[\"geo\"] in [\"box\", \"vec\"]\n",
    "            @assert false \"Q2B and GQE cannot handle queries with negation\"\n",
    "        end\n",
    "    end\n",
    "    if args[\"evaluate_union\"] == \"DM\"\n",
    "        @assert args[\"geo\"] == \"beta\" \"only BetaE supports modeling union using De Morgan's Laws\"\n",
    "    end\n",
    "\n",
    "    cur_time = format_time()\n",
    "    if args[\"prefix\"] == nothing\n",
    "        prefix = \"logs\"\n",
    "    else\n",
    "        prefix = args[\"prefix\"]\n",
    "    end\n",
    "\n",
    "    @info (\"overwritting saving path: $(args[\"save_path\"])\")\n",
    "    args[\"save_path\"] = joinpath(prefix, last(split(args[\"data_path\"], \"/\")), args[\"tasks\"], args[\"geo\"])\n",
    "    geo = args[\"geo\"]\n",
    "    if geo in [\"box\"]\n",
    "        save_str = \"g-$(args[\"gamma\"])-mode-$(args[\"box_mode\"])\"\n",
    "    elseif geo in [\"vec\"]\n",
    "        save_str = \"g-$(args[\"gamma\"])\"\n",
    "    elseif geo == \"beta\"\n",
    "        save_str = \"g-$(args[\"gamma\"])-mode-$(args[\"beta_mode\"])\"\n",
    "    end\n",
    "\n",
    "    if args[\"checkpoint_path\"] != nothing\n",
    "        args[\"save_path\"] = args[\"checkpoint_path\"]\n",
    "    else\n",
    "        args[\"save_path\"] = joinpath(args[\"save_path\"], save_str, cur_time)\n",
    "    end\n",
    "\n",
    "    if ! ispath(args[\"save_path\"])\n",
    "        mkpath(args[\"save_path\"])\n",
    "    end\n",
    "\n",
    "    @info (\"logging to $(args[\"save_path\"])\")\n",
    "    if ! args[\"train\"] # if not training, then create tensorboard files in some tmp location\n",
    "        writer = TBLogger(\"./logs-debug/unused-tb\")\n",
    "    else\n",
    "        writer = TBLogger(args[\"save_path\"])\n",
    "    end\n",
    "    set_logger(args)\n",
    "\n",
    "    nentity, nrelation = open(joinpath(args[\"data_path\"], \"stats.txt\")) do f\n",
    "        entrel = readlines(f)\n",
    "        nentity = parse(Int, last(split(entrel[1], \" \")))\n",
    "        nrelation = parse(Int, last(split(entrel[2], \" \")))\n",
    "\n",
    "        (nentity, nrelation)\n",
    "    end\n",
    "\n",
    "    args[\"nentity\"] = nentity\n",
    "    args[\"nrelation\"] = nrelation\n",
    "\n",
    "    @info(repeat(\"-------------------------------\", 2))\n",
    "    @info(\"Geo: $(args[\"geo\"])\")\n",
    "    @info(\"Data Path: $(args[\"data_path\"])\")\n",
    "    @info(\"#entity: $(nentity)\")\n",
    "    @info(\"#relation: $(nrelation)\")\n",
    "    @info(\"#max steps: $(args[\"max_steps\"])\")\n",
    "    @info(\"Evaluate unoins using: $(args[\"evaluate_union\"])\")\n",
    "\n",
    "    #train_queries, train_answers, valid_queries, valid_hard_answers, valid_easy_answers,\n",
    "    #test_queries, test_hard_answers, test_easy_answers = KGDataset.load_data(args, name_query_dict)\n",
    "\n",
    "    local train_path_iterator, train_other_iterator\n",
    "    if args[\"train\"]\n",
    "        @info(\"Train asked...\")\n",
    "        train_path_queries = Dict{Any, Set}()\n",
    "        train_other_queries = Dict{Any, Set}()\n",
    "        query_path_list = [\"1p\", \"2p\", \"3p\"]\n",
    "        for query_structure in keys(train_queries)\n",
    "            print(query_structure)\n",
    "            if query_name_dict[query_structure] in query_path_list\n",
    "                train_path_queries[query_structure] = train_queries[query_structure]\n",
    "            else\n",
    "                train_other_queries[query_structure] = train_queries[query_structure]\n",
    "            end\n",
    "        end\n",
    "\n",
    "        train_path_queries = flatten_query(train_path_queries)\n",
    "        @info \"Flatten query length: $(length(train_path_queries)) typeof(query) $(typeof(train_path_queries))\"\n",
    "\n",
    "        train_dataset = KGDataset.TrainDataset(train_path_queries, train_answers, nentity, nrelation, args[\"negative_sample_size\"])\n",
    "        data_loader = MLUtils.DataLoader(train_dataset, batchsize = args[\"batch_size\"], collate = true, shuffle = false);\n",
    "        #for x in data_loader\n",
    "        #    @info \"data_loader loop....\" * \"$(size(x))\"\n",
    "        #end\n",
    "        train_path_iterator = KGDataset.SingleDirectionalOneShotIterator(data_loader);\n",
    "        #            num_workers=args.cpu_num,\n",
    "        #            collate_fn=TrainDataset.collate_fn));\n",
    "\n",
    "        if length(train_other_queries) > 0\n",
    "            train_other_queries = flatten_query(train_other_queries)\n",
    "            train_other_iterator = KGDataset.SingleDirectionalOneShotIterator(\n",
    "                MLUtils.DataLoader(KGDataset.TrainDataset(train_other_queries,\n",
    "                                                          train_answers,\n",
    "                                                          nentity,\n",
    "                                                          nrelation,\n",
    "                                                          args[\"negative_sample_size\"]),\n",
    "                                   batchsize=args[\"batch_size\"],\n",
    "                                   shuffle=true));\n",
    "            #                                       num_workers=args.cpu_num,\n",
    "            #                                       collate_fn=TrainDataset.collate_fn))\n",
    "        else\n",
    "            train_other_iterator = nothing\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if args[\"valid\"]\n",
    "        @info(\"Validation asked...\")\n",
    "\n",
    "        #for query_structure in keys(valid_queries)\n",
    "        #    @info query_name_dict[query_structure] * \": \" * \"$(length(valid_queries[query_structure]))\"\n",
    "        # end\n",
    "        valid_queries2 = flatten_query(valid_queries)\n",
    "        valid_dataloader = KGDataset.DataLoader(KGDataset.TestDataset(valid_queries2, nentity, nrelation),\n",
    "                                                batchsize=args[\"test_batch_size\"]);\n",
    "        #            num_workers=args.cpu_num,\n",
    "        #            collate_fn=TestDataset.collate_fn)\n",
    "    end\n",
    "\n",
    "    if args[\"test\"]\n",
    "        @info(\"Test ...\")\n",
    "\n",
    "        # for query_structure in keys(test_queries)\n",
    "        #    @info query_name_dict[query_structure] * \": \" * \"$(length(test_queries[query_structure]))\"\n",
    "        # end\n",
    "        test_queries = flatten_query(test_queries)\n",
    "        test_dataloader = KGDataset.DataLoader(\n",
    "            KGDataset.TestDataset(test_queries, nentity, nrelation),\n",
    "            batchsize=args[\"test_batch_size\"]);\n",
    "        #         num_workers=args.cpu_num,\n",
    "        #         collate_fn=TestDataset.collate_fn)\n",
    "    end\n",
    "\n",
    "    model = KGModel.KGReasoning(nentity,\n",
    "                                 nrelation,\n",
    "                                 args[\"hidden_dim\"],\n",
    "                                 args[\"gamma\"],\n",
    "                                 args[\"geo\"],\n",
    "                                 args[\"test_batch_size\"],\n",
    "                                 eval_tuple(args[\"box_mode\"]),\n",
    "                                 eval_tuple(args[\"beta_mode\"]),\n",
    "                                 query_name_dict,\n",
    "                                 args[\"cuda\"] == \"Yes\")\n",
    "\n",
    "    @info(\"Model Parameter Configuration:\")\n",
    "    for (lindex,layer) in enumerate(Flux.params(model)) #.named_parameters()\n",
    "        #@info(\"Parameter %s: %s, require_grad = %s\" % (name, str(param.size()), str(param.requires_grad)))\n",
    "        #if param.requires_grad\n",
    "        #    num_params += np.prod(param.size())\n",
    "        #end\n",
    "        num_params = 0\n",
    "        for (pindex, pa) in enumerate(Flux.params(layer))\n",
    "            @info(\"Parameter layer$lindex-$pindex: $(size(pa))\")\n",
    "            num_params += sum(length, Flux.params(layer))\n",
    "        end\n",
    "        @info(\"Parameter Number: $num_params\")\n",
    "    end\n",
    "\n",
    "    if args[\"cuda\"]\n",
    "        model = model.cuda()\n",
    "    end\n",
    "\n",
    "    local init_step, checkpoint, step, current_learning_rate, warn_up_steps\n",
    "    if args[\"train\"]\n",
    "        current_learning_rate = args[\"learning_rate\"]\n",
    "        opt_state = Flux.setup(Flux.Optimise.Adam(current_learning_rate), model)\n",
    "        warn_up_steps = floor(args[\"max_steps\"] / 2)\n",
    "    end\n",
    "\n",
    "    if args[\"checkpoint_path\"] != nothing\n",
    "        @info(\"Loading checkpoint $(args[\"checkpoint_path\"])...\")\n",
    "        checkpoint = Flux.loadmodel!(model, JLD2.load(joinPath(args[\"checkpoint_path\"], \"checkpoint\"), \"model_state\"))\n",
    "        init_step = checkpoint[\"step\"]\n",
    "        Flux.loadmodel!(model, checkpoint[\"model_state_dict\"])\n",
    "        #model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "        if args[\"train\"]\n",
    "            current_learning_rate = checkpoint[\"current_learning_rate\"]\n",
    "            warn_up_steps = checkpoint[\"warn_up_steps\"]\n",
    "            #optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        end\n",
    "        @info(\"Ramdomly Initializing $(args[\"geo\"]) Model...\")\n",
    "    else\n",
    "        @info(\"Ramdomly Initializing $(args[\"geo\"]) Model...\")\n",
    "        init_step = 0\n",
    "    end\n",
    "\n",
    "    step = init_step\n",
    "    if args[\"geo\"] == \"box\"\n",
    "        @info(\"box mode = $(args[\"box_mode\"])\")\n",
    "    elseif args[\"geo\"] == \"beta\"\n",
    "        @info(\"beta mode = $(args[\"beta_mode\"])\")\n",
    "    end\n",
    "    @info(\"tasks = $(args[\"tasks\"])\")\n",
    "    @info(\"init_step = $init_step\")\n",
    "    if args[\"train\"]\n",
    "        @info(\"learning_rate = $current_learning_rate\")\n",
    "    end\n",
    "    @info(\"batch_size = $(args[\"batch_size\"])\")\n",
    "    @info(\"hidden_dim = $(args[\"hidden_dim\"])\")\n",
    "    @info(\"gamma = $(args[\"gamma\"])\")\n",
    "\n",
    "\n",
    "    if args[\"train\"]\n",
    "        @info(\"Start Training...\")\n",
    "        training_logs = []\n",
    "        \n",
    "        # #Training Loop\n",
    "        local path_data; path_next=1; \n",
    "        local other_data; other_next=1;\n",
    "        for step in range(init_step, args[\"max_steps\"])\n",
    "            if step == 2 * floor(args[\"max_steps\"] / 3)\n",
    "                args[\"valid_steps\"] *= 4\n",
    "            end\n",
    "\n",
    "            (path_data, path_next) = iterate(train_path_iterator, path_next)\n",
    "            println(\"path_data: $(path_data),\\n path_next: $(path_next)\")\n",
    "            log = KGModel.train_step(model, opt_state, path_data, args, step)\n",
    "            for metric in log\n",
    "                writer.add_scalar(\"path_\" * metric, log[metric], step)\n",
    "            end\n",
    "            \n",
    "            if train_other_iterator != nothing\n",
    "                (other_data, other_next) = iterate(train_other_iterator, other_next)\n",
    "                log = KGModel.train_step(model, opt_state, other_data, args, step)\n",
    "                for metric in log\n",
    "                    @info \"metric : $(metric)\"\n",
    "                    writer.add_scalar(\"other_\"+metric, log[metric], step)\n",
    "                end\n",
    "                log = KGModule.train_step(model, opt_state, path_data, args, step)\n",
    "            end\n",
    "\n",
    "            training_logs.append(log)\n",
    "\n",
    "            if step >= warn_up_steps\n",
    "                current_learning_rate = current_learning_rate / 5\n",
    "                @info(\"Change learning_rate to $(current_learning_rate) at step $(step)\")\n",
    "\n",
    "                opt_state = Flux.setup(Flux.Optimiser.Adam(lr = current_learning_rate),\n",
    "                                       model)\n",
    "                warn_up_steps = warn_up_steps * 1.5\n",
    "            end\n",
    "\n",
    "            if step % args[\"save_checkpoint_steps\"] == 0\n",
    "                save_variable_list = (\n",
    "                    \"step\": step,\n",
    "                    \"current_learning_rate\": current_learning_rate,\n",
    "                    \"warm_up_steps\": warn_up_steps\n",
    "                )\n",
    "                JLD2.save(model, opt_state, save_variable_list, args)\n",
    "            end\n",
    "\n",
    "            if step % args[\"valid_steps\"] == 0 && step > 0\n",
    "                if args[\"do_valid\"]\n",
    "                    @info(\"Evaluating on Valid Dataset...\")\n",
    "                    valid_all_metrics = evaluate(model, valid_easy_answers, valid_hard_answers, args,\n",
    "                                                 valid_dataloader, query_name_dict, \"Valid\", step, writer)\n",
    "                end\n",
    "\n",
    "                if args[\"do_test\"]\n",
    "                    @info(\"Evaluating on Test Dataset...\")\n",
    "                    test_all_metrics = evaluate(model, test_easy_answers, test_hard_answers, args,\n",
    "                                                test_dataloader, query_name_dict, \"Test\", step, writer)\n",
    "                end\n",
    "            end\n",
    "\n",
    "            if step % args[\"log_steps\"] == 0\n",
    "                metrics = Dict()\n",
    "                for metric in training_logs[0].keys()\n",
    "                    metrics[metric] = sum([log[metric] for log in training_logs])/len(training_logs)\n",
    "                end\n",
    "\n",
    "                log_metrics(\"Training average\", step, metrics)\n",
    "                training_logs = []\n",
    "            end\n",
    "\n",
    "            save_variable_list = (\n",
    "                \"step\": step,\n",
    "                \"current_learning_rate\": current_learning_rate,\n",
    "                \"warm_up_steps\": warn_up_steps\n",
    "            )\n",
    "            JLD2.save(model, opt_state, save_variable_list, args)\n",
    "\n",
    "            try\n",
    "                print(step)\n",
    "            catch\n",
    "                step = 0\n",
    "            end\n",
    "        end\n",
    "        @info(\"Training finished!!\")\n",
    "    end\n",
    "\n",
    "    #    if args[\"test\"]\n",
    "    #        @info(\"Evaluating on Test Dataset...\")\n",
    "    #        test_all_metrics = evaluate(model, test_easy_answers, test_hard_answers, args, test_dataloader, query_name_dict, \"Test\", step, writer)\n",
    "    #    end\n",
    "    #\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae9d4e0-94a3-4b76-a392-659c9c6ac87d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#if abspath(PROGRAM_FILE) == @__FILE__\n",
    "    args = Vector{String}([\"--train\", \"--data_path\", \"dataset/FB15k-betae\",\n",
    "                           \"-n\", \"128\", \"-b\", \"1\", \"-d\", \"800\", \"-g\", \"24\",\"--learning_rate\",\n",
    "                           \"0.0001\", \"--max_steps\", \"450001\",\n",
    "                           \"--cpu\", \"1\", \"--geo\", \"beta\", \"--valid_steps\", \"15000\"])\n",
    "    structed_args = parse_cmdargs(args);\n",
    "    println(structed_args)\n",
    "    set_logger(structed_args);\n",
    "\n",
    "    main(structed_args)\n",
    "\n",
    "#end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1319ac7f-7b4e-4225-a383-b61883827348",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8c5a157-b35a-4c26-9e7c-736d396d6575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict{String, Any}(\"geo\" => \"beta\", \"test_log_steps\" => 1000, \"tasks\" => \"1p.2p.3p.2i.3i.ip.pi.2in.3in.inp.pin.pni.2u.up\", \"batch_size\" => 2, \"evaluate_union\" => \"DNF\", \"nentity\" => 0, \"nrelation\" => 0, \"print_on_screen\" => true, \"cpu\" => 1, \"valid\" => false, \"valid_steps\" => 15000, \"train\" => true, \"negative_sample_size\" => 32, \"checkpoint_path\" => nothing, \"prefix\" => nothing, \"cuda\" => false, \"warm_up_steps\" => nothing, \"hidden_dim\" => 800, \"beta_mode\" => \"(1600,2)\", \"learning_rate\" => 0.0001, \"box_mode\" => \"(nothing,0.02)\", \"data_path\" => \"dataset/FB15k-betae\", \"max_steps\" => 450001, \"save_checkpoint_steps\" => 50000, \"save_path\" => \".\", \"test\" => false, \"gamma\" => 24.0, \"log_steps\" => 100, \"seed\" => 0, \"test_batch_size\" => 1)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:19:28 overwritting saving path: .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module KGDataset.\n",
      "WARNING: replacing module KGModel.\n",
      "WARNING: using KGDataset.TrainDataset in module Main conflicts with an existing identifier.\n",
      "WARNING: using KGModel.KGReasoning in module Main conflicts with an existing identifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:19:28 logging to logs/FB15k-betae/1p.2p.3p.2i.3i.ip.pi.2in.3in.inp.pin.pni.2u.up/beta/g-24.0-mode-(1600,2)/2024.02.15\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:19:28 --------------------------------------------------------------\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:19:28 Geo: beta\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:19:28 Data Path: dataset/FB15k-betae\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:19:28 #entity: 14951\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:19:28 #relation: 2690\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:19:28 #max steps: 450001\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:19:28 Evaluate unoins using: DNF\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:19:28 Train required...\n",
      "(\"e\", (\"r\", \"r\", \"r\"))((\"e\", (\"r\",)), (\"e\", (\"r\",)))((\"e\", (\"r\",)), (\"e\", (\"r\",)), (\"e\", (\"r\",)))(\"e\", (\"r\", \"r\"))(\"e\", (\"r\",))\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:19:28 Flatten query length: 821130 typeof(query) Vector{Any}\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:43 Model Parameter Configuration:\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter layer1-1: (14951, 1)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter Number: 14951\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter layer2-1: (1600, 1600)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter Number: 2560000\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter layer3-1: (1600,)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter Number: 1600\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter layer4-1: (800, 1600)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter Number: 1280000\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter layer5-1: (800,)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter Number: 800\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter layer6-1: (1600, 1600)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter Number: 2560000\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter layer7-1: (1600,)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter Number: 1600\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter layer8-1: (1600, 1600)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter Number: 2560000\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter layer9-1: (1600,)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter Number: 1600\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter layer10-1: (1600, 2400)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter Number: 3840000\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter layer11-1: (1600,)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Parameter Number: 1600\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Ramdomly Initializing beta Model...\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 beta mode = (1600,2)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 tasks = 1p.2p.3p.2i.3i.ip.pi.2in.3in.inp.pin.pni.2u.up\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 init_step = 0\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 learning_rate = 0.0001\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 batch_size = 2\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 hidden_dim = 800\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 gamma = 24.0\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 Start Training...\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 TrainDataset [1] -> ((8300, (442,)), (\"e\", (\"r\",))) answer: Set(Any[401, 365])\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 TrainDataset tail 365 subsampling_weight: 6\n",
      "getobs set mask at 2 11591\n",
      "getobs set mask at 2 10052\n",
      "getobs set mask at 2 10740\n",
      "getobs set mask at 1 7639\n",
      "getobs set mask at 2 5732\n",
      "getobs set mask at 2 8902\n",
      "getobs set mask at 2 2099\n",
      "getobs set mask at 1 1523\n",
      "getobs set mask at 2 11992\n",
      "getobs set mask at 2 14327\n",
      "getobs set mask at 2 12283\n",
      "getobs set mask at 1 7975\n",
      "getobs set mask at 2 11947\n",
      "getobs set mask at 1 10253\n",
      "getobs set mask at 2 9273\n",
      "getobs set mask at 1 11938\n",
      "getobs set mask at 1 2390\n",
      "getobs set mask at 2 3852\n",
      "getobs set mask at 2 4423\n",
      "getobs set mask at 2 2879\n",
      "getobs set mask at 2 817\n",
      "getobs set mask at 1 676\n",
      "getobs set mask at 2 244\n",
      "getobs set mask at 1 14134\n",
      "getobs set mask at 1 7019\n",
      "getobs set mask at 1 11433\n",
      "getobs set mask at 2 6243\n",
      "getobs set mask at 2 3561\n",
      "getobs set mask at 1 3179\n",
      "getobs set mask at 1 14630\n",
      "getobs set mask at 1 14226\n",
      "getobs set mask at 2 14715\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m2024-02-15 10:20:44 getobs one item -------------------------------------------------\n",
      "Main.KGDataset.TrainDataset\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching getindex(::Main.KGDataset.TrainDataset, ::Int64)",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching getindex(::Main.KGDataset.TrainDataset, ::Int64)",
      "",
      "Stacktrace:",
      " [1] getobs(::Type{SimpleTraits.Not{MLUtils.IsTable{Main.KGDataset.TrainDataset}}}, data::Main.KGDataset.TrainDataset, idx::Int64)",
      "   @ MLUtils ~/.julia/packages/MLUtils/LmmaQ/src/observation.jl:110",
      " [2] getobs",
      "   @ ~/.julia/packages/SimpleTraits/l1ZsK/src/SimpleTraits.jl:331 [inlined]",
      " [3] train_step(model::Main.KGModel.KGReasoning, opt_state::@NamedTuple{nentity::Tuple{}, nrelation::Tuple{}, hidden_dim::Tuple{}, epsilon::Tuple{}, geo::Tuple{}, use_cuda::Tuple{}, batch_entity_range::Optimisers.Leaf{Optimisers.Adam, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, query_name_dict::Dict{Tuple{Any, Tuple{String, Vararg{Any}}, Vararg{Tuple{String, Vararg{Tuple{String, Vararg{String}}}}}}, Tuple{}}, gamma::Tuple{}, embedding_range::Tuple{}, entity_dim::Tuple{}, relation_dim::Tuple{}, entity_embedding::Tuple{}, cen::Tuple{}, func::Tuple{}, entity_regularizer::@NamedTuple{base_add::Tuple{}, min_val::Tuple{}, max_val::Tuple{}}, projection_regularizer::@NamedTuple{base_add::Tuple{}, min_val::Tuple{}, max_val::Tuple{}}, offset_embedding::Tuple{}, center_net::@NamedTuple{dim::Tuple{}, layer1::@NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}, ::Tuple{}}, layer2::@NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}, ::Tuple{}}}, offset_net::Tuple{}, num_layers::Tuple{}, projection_net::@NamedTuple{entity_dim::Tuple{}, relation_dim::Tuple{}, hidden_dim::Tuple{}, num_layers::Tuple{}, layers::Dict{Symbol, @NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}, ::Tuple{}}}, projection_regularizer::@NamedTuple{base_add::Tuple{}, min_val::Tuple{}, max_val::Tuple{}}}}, data::Main.KGDataset.TrainDataset, args::Dict{String, Any}, step::Int64)",
      "   @ Main.KGModel /sata/sdb5/julia/pro_kgreasoning/src/model.jl:906",
      " [4] main(args::Dict{String, Any})",
      "   @ Main /sata/sdb5/julia/pro_kgreasoning/src/main.jl:462",
      " [5] top-level scope",
      "   @ In[11]:13"
     ]
    }
   ],
   "source": [
    "using Revise\n",
    "\n",
    "include(\"src/main.jl\")\n",
    "\n",
    "args = Vector{String}([\"--train\", \"--data_path\", \"dataset/FB15k-betae\",\n",
    "                       \"-n\", \"32\", \"-b\", \"2\", \"-d\", \"800\", \"-g\", \"24\",\"--learning_rate\",\n",
    "                       \"0.0001\", \"--max_steps\", \"450001\",\n",
    "                       \"--cpu\", \"1\", \"--geo\", \"beta\", \"--valid_steps\", \"15000\"])\n",
    "structed_args = parse_cmdargs(args);\n",
    "println(structed_args)\n",
    "set_logger(structed_args);\n",
    "\n",
    "main(structed_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20641f61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  },
  "name": "KGReasoning.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
